{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "from random import randint\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='svg'\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Birth Rate dataset: \n",
      "    year   value\n",
      "45  2005  38.366\n",
      "46  2006  37.890\n",
      "47  2007  37.330\n",
      "48  2008  36.678\n",
      "49  2009  35.942\n",
      "50  2010  35.128\n",
      "51  2011  34.249\n",
      "52  2012  33.333\n",
      "53  2013  32.415\n",
      "54  2014  31.522\n",
      "55  2015  30.688\n",
      "56  2016  29.943\n",
      "57  2017  29.296\n",
      "58  2018  28.748\n",
      "59  2019  28.298\n",
      "shape:  (60, 2)\n"
     ]
    }
   ],
   "source": [
    "#process data\n",
    "#read from csv\n",
    "df=pd.read_csv('data/univariate/kenya/ken_brt_lstm.csv')\n",
    "print('Birth Rate dataset: ')\n",
    "print(df.tail(15))\n",
    "print('shape: ',df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"389.829844pt\" version=\"1.1\" viewBox=\"0 0 497.508437 389.829844\" width=\"497.508437pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2021-08-18T16:56:21.472204</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 389.829844 \n",
       "L 497.508437 389.829844 \n",
       "L 497.508437 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 43.908438 348.095625 \n",
       "L 490.308437 348.095625 \n",
       "L 490.308437 21.935625 \n",
       "L 43.908438 21.935625 \n",
       "z\n",
       "\" style=\"fill:#eaeaf2;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path clip-path=\"url(#p59f17a537d)\" d=\"M 64.199347 348.095625 \n",
       "L 64.199347 21.935625 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 1960 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(51.965284 365.469219)scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path d=\"M 37.25 0 \n",
       "L 28.46875 0 \n",
       "L 28.46875 56 \n",
       "Q 25.296875 52.984375 20.140625 49.953125 \n",
       "Q 14.984375 46.921875 10.890625 45.40625 \n",
       "L 10.890625 53.90625 \n",
       "Q 18.265625 57.375 23.78125 62.296875 \n",
       "Q 29.296875 67.234375 31.59375 71.875 \n",
       "L 37.25 71.875 \n",
       "z\n",
       "\" id=\"ArialMT-49\"/>\n",
       "        <path d=\"M 5.46875 16.546875 \n",
       "L 13.921875 17.328125 \n",
       "Q 14.984375 11.375 18.015625 8.6875 \n",
       "Q 21.046875 6 25.78125 6 \n",
       "Q 29.828125 6 32.875 7.859375 \n",
       "Q 35.9375 9.71875 37.890625 12.8125 \n",
       "Q 39.84375 15.921875 41.15625 21.1875 \n",
       "Q 42.484375 26.46875 42.484375 31.9375 \n",
       "Q 42.484375 32.515625 42.4375 33.6875 \n",
       "Q 39.796875 29.5 35.234375 26.875 \n",
       "Q 30.671875 24.265625 25.34375 24.265625 \n",
       "Q 16.453125 24.265625 10.296875 30.703125 \n",
       "Q 4.15625 37.15625 4.15625 47.703125 \n",
       "Q 4.15625 58.59375 10.578125 65.234375 \n",
       "Q 17 71.875 26.65625 71.875 \n",
       "Q 33.640625 71.875 39.421875 68.109375 \n",
       "Q 45.21875 64.359375 48.21875 57.390625 \n",
       "Q 51.21875 50.4375 51.21875 37.25 \n",
       "Q 51.21875 23.53125 48.234375 15.40625 \n",
       "Q 45.265625 7.28125 39.375 3.03125 \n",
       "Q 33.5 -1.21875 25.59375 -1.21875 \n",
       "Q 17.1875 -1.21875 11.859375 3.4375 \n",
       "Q 6.546875 8.109375 5.46875 16.546875 \n",
       "z\n",
       "M 41.453125 48.140625 \n",
       "Q 41.453125 55.71875 37.421875 60.15625 \n",
       "Q 33.40625 64.59375 27.734375 64.59375 \n",
       "Q 21.875 64.59375 17.53125 59.8125 \n",
       "Q 13.1875 55.03125 13.1875 47.40625 \n",
       "Q 13.1875 40.578125 17.3125 36.296875 \n",
       "Q 21.4375 32.03125 27.484375 32.03125 \n",
       "Q 33.59375 32.03125 37.515625 36.296875 \n",
       "Q 41.453125 40.578125 41.453125 48.140625 \n",
       "z\n",
       "\" id=\"ArialMT-57\"/>\n",
       "        <path d=\"M 49.75 54.046875 \n",
       "L 41.015625 53.375 \n",
       "Q 39.84375 58.546875 37.703125 60.890625 \n",
       "Q 34.125 64.65625 28.90625 64.65625 \n",
       "Q 24.703125 64.65625 21.53125 62.3125 \n",
       "Q 17.390625 59.28125 14.984375 53.46875 \n",
       "Q 12.59375 47.65625 12.5 36.921875 \n",
       "Q 15.671875 41.75 20.265625 44.09375 \n",
       "Q 24.859375 46.4375 29.890625 46.4375 \n",
       "Q 38.671875 46.4375 44.84375 39.96875 \n",
       "Q 51.03125 33.5 51.03125 23.25 \n",
       "Q 51.03125 16.5 48.125 10.71875 \n",
       "Q 45.21875 4.9375 40.140625 1.859375 \n",
       "Q 35.0625 -1.21875 28.609375 -1.21875 \n",
       "Q 17.625 -1.21875 10.6875 6.859375 \n",
       "Q 3.765625 14.9375 3.765625 33.5 \n",
       "Q 3.765625 54.25 11.421875 63.671875 \n",
       "Q 18.109375 71.875 29.4375 71.875 \n",
       "Q 37.890625 71.875 43.28125 67.140625 \n",
       "Q 48.6875 62.40625 49.75 54.046875 \n",
       "z\n",
       "M 13.875 23.1875 \n",
       "Q 13.875 18.65625 15.796875 14.5 \n",
       "Q 17.71875 10.359375 21.1875 8.171875 \n",
       "Q 24.65625 6 28.46875 6 \n",
       "Q 34.03125 6 38.03125 10.484375 \n",
       "Q 42.046875 14.984375 42.046875 22.703125 \n",
       "Q 42.046875 30.125 38.078125 34.390625 \n",
       "Q 34.125 38.671875 28.125 38.671875 \n",
       "Q 22.171875 38.671875 18.015625 34.390625 \n",
       "Q 13.875 30.125 13.875 23.1875 \n",
       "z\n",
       "\" id=\"ArialMT-54\"/>\n",
       "        <path d=\"M 4.15625 35.296875 \n",
       "Q 4.15625 48 6.765625 55.734375 \n",
       "Q 9.375 63.484375 14.515625 67.671875 \n",
       "Q 19.671875 71.875 27.484375 71.875 \n",
       "Q 33.25 71.875 37.59375 69.546875 \n",
       "Q 41.9375 67.234375 44.765625 62.859375 \n",
       "Q 47.609375 58.5 49.21875 52.21875 \n",
       "Q 50.828125 45.953125 50.828125 35.296875 \n",
       "Q 50.828125 22.703125 48.234375 14.96875 \n",
       "Q 45.65625 7.234375 40.5 3 \n",
       "Q 35.359375 -1.21875 27.484375 -1.21875 \n",
       "Q 17.140625 -1.21875 11.234375 6.203125 \n",
       "Q 4.15625 15.140625 4.15625 35.296875 \n",
       "z\n",
       "M 13.1875 35.296875 \n",
       "Q 13.1875 17.671875 17.3125 11.828125 \n",
       "Q 21.4375 6 27.484375 6 \n",
       "Q 33.546875 6 37.671875 11.859375 \n",
       "Q 41.796875 17.71875 41.796875 35.296875 \n",
       "Q 41.796875 52.984375 37.671875 58.78125 \n",
       "Q 33.546875 64.59375 27.390625 64.59375 \n",
       "Q 21.34375 64.59375 17.71875 59.46875 \n",
       "Q 13.1875 52.9375 13.1875 35.296875 \n",
       "z\n",
       "\" id=\"ArialMT-48\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-49\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-57\"/>\n",
       "       <use x=\"111.230469\" xlink:href=\"#ArialMT-54\"/>\n",
       "       <use x=\"166.845703\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <path clip-path=\"url(#p59f17a537d)\" d=\"M 132.982089 348.095625 \n",
       "L 132.982089 21.935625 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 1970 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(120.748027 365.469219)scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path d=\"M 4.734375 62.203125 \n",
       "L 4.734375 70.65625 \n",
       "L 51.078125 70.65625 \n",
       "L 51.078125 63.8125 \n",
       "Q 44.234375 56.546875 37.515625 44.484375 \n",
       "Q 30.8125 32.421875 27.15625 19.671875 \n",
       "Q 24.515625 10.6875 23.78125 0 \n",
       "L 14.75 0 \n",
       "Q 14.890625 8.453125 18.0625 20.40625 \n",
       "Q 21.234375 32.375 27.171875 43.484375 \n",
       "Q 33.109375 54.59375 39.796875 62.203125 \n",
       "z\n",
       "\" id=\"ArialMT-55\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-49\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-57\"/>\n",
       "       <use x=\"111.230469\" xlink:href=\"#ArialMT-55\"/>\n",
       "       <use x=\"166.845703\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path clip-path=\"url(#p59f17a537d)\" d=\"M 201.764832 348.095625 \n",
       "L 201.764832 21.935625 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 1980 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(189.530769 365.469219)scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path d=\"M 17.671875 38.8125 \n",
       "Q 12.203125 40.828125 9.5625 44.53125 \n",
       "Q 6.9375 48.25 6.9375 53.421875 \n",
       "Q 6.9375 61.234375 12.546875 66.546875 \n",
       "Q 18.171875 71.875 27.484375 71.875 \n",
       "Q 36.859375 71.875 42.578125 66.421875 \n",
       "Q 48.296875 60.984375 48.296875 53.171875 \n",
       "Q 48.296875 48.1875 45.671875 44.5 \n",
       "Q 43.0625 40.828125 37.75 38.8125 \n",
       "Q 44.34375 36.671875 47.78125 31.875 \n",
       "Q 51.21875 27.09375 51.21875 20.453125 \n",
       "Q 51.21875 11.28125 44.71875 5.03125 \n",
       "Q 38.234375 -1.21875 27.640625 -1.21875 \n",
       "Q 17.046875 -1.21875 10.546875 5.046875 \n",
       "Q 4.046875 11.328125 4.046875 20.703125 \n",
       "Q 4.046875 27.6875 7.59375 32.390625 \n",
       "Q 11.140625 37.109375 17.671875 38.8125 \n",
       "z\n",
       "M 15.921875 53.71875 \n",
       "Q 15.921875 48.640625 19.1875 45.40625 \n",
       "Q 22.46875 42.1875 27.6875 42.1875 \n",
       "Q 32.765625 42.1875 36.015625 45.375 \n",
       "Q 39.265625 48.578125 39.265625 53.21875 \n",
       "Q 39.265625 58.0625 35.90625 61.359375 \n",
       "Q 32.5625 64.65625 27.59375 64.65625 \n",
       "Q 22.5625 64.65625 19.234375 61.421875 \n",
       "Q 15.921875 58.203125 15.921875 53.71875 \n",
       "z\n",
       "M 13.09375 20.65625 \n",
       "Q 13.09375 16.890625 14.875 13.375 \n",
       "Q 16.65625 9.859375 20.171875 7.921875 \n",
       "Q 23.6875 6 27.734375 6 \n",
       "Q 34.03125 6 38.125 10.046875 \n",
       "Q 42.234375 14.109375 42.234375 20.359375 \n",
       "Q 42.234375 26.703125 38.015625 30.859375 \n",
       "Q 33.796875 35.015625 27.4375 35.015625 \n",
       "Q 21.234375 35.015625 17.15625 30.90625 \n",
       "Q 13.09375 26.8125 13.09375 20.65625 \n",
       "z\n",
       "\" id=\"ArialMT-56\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-49\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-57\"/>\n",
       "       <use x=\"111.230469\" xlink:href=\"#ArialMT-56\"/>\n",
       "       <use x=\"166.845703\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <path clip-path=\"url(#p59f17a537d)\" d=\"M 270.547575 348.095625 \n",
       "L 270.547575 21.935625 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 1990 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(258.313512 365.469219)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-49\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-57\"/>\n",
       "       <use x=\"111.230469\" xlink:href=\"#ArialMT-57\"/>\n",
       "       <use x=\"166.845703\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path clip-path=\"url(#p59f17a537d)\" d=\"M 339.330317 348.095625 \n",
       "L 339.330317 21.935625 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 2000 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(327.096255 365.469219)scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path d=\"M 50.34375 8.453125 \n",
       "L 50.34375 0 \n",
       "L 3.03125 0 \n",
       "Q 2.9375 3.171875 4.046875 6.109375 \n",
       "Q 5.859375 10.9375 9.828125 15.625 \n",
       "Q 13.8125 20.3125 21.34375 26.46875 \n",
       "Q 33.015625 36.03125 37.109375 41.625 \n",
       "Q 41.21875 47.21875 41.21875 52.203125 \n",
       "Q 41.21875 57.421875 37.46875 61 \n",
       "Q 33.734375 64.59375 27.734375 64.59375 \n",
       "Q 21.390625 64.59375 17.578125 60.78125 \n",
       "Q 13.765625 56.984375 13.71875 50.25 \n",
       "L 4.6875 51.171875 \n",
       "Q 5.609375 61.28125 11.65625 66.578125 \n",
       "Q 17.71875 71.875 27.9375 71.875 \n",
       "Q 38.234375 71.875 44.234375 66.15625 \n",
       "Q 50.25 60.453125 50.25 52 \n",
       "Q 50.25 47.703125 48.484375 43.546875 \n",
       "Q 46.734375 39.40625 42.65625 34.8125 \n",
       "Q 38.578125 30.21875 29.109375 22.21875 \n",
       "Q 21.1875 15.578125 18.9375 13.203125 \n",
       "Q 16.703125 10.84375 15.234375 8.453125 \n",
       "z\n",
       "\" id=\"ArialMT-50\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-50\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"111.230469\" xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"166.845703\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <path clip-path=\"url(#p59f17a537d)\" d=\"M 408.11306 348.095625 \n",
       "L 408.11306 21.935625 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 2010 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(395.878997 365.469219)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-50\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"111.230469\" xlink:href=\"#ArialMT-49\"/>\n",
       "       <use x=\"166.845703\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path clip-path=\"url(#p59f17a537d)\" d=\"M 476.895803 348.095625 \n",
       "L 476.895803 21.935625 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 2020 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(464.66174 365.469219)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-50\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\n",
       "       <use x=\"111.230469\" xlink:href=\"#ArialMT-50\"/>\n",
       "       <use x=\"166.845703\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_8\">\n",
       "     <!-- Year -->\n",
       "     <g style=\"fill:#262626;\" transform=\"translate(254.982812 380.244844)scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path d=\"M 27.875 0 \n",
       "L 27.875 30.328125 \n",
       "L 0.296875 71.578125 \n",
       "L 11.8125 71.578125 \n",
       "L 25.921875 50 \n",
       "Q 29.828125 43.953125 33.203125 37.890625 \n",
       "Q 36.421875 43.5 41.015625 50.53125 \n",
       "L 54.890625 71.578125 \n",
       "L 65.921875 71.578125 \n",
       "L 37.359375 30.328125 \n",
       "L 37.359375 0 \n",
       "z\n",
       "\" id=\"ArialMT-89\"/>\n",
       "       <path d=\"M 42.09375 16.703125 \n",
       "L 51.171875 15.578125 \n",
       "Q 49.03125 7.625 43.21875 3.21875 \n",
       "Q 37.40625 -1.171875 28.375 -1.171875 \n",
       "Q 17 -1.171875 10.328125 5.828125 \n",
       "Q 3.65625 12.84375 3.65625 25.484375 \n",
       "Q 3.65625 38.578125 10.390625 45.796875 \n",
       "Q 17.140625 53.03125 27.875 53.03125 \n",
       "Q 38.28125 53.03125 44.875 45.953125 \n",
       "Q 51.46875 38.875 51.46875 26.03125 \n",
       "Q 51.46875 25.25 51.421875 23.6875 \n",
       "L 12.75 23.6875 \n",
       "Q 13.234375 15.140625 17.578125 10.59375 \n",
       "Q 21.921875 6.0625 28.421875 6.0625 \n",
       "Q 33.25 6.0625 36.671875 8.59375 \n",
       "Q 40.09375 11.140625 42.09375 16.703125 \n",
       "z\n",
       "M 13.234375 30.90625 \n",
       "L 42.1875 30.90625 \n",
       "Q 41.609375 37.453125 38.875 40.71875 \n",
       "Q 34.671875 45.796875 27.984375 45.796875 \n",
       "Q 21.921875 45.796875 17.796875 41.75 \n",
       "Q 13.671875 37.703125 13.234375 30.90625 \n",
       "z\n",
       "\" id=\"ArialMT-101\"/>\n",
       "       <path d=\"M 40.4375 6.390625 \n",
       "Q 35.546875 2.25 31.03125 0.53125 \n",
       "Q 26.515625 -1.171875 21.34375 -1.171875 \n",
       "Q 12.796875 -1.171875 8.203125 3 \n",
       "Q 3.609375 7.171875 3.609375 13.671875 \n",
       "Q 3.609375 17.484375 5.34375 20.625 \n",
       "Q 7.078125 23.78125 9.890625 25.6875 \n",
       "Q 12.703125 27.59375 16.21875 28.5625 \n",
       "Q 18.796875 29.25 24.03125 29.890625 \n",
       "Q 34.671875 31.15625 39.703125 32.90625 \n",
       "Q 39.75 34.71875 39.75 35.203125 \n",
       "Q 39.75 40.578125 37.25 42.78125 \n",
       "Q 33.890625 45.75 27.25 45.75 \n",
       "Q 21.046875 45.75 18.09375 43.578125 \n",
       "Q 15.140625 41.40625 13.71875 35.890625 \n",
       "L 5.125 37.0625 \n",
       "Q 6.296875 42.578125 8.984375 45.96875 \n",
       "Q 11.671875 49.359375 16.75 51.1875 \n",
       "Q 21.828125 53.03125 28.515625 53.03125 \n",
       "Q 35.15625 53.03125 39.296875 51.46875 \n",
       "Q 43.453125 49.90625 45.40625 47.53125 \n",
       "Q 47.359375 45.171875 48.140625 41.546875 \n",
       "Q 48.578125 39.3125 48.578125 33.453125 \n",
       "L 48.578125 21.734375 \n",
       "Q 48.578125 9.46875 49.140625 6.21875 \n",
       "Q 49.703125 2.984375 51.375 0 \n",
       "L 42.1875 0 \n",
       "Q 40.828125 2.734375 40.4375 6.390625 \n",
       "z\n",
       "M 39.703125 26.03125 \n",
       "Q 34.90625 24.078125 25.34375 22.703125 \n",
       "Q 19.921875 21.921875 17.671875 20.9375 \n",
       "Q 15.4375 19.96875 14.203125 18.09375 \n",
       "Q 12.984375 16.21875 12.984375 13.921875 \n",
       "Q 12.984375 10.40625 15.640625 8.0625 \n",
       "Q 18.3125 5.71875 23.4375 5.71875 \n",
       "Q 28.515625 5.71875 32.46875 7.9375 \n",
       "Q 36.421875 10.15625 38.28125 14.015625 \n",
       "Q 39.703125 17 39.703125 22.796875 \n",
       "z\n",
       "\" id=\"ArialMT-97\"/>\n",
       "       <path d=\"M 6.5 0 \n",
       "L 6.5 51.859375 \n",
       "L 14.40625 51.859375 \n",
       "L 14.40625 44 \n",
       "Q 17.4375 49.515625 20 51.265625 \n",
       "Q 22.5625 53.03125 25.640625 53.03125 \n",
       "Q 30.078125 53.03125 34.671875 50.203125 \n",
       "L 31.640625 42.046875 \n",
       "Q 28.421875 43.953125 25.203125 43.953125 \n",
       "Q 22.3125 43.953125 20.015625 42.21875 \n",
       "Q 17.71875 40.484375 16.75 37.40625 \n",
       "Q 15.28125 32.71875 15.28125 27.15625 \n",
       "L 15.28125 0 \n",
       "z\n",
       "\" id=\"ArialMT-114\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#ArialMT-89\"/>\n",
       "      <use x=\"57.574219\" xlink:href=\"#ArialMT-101\"/>\n",
       "      <use x=\"113.189453\" xlink:href=\"#ArialMT-97\"/>\n",
       "      <use x=\"168.804688\" xlink:href=\"#ArialMT-114\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <path clip-path=\"url(#p59f17a537d)\" d=\"M 43.908438 311.19219 \n",
       "L 490.308437 311.19219 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 30 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(22.174375 315.128987)scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path d=\"M 4.203125 18.890625 \n",
       "L 12.984375 20.0625 \n",
       "Q 14.5 12.59375 18.140625 9.296875 \n",
       "Q 21.78125 6 27 6 \n",
       "Q 33.203125 6 37.46875 10.296875 \n",
       "Q 41.75 14.59375 41.75 20.953125 \n",
       "Q 41.75 27 37.796875 30.921875 \n",
       "Q 33.84375 34.859375 27.734375 34.859375 \n",
       "Q 25.25 34.859375 21.53125 33.890625 \n",
       "L 22.515625 41.609375 \n",
       "Q 23.390625 41.5 23.921875 41.5 \n",
       "Q 29.546875 41.5 34.03125 44.421875 \n",
       "Q 38.53125 47.359375 38.53125 53.46875 \n",
       "Q 38.53125 58.296875 35.25 61.46875 \n",
       "Q 31.984375 64.65625 26.8125 64.65625 \n",
       "Q 21.6875 64.65625 18.265625 61.421875 \n",
       "Q 14.84375 58.203125 13.875 51.765625 \n",
       "L 5.078125 53.328125 \n",
       "Q 6.6875 62.15625 12.390625 67.015625 \n",
       "Q 18.109375 71.875 26.609375 71.875 \n",
       "Q 32.46875 71.875 37.390625 69.359375 \n",
       "Q 42.328125 66.84375 44.9375 62.5 \n",
       "Q 47.5625 58.15625 47.5625 53.265625 \n",
       "Q 47.5625 48.640625 45.0625 44.828125 \n",
       "Q 42.578125 41.015625 37.703125 38.765625 \n",
       "Q 44.046875 37.3125 47.5625 32.6875 \n",
       "Q 51.078125 28.078125 51.078125 21.140625 \n",
       "Q 51.078125 11.765625 44.234375 5.25 \n",
       "Q 37.40625 -1.265625 26.953125 -1.265625 \n",
       "Q 17.53125 -1.265625 11.296875 4.34375 \n",
       "Q 5.078125 9.96875 4.203125 18.890625 \n",
       "z\n",
       "\" id=\"ArialMT-51\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-51\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path clip-path=\"url(#p59f17a537d)\" d=\"M 43.908438 246.333259 \n",
       "L 490.308437 246.333259 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 35 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(22.174375 250.270056)scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path d=\"M 4.15625 18.75 \n",
       "L 13.375 19.53125 \n",
       "Q 14.40625 12.796875 18.140625 9.390625 \n",
       "Q 21.875 6 27.15625 6 \n",
       "Q 33.5 6 37.890625 10.78125 \n",
       "Q 42.28125 15.578125 42.28125 23.484375 \n",
       "Q 42.28125 31 38.0625 35.34375 \n",
       "Q 33.84375 39.703125 27 39.703125 \n",
       "Q 22.75 39.703125 19.328125 37.765625 \n",
       "Q 15.921875 35.84375 13.96875 32.765625 \n",
       "L 5.71875 33.84375 \n",
       "L 12.640625 70.609375 \n",
       "L 48.25 70.609375 \n",
       "L 48.25 62.203125 \n",
       "L 19.671875 62.203125 \n",
       "L 15.828125 42.96875 \n",
       "Q 22.265625 47.46875 29.34375 47.46875 \n",
       "Q 38.71875 47.46875 45.15625 40.96875 \n",
       "Q 51.609375 34.46875 51.609375 24.265625 \n",
       "Q 51.609375 14.546875 45.953125 7.46875 \n",
       "Q 39.0625 -1.21875 27.15625 -1.21875 \n",
       "Q 17.390625 -1.21875 11.203125 4.25 \n",
       "Q 5.03125 9.71875 4.15625 18.75 \n",
       "z\n",
       "\" id=\"ArialMT-53\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-51\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <path clip-path=\"url(#p59f17a537d)\" d=\"M 43.908438 181.474327 \n",
       "L 490.308437 181.474327 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 40 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(22.174375 185.411124)scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path d=\"M 32.328125 0 \n",
       "L 32.328125 17.140625 \n",
       "L 1.265625 17.140625 \n",
       "L 1.265625 25.203125 \n",
       "L 33.9375 71.578125 \n",
       "L 41.109375 71.578125 \n",
       "L 41.109375 25.203125 \n",
       "L 50.78125 25.203125 \n",
       "L 50.78125 17.140625 \n",
       "L 41.109375 17.140625 \n",
       "L 41.109375 0 \n",
       "z\n",
       "M 32.328125 25.203125 \n",
       "L 32.328125 57.46875 \n",
       "L 9.90625 25.203125 \n",
       "z\n",
       "\" id=\"ArialMT-52\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-52\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path clip-path=\"url(#p59f17a537d)\" d=\"M 43.908438 116.615396 \n",
       "L 490.308437 116.615396 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 45 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(22.174375 120.552193)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-52\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <path clip-path=\"url(#p59f17a537d)\" d=\"M 43.908438 51.756464 \n",
       "L 490.308437 51.756464 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 50 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(22.174375 55.693261)scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-53\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_14\">\n",
       "     <!-- Birth Rate -->\n",
       "     <g style=\"fill:#262626;\" transform=\"translate(15.789375 211.692187)rotate(-90)scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path d=\"M 7.328125 0 \n",
       "L 7.328125 71.578125 \n",
       "L 34.1875 71.578125 \n",
       "Q 42.390625 71.578125 47.34375 69.40625 \n",
       "Q 52.296875 67.234375 55.09375 62.71875 \n",
       "Q 57.90625 58.203125 57.90625 53.265625 \n",
       "Q 57.90625 48.6875 55.421875 44.625 \n",
       "Q 52.9375 40.578125 47.90625 38.09375 \n",
       "Q 54.390625 36.1875 57.875 31.59375 \n",
       "Q 61.375 27 61.375 20.75 \n",
       "Q 61.375 15.71875 59.25 11.390625 \n",
       "Q 57.125 7.078125 54 4.734375 \n",
       "Q 50.875 2.390625 46.15625 1.1875 \n",
       "Q 41.453125 0 34.625 0 \n",
       "z\n",
       "M 16.796875 41.5 \n",
       "L 32.28125 41.5 \n",
       "Q 38.578125 41.5 41.3125 42.328125 \n",
       "Q 44.921875 43.40625 46.75 45.890625 \n",
       "Q 48.578125 48.390625 48.578125 52.15625 \n",
       "Q 48.578125 55.71875 46.875 58.421875 \n",
       "Q 45.171875 61.140625 41.984375 62.140625 \n",
       "Q 38.8125 63.140625 31.109375 63.140625 \n",
       "L 16.796875 63.140625 \n",
       "z\n",
       "M 16.796875 8.453125 \n",
       "L 34.625 8.453125 \n",
       "Q 39.203125 8.453125 41.0625 8.796875 \n",
       "Q 44.34375 9.375 46.53125 10.734375 \n",
       "Q 48.734375 12.109375 50.140625 14.71875 \n",
       "Q 51.5625 17.328125 51.5625 20.75 \n",
       "Q 51.5625 24.75 49.515625 27.703125 \n",
       "Q 47.46875 30.671875 43.828125 31.859375 \n",
       "Q 40.1875 33.0625 33.34375 33.0625 \n",
       "L 16.796875 33.0625 \n",
       "z\n",
       "\" id=\"ArialMT-66\"/>\n",
       "       <path d=\"M 6.640625 61.46875 \n",
       "L 6.640625 71.578125 \n",
       "L 15.4375 71.578125 \n",
       "L 15.4375 61.46875 \n",
       "z\n",
       "M 6.640625 0 \n",
       "L 6.640625 51.859375 \n",
       "L 15.4375 51.859375 \n",
       "L 15.4375 0 \n",
       "z\n",
       "\" id=\"ArialMT-105\"/>\n",
       "       <path d=\"M 25.78125 7.859375 \n",
       "L 27.046875 0.09375 \n",
       "Q 23.34375 -0.6875 20.40625 -0.6875 \n",
       "Q 15.625 -0.6875 12.984375 0.828125 \n",
       "Q 10.359375 2.34375 9.28125 4.8125 \n",
       "Q 8.203125 7.28125 8.203125 15.1875 \n",
       "L 8.203125 45.015625 \n",
       "L 1.765625 45.015625 \n",
       "L 1.765625 51.859375 \n",
       "L 8.203125 51.859375 \n",
       "L 8.203125 64.703125 \n",
       "L 16.9375 69.96875 \n",
       "L 16.9375 51.859375 \n",
       "L 25.78125 51.859375 \n",
       "L 25.78125 45.015625 \n",
       "L 16.9375 45.015625 \n",
       "L 16.9375 14.703125 \n",
       "Q 16.9375 10.9375 17.40625 9.859375 \n",
       "Q 17.875 8.796875 18.921875 8.15625 \n",
       "Q 19.96875 7.515625 21.921875 7.515625 \n",
       "Q 23.390625 7.515625 25.78125 7.859375 \n",
       "z\n",
       "\" id=\"ArialMT-116\"/>\n",
       "       <path d=\"M 6.59375 0 \n",
       "L 6.59375 71.578125 \n",
       "L 15.375 71.578125 \n",
       "L 15.375 45.90625 \n",
       "Q 21.53125 53.03125 30.90625 53.03125 \n",
       "Q 36.671875 53.03125 40.921875 50.75 \n",
       "Q 45.171875 48.484375 47 44.484375 \n",
       "Q 48.828125 40.484375 48.828125 32.859375 \n",
       "L 48.828125 0 \n",
       "L 40.046875 0 \n",
       "L 40.046875 32.859375 \n",
       "Q 40.046875 39.453125 37.1875 42.453125 \n",
       "Q 34.328125 45.453125 29.109375 45.453125 \n",
       "Q 25.203125 45.453125 21.75 43.421875 \n",
       "Q 18.3125 41.40625 16.84375 37.9375 \n",
       "Q 15.375 34.46875 15.375 28.375 \n",
       "L 15.375 0 \n",
       "z\n",
       "\" id=\"ArialMT-104\"/>\n",
       "       <path id=\"ArialMT-32\"/>\n",
       "       <path d=\"M 7.859375 0 \n",
       "L 7.859375 71.578125 \n",
       "L 39.59375 71.578125 \n",
       "Q 49.171875 71.578125 54.140625 69.640625 \n",
       "Q 59.125 67.71875 62.109375 62.828125 \n",
       "Q 65.09375 57.953125 65.09375 52.046875 \n",
       "Q 65.09375 44.4375 60.15625 39.203125 \n",
       "Q 55.21875 33.984375 44.921875 32.5625 \n",
       "Q 48.6875 30.765625 50.640625 29 \n",
       "Q 54.78125 25.203125 58.5 19.484375 \n",
       "L 70.953125 0 \n",
       "L 59.03125 0 \n",
       "L 49.5625 14.890625 \n",
       "Q 45.40625 21.34375 42.71875 24.75 \n",
       "Q 40.046875 28.171875 37.921875 29.53125 \n",
       "Q 35.796875 30.90625 33.59375 31.453125 \n",
       "Q 31.984375 31.78125 28.328125 31.78125 \n",
       "L 17.328125 31.78125 \n",
       "L 17.328125 0 \n",
       "z\n",
       "M 17.328125 39.984375 \n",
       "L 37.703125 39.984375 \n",
       "Q 44.1875 39.984375 47.84375 41.328125 \n",
       "Q 51.515625 42.671875 53.421875 45.625 \n",
       "Q 55.328125 48.578125 55.328125 52.046875 \n",
       "Q 55.328125 57.125 51.640625 60.390625 \n",
       "Q 47.953125 63.671875 39.984375 63.671875 \n",
       "L 17.328125 63.671875 \n",
       "z\n",
       "\" id=\"ArialMT-82\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#ArialMT-66\"/>\n",
       "      <use x=\"66.699219\" xlink:href=\"#ArialMT-105\"/>\n",
       "      <use x=\"88.916016\" xlink:href=\"#ArialMT-114\"/>\n",
       "      <use x=\"122.216797\" xlink:href=\"#ArialMT-116\"/>\n",
       "      <use x=\"150\" xlink:href=\"#ArialMT-104\"/>\n",
       "      <use x=\"205.615234\" xlink:href=\"#ArialMT-32\"/>\n",
       "      <use x=\"233.398438\" xlink:href=\"#ArialMT-82\"/>\n",
       "      <use x=\"305.615234\" xlink:href=\"#ArialMT-97\"/>\n",
       "      <use x=\"361.230469\" xlink:href=\"#ArialMT-116\"/>\n",
       "      <use x=\"389.013672\" xlink:href=\"#ArialMT-101\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_13\">\n",
       "    <path clip-path=\"url(#p59f17a537d)\" d=\"M 64.199347 36.76108 \n",
       "L 71.077621 37.902597 \n",
       "L 77.955895 39.096001 \n",
       "L 84.834169 40.25049 \n",
       "L 91.712444 41.288233 \n",
       "L 98.590718 42.053568 \n",
       "L 105.468992 42.377863 \n",
       "L 112.347266 42.274089 \n",
       "L 119.225541 41.794133 \n",
       "L 126.103815 41.054741 \n",
       "L 132.982089 40.25049 \n",
       "L 139.860364 39.588929 \n",
       "L 146.738638 39.329493 \n",
       "L 153.616912 39.627844 \n",
       "L 160.495186 40.6137 \n",
       "L 167.373461 42.261117 \n",
       "L 174.251735 44.492264 \n",
       "L 181.130009 47.138509 \n",
       "L 188.008283 50.134991 \n",
       "L 194.886558 53.533599 \n",
       "L 201.764832 57.412163 \n",
       "L 208.643106 61.88743 \n",
       "L 215.52138 67.102088 \n",
       "L 222.399655 73.172884 \n",
       "L 229.277929 80.19062 \n",
       "L 236.156203 88.453648 \n",
       "L 243.034478 98.338149 \n",
       "L 249.912752 109.753321 \n",
       "L 256.791026 122.322982 \n",
       "L 263.6693 135.502317 \n",
       "L 270.547575 148.266554 \n",
       "L 277.425849 159.448234 \n",
       "L 284.304123 168.307964 \n",
       "L 291.182397 174.443619 \n",
       "L 298.060672 177.842227 \n",
       "L 304.938946 178.931857 \n",
       "L 311.81722 178.542704 \n",
       "L 318.695495 177.816284 \n",
       "L 325.573769 177.725481 \n",
       "L 332.452043 178.724309 \n",
       "L 339.330317 180.994371 \n",
       "L 346.208592 184.367036 \n",
       "L 353.086866 188.375318 \n",
       "L 359.96514 192.694922 \n",
       "L 366.843414 197.390709 \n",
       "L 373.721689 202.670226 \n",
       "L 380.599963 208.844796 \n",
       "L 387.478237 216.108997 \n",
       "L 394.356511 224.566601 \n",
       "L 401.234786 234.113836 \n",
       "L 408.11306 244.67287 \n",
       "L 414.991334 256.07507 \n",
       "L 421.869609 267.957227 \n",
       "L 428.747883 279.865326 \n",
       "L 435.626157 291.449131 \n",
       "L 442.504431 302.267601 \n",
       "L 449.382706 311.931582 \n",
       "L 456.26098 320.324328 \n",
       "L 463.139254 327.432867 \n",
       "L 470.017528 333.27017 \n",
       "\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 43.908438 348.095625 \n",
       "L 43.908438 21.935625 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 490.308437 348.095625 \n",
       "L 490.308437 21.935625 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 43.908437 348.095625 \n",
       "L 490.308437 348.095625 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 43.908437 21.935625 \n",
       "L 490.308437 21.935625 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_15\">\n",
       "    <!-- Birth Rate crude(per 1000 people) -->\n",
       "    <g style=\"fill:#262626;\" transform=\"translate(176.395 15.935625)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path d=\"M 40.4375 19 \n",
       "L 49.078125 17.875 \n",
       "Q 47.65625 8.9375 41.8125 3.875 \n",
       "Q 35.984375 -1.171875 27.484375 -1.171875 \n",
       "Q 16.84375 -1.171875 10.375 5.78125 \n",
       "Q 3.90625 12.75 3.90625 25.734375 \n",
       "Q 3.90625 34.125 6.6875 40.421875 \n",
       "Q 9.46875 46.734375 15.15625 49.875 \n",
       "Q 20.84375 53.03125 27.546875 53.03125 \n",
       "Q 35.984375 53.03125 41.359375 48.75 \n",
       "Q 46.734375 44.484375 48.25 36.625 \n",
       "L 39.703125 35.296875 \n",
       "Q 38.484375 40.53125 35.375 43.15625 \n",
       "Q 32.28125 45.796875 27.875 45.796875 \n",
       "Q 21.234375 45.796875 17.078125 41.03125 \n",
       "Q 12.9375 36.28125 12.9375 25.984375 \n",
       "Q 12.9375 15.53125 16.9375 10.796875 \n",
       "Q 20.953125 6.0625 27.390625 6.0625 \n",
       "Q 32.5625 6.0625 36.03125 9.234375 \n",
       "Q 39.5 12.40625 40.4375 19 \n",
       "z\n",
       "\" id=\"ArialMT-99\"/>\n",
       "      <path d=\"M 40.578125 0 \n",
       "L 40.578125 7.625 \n",
       "Q 34.515625 -1.171875 24.125 -1.171875 \n",
       "Q 19.53125 -1.171875 15.546875 0.578125 \n",
       "Q 11.578125 2.34375 9.640625 5 \n",
       "Q 7.71875 7.671875 6.9375 11.53125 \n",
       "Q 6.390625 14.109375 6.390625 19.734375 \n",
       "L 6.390625 51.859375 \n",
       "L 15.1875 51.859375 \n",
       "L 15.1875 23.09375 \n",
       "Q 15.1875 16.21875 15.71875 13.8125 \n",
       "Q 16.546875 10.359375 19.234375 8.375 \n",
       "Q 21.921875 6.390625 25.875 6.390625 \n",
       "Q 29.828125 6.390625 33.296875 8.421875 \n",
       "Q 36.765625 10.453125 38.203125 13.9375 \n",
       "Q 39.65625 17.4375 39.65625 24.078125 \n",
       "L 39.65625 51.859375 \n",
       "L 48.4375 51.859375 \n",
       "L 48.4375 0 \n",
       "z\n",
       "\" id=\"ArialMT-117\"/>\n",
       "      <path d=\"M 40.234375 0 \n",
       "L 40.234375 6.546875 \n",
       "Q 35.296875 -1.171875 25.734375 -1.171875 \n",
       "Q 19.53125 -1.171875 14.328125 2.25 \n",
       "Q 9.125 5.671875 6.265625 11.796875 \n",
       "Q 3.421875 17.921875 3.421875 25.875 \n",
       "Q 3.421875 33.640625 6 39.96875 \n",
       "Q 8.59375 46.296875 13.765625 49.65625 \n",
       "Q 18.953125 53.03125 25.34375 53.03125 \n",
       "Q 30.03125 53.03125 33.6875 51.046875 \n",
       "Q 37.359375 49.078125 39.65625 45.90625 \n",
       "L 39.65625 71.578125 \n",
       "L 48.390625 71.578125 \n",
       "L 48.390625 0 \n",
       "z\n",
       "M 12.453125 25.875 \n",
       "Q 12.453125 15.921875 16.640625 10.984375 \n",
       "Q 20.84375 6.0625 26.5625 6.0625 \n",
       "Q 32.328125 6.0625 36.34375 10.765625 \n",
       "Q 40.375 15.484375 40.375 25.140625 \n",
       "Q 40.375 35.796875 36.265625 40.765625 \n",
       "Q 32.171875 45.75 26.171875 45.75 \n",
       "Q 20.3125 45.75 16.375 40.96875 \n",
       "Q 12.453125 36.1875 12.453125 25.875 \n",
       "z\n",
       "\" id=\"ArialMT-100\"/>\n",
       "      <path d=\"M 23.390625 -21.046875 \n",
       "Q 16.109375 -11.859375 11.078125 0.4375 \n",
       "Q 6.0625 12.75 6.0625 25.921875 \n",
       "Q 6.0625 37.546875 9.8125 48.1875 \n",
       "Q 14.203125 60.546875 23.390625 72.796875 \n",
       "L 29.6875 72.796875 \n",
       "Q 23.78125 62.640625 21.875 58.296875 \n",
       "Q 18.890625 51.5625 17.1875 44.234375 \n",
       "Q 15.09375 35.109375 15.09375 25.875 \n",
       "Q 15.09375 2.390625 29.6875 -21.046875 \n",
       "z\n",
       "\" id=\"ArialMT-40\"/>\n",
       "      <path d=\"M 6.59375 -19.875 \n",
       "L 6.59375 51.859375 \n",
       "L 14.59375 51.859375 \n",
       "L 14.59375 45.125 \n",
       "Q 17.4375 49.078125 21 51.046875 \n",
       "Q 24.5625 53.03125 29.640625 53.03125 \n",
       "Q 36.28125 53.03125 41.359375 49.609375 \n",
       "Q 46.4375 46.1875 49.015625 39.953125 \n",
       "Q 51.609375 33.734375 51.609375 26.3125 \n",
       "Q 51.609375 18.359375 48.75 11.984375 \n",
       "Q 45.90625 5.609375 40.453125 2.21875 \n",
       "Q 35.015625 -1.171875 29 -1.171875 \n",
       "Q 24.609375 -1.171875 21.109375 0.6875 \n",
       "Q 17.625 2.546875 15.375 5.375 \n",
       "L 15.375 -19.875 \n",
       "z\n",
       "M 14.546875 25.640625 \n",
       "Q 14.546875 15.625 18.59375 10.84375 \n",
       "Q 22.65625 6.0625 28.421875 6.0625 \n",
       "Q 34.28125 6.0625 38.453125 11.015625 \n",
       "Q 42.625 15.96875 42.625 26.375 \n",
       "Q 42.625 36.28125 38.546875 41.203125 \n",
       "Q 34.46875 46.140625 28.8125 46.140625 \n",
       "Q 23.1875 46.140625 18.859375 40.890625 \n",
       "Q 14.546875 35.640625 14.546875 25.640625 \n",
       "z\n",
       "\" id=\"ArialMT-112\"/>\n",
       "      <path d=\"M 3.328125 25.921875 \n",
       "Q 3.328125 40.328125 11.328125 47.265625 \n",
       "Q 18.015625 53.03125 27.640625 53.03125 \n",
       "Q 38.328125 53.03125 45.109375 46.015625 \n",
       "Q 51.90625 39.015625 51.90625 26.65625 \n",
       "Q 51.90625 16.65625 48.90625 10.90625 \n",
       "Q 45.90625 5.171875 40.15625 2 \n",
       "Q 34.421875 -1.171875 27.640625 -1.171875 \n",
       "Q 16.75 -1.171875 10.03125 5.8125 \n",
       "Q 3.328125 12.796875 3.328125 25.921875 \n",
       "z\n",
       "M 12.359375 25.921875 \n",
       "Q 12.359375 15.96875 16.703125 11.015625 \n",
       "Q 21.046875 6.0625 27.640625 6.0625 \n",
       "Q 34.1875 6.0625 38.53125 11.03125 \n",
       "Q 42.875 16.015625 42.875 26.21875 \n",
       "Q 42.875 35.84375 38.5 40.796875 \n",
       "Q 34.125 45.75 27.640625 45.75 \n",
       "Q 21.046875 45.75 16.703125 40.8125 \n",
       "Q 12.359375 35.890625 12.359375 25.921875 \n",
       "z\n",
       "\" id=\"ArialMT-111\"/>\n",
       "      <path d=\"M 6.390625 0 \n",
       "L 6.390625 71.578125 \n",
       "L 15.1875 71.578125 \n",
       "L 15.1875 0 \n",
       "z\n",
       "\" id=\"ArialMT-108\"/>\n",
       "      <path d=\"M 12.359375 -21.046875 \n",
       "L 6.0625 -21.046875 \n",
       "Q 20.65625 2.390625 20.65625 25.875 \n",
       "Q 20.65625 35.0625 18.5625 44.09375 \n",
       "Q 16.890625 51.421875 13.921875 58.15625 \n",
       "Q 12.015625 62.546875 6.0625 72.796875 \n",
       "L 12.359375 72.796875 \n",
       "Q 21.53125 60.546875 25.921875 48.1875 \n",
       "Q 29.6875 37.546875 29.6875 25.921875 \n",
       "Q 29.6875 12.75 24.625 0.4375 \n",
       "Q 19.578125 -11.859375 12.359375 -21.046875 \n",
       "z\n",
       "\" id=\"ArialMT-41\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-66\"/>\n",
       "     <use x=\"66.699219\" xlink:href=\"#ArialMT-105\"/>\n",
       "     <use x=\"88.916016\" xlink:href=\"#ArialMT-114\"/>\n",
       "     <use x=\"122.216797\" xlink:href=\"#ArialMT-116\"/>\n",
       "     <use x=\"150\" xlink:href=\"#ArialMT-104\"/>\n",
       "     <use x=\"205.615234\" xlink:href=\"#ArialMT-32\"/>\n",
       "     <use x=\"233.398438\" xlink:href=\"#ArialMT-82\"/>\n",
       "     <use x=\"305.615234\" xlink:href=\"#ArialMT-97\"/>\n",
       "     <use x=\"361.230469\" xlink:href=\"#ArialMT-116\"/>\n",
       "     <use x=\"389.013672\" xlink:href=\"#ArialMT-101\"/>\n",
       "     <use x=\"444.628906\" xlink:href=\"#ArialMT-32\"/>\n",
       "     <use x=\"472.412109\" xlink:href=\"#ArialMT-99\"/>\n",
       "     <use x=\"522.412109\" xlink:href=\"#ArialMT-114\"/>\n",
       "     <use x=\"555.712891\" xlink:href=\"#ArialMT-117\"/>\n",
       "     <use x=\"611.328125\" xlink:href=\"#ArialMT-100\"/>\n",
       "     <use x=\"666.943359\" xlink:href=\"#ArialMT-101\"/>\n",
       "     <use x=\"722.558594\" xlink:href=\"#ArialMT-40\"/>\n",
       "     <use x=\"755.859375\" xlink:href=\"#ArialMT-112\"/>\n",
       "     <use x=\"811.474609\" xlink:href=\"#ArialMT-101\"/>\n",
       "     <use x=\"867.089844\" xlink:href=\"#ArialMT-114\"/>\n",
       "     <use x=\"900.390625\" xlink:href=\"#ArialMT-32\"/>\n",
       "     <use x=\"928.173828\" xlink:href=\"#ArialMT-49\"/>\n",
       "     <use x=\"983.789062\" xlink:href=\"#ArialMT-48\"/>\n",
       "     <use x=\"1039.404297\" xlink:href=\"#ArialMT-48\"/>\n",
       "     <use x=\"1095.019531\" xlink:href=\"#ArialMT-48\"/>\n",
       "     <use x=\"1150.634766\" xlink:href=\"#ArialMT-32\"/>\n",
       "     <use x=\"1178.417969\" xlink:href=\"#ArialMT-112\"/>\n",
       "     <use x=\"1234.033203\" xlink:href=\"#ArialMT-101\"/>\n",
       "     <use x=\"1289.648438\" xlink:href=\"#ArialMT-111\"/>\n",
       "     <use x=\"1345.263672\" xlink:href=\"#ArialMT-112\"/>\n",
       "     <use x=\"1400.878906\" xlink:href=\"#ArialMT-108\"/>\n",
       "     <use x=\"1423.095703\" xlink:href=\"#ArialMT-101\"/>\n",
       "     <use x=\"1478.710938\" xlink:href=\"#ArialMT-41\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p59f17a537d\">\n",
       "   <rect height=\"326.16\" width=\"446.4\" x=\"43.908438\" y=\"21.935625\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualize csv data\n",
    "plt.plot(df['year'],df['value'])\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Birth Rate')\n",
    "plt.title('Birth Rate crude(per 1000 people)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            ----------------------Data Preparation----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year\n",
       "3  2013\n",
       "4  2014\n",
       "5  2015\n",
       "6  2016\n",
       "7  2017\n",
       "8  2018\n",
       "9  2019"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#separate data into training and test datasets as arrays\n",
    "# training_set = df.iloc[:40, 1:2].values\n",
    "# test_set = df.iloc[40:, 1:2].values\n",
    "# test_years=df.loc[43:68, 'year'].values\n",
    "# test_years = np.reshape(test_years, (17,1))\n",
    "\n",
    "years = df.iloc[:, :1]\n",
    "\n",
    "training_data = df[df['year']<2010].copy()\n",
    "mape_training_values = training_data.iloc[3:, 1:].values\n",
    "training_data = training_data.iloc[:, 1:].values\n",
    "test_data = df[df['year']>=2010].copy().reset_index()\n",
    "mape_test_values = test_data.iloc[3:, 2:].values\n",
    "test_years = test_data.iloc[3:, 1:2]\n",
    "test_data = test_data.iloc[:, 2:].values\n",
    " \n",
    "#sliding window used in spliting the sequence\n",
    "lag = 3 \n",
    "\n",
    "#features\n",
    "n_features = 1\n",
    "test_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data set into time steps that predict the next step: X for samples, y for labels (actual output)\n",
    "\n",
    "def split_sequence(sequence, lag):\n",
    "    print(len(sequence))\n",
    "    x, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + lag\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(x), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "Training samples: \n",
      "shape:  (47, 3, 1)\n",
      "[[50.887]\n",
      " [50.807]\n",
      " [50.748]\n",
      " [50.723]\n",
      " [50.731]\n",
      " [50.768]\n",
      " [50.825]\n",
      " [50.887]\n",
      " [50.938]\n",
      " [50.958]\n",
      " [50.935]\n",
      " [50.859]\n",
      " [50.732]\n",
      " [50.56 ]\n",
      " [50.356]\n",
      " [50.125]\n",
      " [49.863]\n",
      " [49.564]\n",
      " [49.219]\n",
      " [48.817]\n",
      " [48.349]\n",
      " [47.808]\n",
      " [47.171]\n",
      " [46.409]\n",
      " [45.529]\n",
      " [44.56 ]\n",
      " [43.544]\n",
      " [42.56 ]\n",
      " [41.698]\n",
      " [41.015]\n",
      " [40.542]\n",
      " [40.28 ]\n",
      " [40.196]\n",
      " [40.226]\n",
      " [40.282]\n",
      " [40.289]\n",
      " [40.212]\n",
      " [40.037]\n",
      " [39.777]\n",
      " [39.468]\n",
      " [39.135]\n",
      " [38.773]\n",
      " [38.366]\n",
      " [37.89 ]\n",
      " [37.33 ]\n",
      " [36.678]\n",
      " [35.942]]\n"
     ]
    }
   ],
   "source": [
    "#prepare the data for training\n",
    "#split into samples and labels\n",
    "x, y = split_sequence(training_data, lag)\n",
    "# x, y = split_sequence(training_set, lag)\n",
    "print('Training samples: ')\n",
    "print('shape: ',x.shape)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Test samples: \n",
      "shape:  (47, 3, 1)\n",
      "[[[35.128]\n",
      "  [34.249]\n",
      "  [33.333]]\n",
      "\n",
      " [[34.249]\n",
      "  [33.333]\n",
      "  [32.415]]\n",
      "\n",
      " [[33.333]\n",
      "  [32.415]\n",
      "  [31.522]]\n",
      "\n",
      " [[32.415]\n",
      "  [31.522]\n",
      "  [30.688]]\n",
      "\n",
      " [[31.522]\n",
      "  [30.688]\n",
      "  [29.943]]\n",
      "\n",
      " [[30.688]\n",
      "  [29.943]\n",
      "  [29.296]]\n",
      "\n",
      " [[29.943]\n",
      "  [29.296]\n",
      "  [28.748]]]\n"
     ]
    }
   ],
   "source": [
    "#Prep the test data\n",
    "x_test, y_test = split_sequence(test_data, lag)\n",
    "print('Test samples: ')\n",
    "print('shape: ',x.shape)\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------Hyperparameter Tuning-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Possible Models 27\n"
     ]
    }
   ],
   "source": [
    "#select possible parameters combination using grid search\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "param_grid = {  \n",
    "    'n_epoch': [20,50,100],\n",
    "    'n_units': [40,50,60],\n",
    "    'n_timesteps':(1,2,3)\n",
    "}\n",
    "\n",
    "\n",
    "grid = ParameterGrid(param_grid)\n",
    "cnt = 0\n",
    "for p in grid:\n",
    "    cnt = cnt+1\n",
    "\n",
    "print('Total Possible Models',cnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use MAPE to determine the combination with the lowest error\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_epoch': 20, 'n_timesteps': 1, 'n_units': 40}\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_12_input'), name='lstm_12_input', description=\"created by layer 'lstm_12_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_12_input'), name='lstm_12_input', description=\"created by layer 'lstm_12_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_12_input'), name='lstm_12_input', description=\"created by layer 'lstm_12_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 425.8438 - accuracy: 0.0000e+00 - val_loss: 2.2785 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "42/42 - 0s - loss: 4.0375 - accuracy: 0.0000e+00 - val_loss: 0.2368 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "42/42 - 0s - loss: 0.9776 - accuracy: 0.0000e+00 - val_loss: 0.9750 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "42/42 - 0s - loss: 1.0476 - accuracy: 0.0000e+00 - val_loss: 1.8856 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "42/42 - 0s - loss: 1.6800 - accuracy: 0.0000e+00 - val_loss: 0.0429 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "42/42 - 0s - loss: 1.9068 - accuracy: 0.0000e+00 - val_loss: 1.0800 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "42/42 - 0s - loss: 1.8180 - accuracy: 0.0000e+00 - val_loss: 0.3189 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "42/42 - 0s - loss: 1.8759 - accuracy: 0.0000e+00 - val_loss: 0.3168 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "42/42 - 0s - loss: 2.2703 - accuracy: 0.0000e+00 - val_loss: 1.4282 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "42/42 - 0s - loss: 2.3843 - accuracy: 0.0000e+00 - val_loss: 4.8350 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "42/42 - 0s - loss: 2.4442 - accuracy: 0.0000e+00 - val_loss: 0.6090 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "42/42 - 0s - loss: 2.2514 - accuracy: 0.0000e+00 - val_loss: 1.4876 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "42/42 - 0s - loss: 2.1396 - accuracy: 0.0000e+00 - val_loss: 0.3413 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "42/42 - 0s - loss: 1.7738 - accuracy: 0.0000e+00 - val_loss: 0.0633 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "42/42 - 0s - loss: 2.4482 - accuracy: 0.0000e+00 - val_loss: 0.2390 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "42/42 - 0s - loss: 1.7298 - accuracy: 0.0000e+00 - val_loss: 0.4684 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "42/42 - 0s - loss: 2.8439 - accuracy: 0.0000e+00 - val_loss: 1.4073 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "42/42 - 0s - loss: 1.2579 - accuracy: 0.0000e+00 - val_loss: 0.1429 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "42/42 - 0s - loss: 3.4454 - accuracy: 0.0000e+00 - val_loss: 3.2395 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "42/42 - 0s - loss: 4.3924 - accuracy: 0.0000e+00 - val_loss: 0.5002 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_12_input'), name='lstm_12_input', description=\"created by layer 'lstm_12_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 2.927389953273544\n",
      "Test MAPE------------------- 1.0647113605562653\n",
      "{'n_epoch': 20, 'n_timesteps': 1, 'n_units': 50}\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_15_input'), name='lstm_15_input', description=\"created by layer 'lstm_15_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_15_input'), name='lstm_15_input', description=\"created by layer 'lstm_15_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_15_input'), name='lstm_15_input', description=\"created by layer 'lstm_15_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 204.1389 - accuracy: 0.0000e+00 - val_loss: 0.0588 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "42/42 - 0s - loss: 1.2205 - accuracy: 0.0000e+00 - val_loss: 0.5815 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "42/42 - 0s - loss: 1.6462 - accuracy: 0.0000e+00 - val_loss: 2.5487 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "42/42 - 0s - loss: 1.5906 - accuracy: 0.0000e+00 - val_loss: 0.3295 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "42/42 - 0s - loss: 2.3063 - accuracy: 0.0000e+00 - val_loss: 0.0738 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "42/42 - 0s - loss: 2.9555 - accuracy: 0.0000e+00 - val_loss: 1.3379 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "42/42 - 0s - loss: 3.3812 - accuracy: 0.0000e+00 - val_loss: 0.0631 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "42/42 - 0s - loss: 5.2145 - accuracy: 0.0000e+00 - val_loss: 0.9680 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "42/42 - 0s - loss: 3.2824 - accuracy: 0.0000e+00 - val_loss: 0.1398 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "42/42 - 0s - loss: 3.2372 - accuracy: 0.0000e+00 - val_loss: 7.4402 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "42/42 - 0s - loss: 3.0958 - accuracy: 0.0000e+00 - val_loss: 0.2893 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "42/42 - 0s - loss: 3.2211 - accuracy: 0.0000e+00 - val_loss: 2.8431 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "42/42 - 0s - loss: 5.1620 - accuracy: 0.0000e+00 - val_loss: 2.0415 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "42/42 - 0s - loss: 3.0093 - accuracy: 0.0000e+00 - val_loss: 0.7193 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "42/42 - 0s - loss: 1.8939 - accuracy: 0.0000e+00 - val_loss: 0.0911 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "42/42 - 0s - loss: 2.7321 - accuracy: 0.0000e+00 - val_loss: 0.5977 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "42/42 - 0s - loss: 6.4327 - accuracy: 0.0000e+00 - val_loss: 1.8359 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "42/42 - 0s - loss: 5.1061 - accuracy: 0.0000e+00 - val_loss: 2.2979 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "42/42 - 0s - loss: 3.6530 - accuracy: 0.0000e+00 - val_loss: 0.3868 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "42/42 - 0s - loss: 2.7690 - accuracy: 0.0000e+00 - val_loss: 1.3702 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_15_input'), name='lstm_15_input', description=\"created by layer 'lstm_15_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 2.80271838868835\n",
      "Test MAPE------------------- 3.4364012195236424\n",
      "{'n_epoch': 20, 'n_timesteps': 1, 'n_units': 60}\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_18_input'), name='lstm_18_input', description=\"created by layer 'lstm_18_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_18_input'), name='lstm_18_input', description=\"created by layer 'lstm_18_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_18_input'), name='lstm_18_input', description=\"created by layer 'lstm_18_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 158.2835 - accuracy: 0.0000e+00 - val_loss: 0.0763 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "42/42 - 0s - loss: 2.5071 - accuracy: 0.0000e+00 - val_loss: 0.5632 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "42/42 - 0s - loss: 5.4298 - accuracy: 0.0000e+00 - val_loss: 1.0499 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "42/42 - 0s - loss: 7.4258 - accuracy: 0.0000e+00 - val_loss: 1.8925 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "42/42 - 0s - loss: 13.5756 - accuracy: 0.0000e+00 - val_loss: 3.7761 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "42/42 - 0s - loss: 3.9397 - accuracy: 0.0000e+00 - val_loss: 0.8225 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "42/42 - 0s - loss: 2.6952 - accuracy: 0.0000e+00 - val_loss: 0.6906 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "42/42 - 0s - loss: 4.5304 - accuracy: 0.0000e+00 - val_loss: 3.0432 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "42/42 - 0s - loss: 2.4591 - accuracy: 0.0000e+00 - val_loss: 2.1091 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "42/42 - 0s - loss: 1.8524 - accuracy: 0.0000e+00 - val_loss: 0.0662 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "42/42 - 0s - loss: 4.1426 - accuracy: 0.0000e+00 - val_loss: 8.4315 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "42/42 - 0s - loss: 8.6676 - accuracy: 0.0000e+00 - val_loss: 0.5014 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "42/42 - 0s - loss: 1.8347 - accuracy: 0.0000e+00 - val_loss: 0.5794 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "42/42 - 0s - loss: 2.6961 - accuracy: 0.0000e+00 - val_loss: 0.1419 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "42/42 - 0s - loss: 4.2242 - accuracy: 0.0000e+00 - val_loss: 2.4207 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "42/42 - 0s - loss: 4.6236 - accuracy: 0.0000e+00 - val_loss: 1.5209 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "42/42 - 0s - loss: 1.5279 - accuracy: 0.0000e+00 - val_loss: 2.8744 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "42/42 - 0s - loss: 2.5786 - accuracy: 0.0000e+00 - val_loss: 10.0369 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "42/42 - 0s - loss: 9.0304 - accuracy: 0.0000e+00 - val_loss: 2.2149 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "42/42 - 0s - loss: 1.4208 - accuracy: 0.0000e+00 - val_loss: 2.4043 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_18_input'), name='lstm_18_input', description=\"created by layer 'lstm_18_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 3.790402234482519\n",
      "Test MAPE------------------- 4.835856529679413\n",
      "{'n_epoch': 20, 'n_timesteps': 2, 'n_units': 40}\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_21_input'), name='lstm_21_input', description=\"created by layer 'lstm_21_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_21_input'), name='lstm_21_input', description=\"created by layer 'lstm_21_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_21_input'), name='lstm_21_input', description=\"created by layer 'lstm_21_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 380.6433 - accuracy: 0.0000e+00 - val_loss: 1.6000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "42/42 - 0s - loss: 1.2336 - accuracy: 0.0000e+00 - val_loss: 1.1680 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "42/42 - 0s - loss: 1.4121 - accuracy: 0.0000e+00 - val_loss: 0.2128 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "42/42 - 0s - loss: 1.2405 - accuracy: 0.0000e+00 - val_loss: 1.0425 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "42/42 - 0s - loss: 1.4301 - accuracy: 0.0000e+00 - val_loss: 1.8145 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "42/42 - 0s - loss: 1.1210 - accuracy: 0.0000e+00 - val_loss: 0.2350 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "42/42 - 0s - loss: 0.9772 - accuracy: 0.0000e+00 - val_loss: 2.3646 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "42/42 - 0s - loss: 1.7959 - accuracy: 0.0000e+00 - val_loss: 1.1327 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "42/42 - 0s - loss: 1.7811 - accuracy: 0.0000e+00 - val_loss: 2.2001 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "42/42 - 0s - loss: 1.8465 - accuracy: 0.0000e+00 - val_loss: 1.2099 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "42/42 - 0s - loss: 2.3198 - accuracy: 0.0000e+00 - val_loss: 0.1165 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "42/42 - 0s - loss: 1.9141 - accuracy: 0.0000e+00 - val_loss: 0.0907 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "42/42 - 0s - loss: 2.3537 - accuracy: 0.0000e+00 - val_loss: 2.7182 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "42/42 - 0s - loss: 1.9293 - accuracy: 0.0000e+00 - val_loss: 0.0711 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "42/42 - 0s - loss: 1.5063 - accuracy: 0.0000e+00 - val_loss: 3.3317 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "42/42 - 0s - loss: 1.4935 - accuracy: 0.0000e+00 - val_loss: 2.3522 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "42/42 - 0s - loss: 1.7387 - accuracy: 0.0000e+00 - val_loss: 0.4310 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "42/42 - 0s - loss: 2.5526 - accuracy: 0.0000e+00 - val_loss: 1.0407 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "42/42 - 0s - loss: 3.2790 - accuracy: 0.0000e+00 - val_loss: 2.3915 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "42/42 - 0s - loss: 2.7837 - accuracy: 0.0000e+00 - val_loss: 0.8566 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_21_input'), name='lstm_21_input', description=\"created by layer 'lstm_21_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 1.6013100029729868\n",
      "Test MAPE------------------- 4.263025440731183\n",
      "{'n_epoch': 20, 'n_timesteps': 2, 'n_units': 50}\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_24_input'), name='lstm_24_input', description=\"created by layer 'lstm_24_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_24_input'), name='lstm_24_input', description=\"created by layer 'lstm_24_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_24_input'), name='lstm_24_input', description=\"created by layer 'lstm_24_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 268.8817 - accuracy: 0.0000e+00 - val_loss: 5.5439 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "42/42 - 0s - loss: 5.2788 - accuracy: 0.0000e+00 - val_loss: 2.1667 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "42/42 - 0s - loss: 2.8013 - accuracy: 0.0000e+00 - val_loss: 1.3001 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "42/42 - 0s - loss: 1.5992 - accuracy: 0.0000e+00 - val_loss: 0.0558 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "42/42 - 0s - loss: 2.7003 - accuracy: 0.0000e+00 - val_loss: 2.6775 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "42/42 - 0s - loss: 5.7947 - accuracy: 0.0000e+00 - val_loss: 18.4247 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "42/42 - 0s - loss: 7.8516 - accuracy: 0.0000e+00 - val_loss: 0.0471 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "42/42 - 0s - loss: 2.4274 - accuracy: 0.0000e+00 - val_loss: 0.0665 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "42/42 - 0s - loss: 6.3173 - accuracy: 0.0000e+00 - val_loss: 1.7782 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "42/42 - 0s - loss: 5.7576 - accuracy: 0.0000e+00 - val_loss: 0.1583 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "42/42 - 0s - loss: 2.8233 - accuracy: 0.0000e+00 - val_loss: 2.3282 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "42/42 - 0s - loss: 2.1628 - accuracy: 0.0000e+00 - val_loss: 4.2740 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "42/42 - 0s - loss: 4.3093 - accuracy: 0.0000e+00 - val_loss: 0.1701 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "42/42 - 0s - loss: 2.0365 - accuracy: 0.0000e+00 - val_loss: 4.1453 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "42/42 - 0s - loss: 3.3877 - accuracy: 0.0000e+00 - val_loss: 0.1103 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "42/42 - 0s - loss: 2.8778 - accuracy: 0.0000e+00 - val_loss: 0.2899 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "42/42 - 0s - loss: 6.2969 - accuracy: 0.0000e+00 - val_loss: 0.9065 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "42/42 - 0s - loss: 4.5809 - accuracy: 0.0000e+00 - val_loss: 1.8356 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "42/42 - 0s - loss: 1.9201 - accuracy: 0.0000e+00 - val_loss: 0.8092 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "42/42 - 0s - loss: 2.5548 - accuracy: 0.0000e+00 - val_loss: 1.1003 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_24_input'), name='lstm_24_input', description=\"created by layer 'lstm_24_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 1.7466824592718078\n",
      "Test MAPE------------------- 4.435807546953057\n",
      "{'n_epoch': 20, 'n_timesteps': 2, 'n_units': 60}\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_27_input'), name='lstm_27_input', description=\"created by layer 'lstm_27_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_27_input'), name='lstm_27_input', description=\"created by layer 'lstm_27_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_27_input'), name='lstm_27_input', description=\"created by layer 'lstm_27_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 243.4094 - accuracy: 0.0000e+00 - val_loss: 9.8188 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "42/42 - 0s - loss: 7.8480 - accuracy: 0.0000e+00 - val_loss: 0.9779 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "42/42 - 0s - loss: 5.3647 - accuracy: 0.0000e+00 - val_loss: 0.1070 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "42/42 - 0s - loss: 3.7005 - accuracy: 0.0000e+00 - val_loss: 14.3721 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "42/42 - 0s - loss: 4.0901 - accuracy: 0.0000e+00 - val_loss: 3.7017 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "42/42 - 0s - loss: 4.1240 - accuracy: 0.0000e+00 - val_loss: 0.6847 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "42/42 - 0s - loss: 4.6689 - accuracy: 0.0000e+00 - val_loss: 2.0914 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "42/42 - 0s - loss: 3.9027 - accuracy: 0.0000e+00 - val_loss: 0.0434 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "42/42 - 0s - loss: 2.4533 - accuracy: 0.0000e+00 - val_loss: 0.3232 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "42/42 - 0s - loss: 2.6704 - accuracy: 0.0000e+00 - val_loss: 0.4950 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "42/42 - 0s - loss: 1.8905 - accuracy: 0.0000e+00 - val_loss: 0.6509 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "42/42 - 0s - loss: 3.4889 - accuracy: 0.0000e+00 - val_loss: 0.0760 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "42/42 - 0s - loss: 2.2463 - accuracy: 0.0000e+00 - val_loss: 1.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "42/42 - 0s - loss: 1.3602 - accuracy: 0.0000e+00 - val_loss: 0.8931 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "42/42 - 0s - loss: 4.6402 - accuracy: 0.0000e+00 - val_loss: 14.6120 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "42/42 - 0s - loss: 3.8354 - accuracy: 0.0000e+00 - val_loss: 3.4381 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "42/42 - 0s - loss: 5.8538 - accuracy: 0.0000e+00 - val_loss: 0.5074 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "42/42 - 0s - loss: 3.5707 - accuracy: 0.0000e+00 - val_loss: 1.3070 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "42/42 - 0s - loss: 4.5258 - accuracy: 0.0000e+00 - val_loss: 1.4390 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "42/42 - 0s - loss: 1.9240 - accuracy: 0.0000e+00 - val_loss: 0.0811 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_27_input'), name='lstm_27_input', description=\"created by layer 'lstm_27_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 1.5774998776479179\n",
      "Test MAPE------------------- 1.9510382945036358\n",
      "{'n_epoch': 20, 'n_timesteps': 3, 'n_units': 40}\n",
      "Epoch 1/20\n",
      "42/42 - 2s - loss: 263.1209 - accuracy: 0.0000e+00 - val_loss: 6.6867 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "42/42 - 0s - loss: 2.5553 - accuracy: 0.0000e+00 - val_loss: 0.3382 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "42/42 - 0s - loss: 1.3686 - accuracy: 0.0000e+00 - val_loss: 0.4279 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "42/42 - 0s - loss: 1.7743 - accuracy: 0.0000e+00 - val_loss: 0.1389 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "42/42 - 0s - loss: 1.7638 - accuracy: 0.0000e+00 - val_loss: 1.3264 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "42/42 - 0s - loss: 5.3733 - accuracy: 0.0000e+00 - val_loss: 1.3310 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "42/42 - 0s - loss: 2.0966 - accuracy: 0.0000e+00 - val_loss: 2.6108 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "42/42 - 0s - loss: 2.3359 - accuracy: 0.0000e+00 - val_loss: 3.4573 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "42/42 - 0s - loss: 1.7135 - accuracy: 0.0000e+00 - val_loss: 0.2406 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "42/42 - 0s - loss: 1.0932 - accuracy: 0.0000e+00 - val_loss: 3.6396 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "42/42 - 0s - loss: 5.5012 - accuracy: 0.0000e+00 - val_loss: 5.0953 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "42/42 - 0s - loss: 2.3323 - accuracy: 0.0000e+00 - val_loss: 0.8775 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "42/42 - 0s - loss: 5.9549 - accuracy: 0.0000e+00 - val_loss: 1.4716 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "42/42 - 0s - loss: 3.4593 - accuracy: 0.0000e+00 - val_loss: 0.5085 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "42/42 - 0s - loss: 1.8284 - accuracy: 0.0000e+00 - val_loss: 1.9276 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "42/42 - 0s - loss: 2.6469 - accuracy: 0.0000e+00 - val_loss: 0.1988 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "42/42 - 0s - loss: 7.2295 - accuracy: 0.0000e+00 - val_loss: 0.1396 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "42/42 - 0s - loss: 3.9990 - accuracy: 0.0000e+00 - val_loss: 2.3906 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "42/42 - 0s - loss: 2.2365 - accuracy: 0.0000e+00 - val_loss: 7.7005 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "42/42 - 0s - loss: 3.4158 - accuracy: 0.0000e+00 - val_loss: 0.1841 - val_accuracy: 0.0000e+00\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 1.557988976199897\n",
      "Test MAPE------------------- 3.0627447432584076\n",
      "{'n_epoch': 20, 'n_timesteps': 3, 'n_units': 50}\n",
      "Epoch 1/20\n",
      "42/42 - 2s - loss: 210.2065 - accuracy: 0.0000e+00 - val_loss: 4.8771 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "42/42 - 0s - loss: 3.5214 - accuracy: 0.0000e+00 - val_loss: 0.1112 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "42/42 - 0s - loss: 2.5379 - accuracy: 0.0000e+00 - val_loss: 0.6143 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "42/42 - 0s - loss: 3.3923 - accuracy: 0.0000e+00 - val_loss: 0.3739 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "42/42 - 0s - loss: 3.0190 - accuracy: 0.0000e+00 - val_loss: 3.3677 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "42/42 - 0s - loss: 4.5405 - accuracy: 0.0000e+00 - val_loss: 2.0010 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "42/42 - 0s - loss: 6.6622 - accuracy: 0.0000e+00 - val_loss: 0.0720 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "42/42 - 0s - loss: 4.1148 - accuracy: 0.0000e+00 - val_loss: 0.4020 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "42/42 - 0s - loss: 8.8878 - accuracy: 0.0000e+00 - val_loss: 4.5795 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "42/42 - 0s - loss: 1.7847 - accuracy: 0.0000e+00 - val_loss: 0.0889 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "42/42 - 0s - loss: 3.8374 - accuracy: 0.0000e+00 - val_loss: 2.4495 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "42/42 - 0s - loss: 3.7094 - accuracy: 0.0000e+00 - val_loss: 0.2571 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "42/42 - 0s - loss: 2.5447 - accuracy: 0.0000e+00 - val_loss: 0.1278 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "42/42 - 0s - loss: 2.6787 - accuracy: 0.0000e+00 - val_loss: 1.7189 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "42/42 - 0s - loss: 5.2549 - accuracy: 0.0000e+00 - val_loss: 3.1536 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "42/42 - 0s - loss: 4.6692 - accuracy: 0.0000e+00 - val_loss: 2.4044 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "42/42 - 0s - loss: 3.6409 - accuracy: 0.0000e+00 - val_loss: 2.5438 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "42/42 - 0s - loss: 3.7956 - accuracy: 0.0000e+00 - val_loss: 0.9461 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "42/42 - 0s - loss: 5.4550 - accuracy: 0.0000e+00 - val_loss: 1.3642 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "42/42 - 0s - loss: 1.6945 - accuracy: 0.0000e+00 - val_loss: 2.7956 - val_accuracy: 0.0000e+00\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 3.6458288970394594\n",
      "Test MAPE------------------- 6.162345767511206\n",
      "{'n_epoch': 20, 'n_timesteps': 3, 'n_units': 60}\n",
      "Epoch 1/20\n",
      "42/42 - 2s - loss: 470.4265 - accuracy: 0.0000e+00 - val_loss: 3.0866 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "42/42 - 0s - loss: 3.4670 - accuracy: 0.0000e+00 - val_loss: 0.2889 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "42/42 - 0s - loss: 1.5795 - accuracy: 0.0000e+00 - val_loss: 0.6384 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "42/42 - 0s - loss: 1.1105 - accuracy: 0.0000e+00 - val_loss: 0.1654 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "42/42 - 0s - loss: 2.0276 - accuracy: 0.0000e+00 - val_loss: 0.1800 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "42/42 - 0s - loss: 0.9865 - accuracy: 0.0000e+00 - val_loss: 0.0737 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "42/42 - 0s - loss: 0.9917 - accuracy: 0.0000e+00 - val_loss: 0.3216 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "42/42 - 0s - loss: 1.1516 - accuracy: 0.0000e+00 - val_loss: 0.7645 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "42/42 - 0s - loss: 1.8713 - accuracy: 0.0000e+00 - val_loss: 0.0649 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "42/42 - 0s - loss: 1.9781 - accuracy: 0.0000e+00 - val_loss: 2.7329 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "42/42 - 0s - loss: 1.1136 - accuracy: 0.0000e+00 - val_loss: 0.3545 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "42/42 - 0s - loss: 2.0556 - accuracy: 0.0000e+00 - val_loss: 0.3866 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "42/42 - 0s - loss: 1.8058 - accuracy: 0.0000e+00 - val_loss: 0.2294 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "42/42 - 0s - loss: 1.4132 - accuracy: 0.0000e+00 - val_loss: 0.6453 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "42/42 - 0s - loss: 1.4486 - accuracy: 0.0000e+00 - val_loss: 0.2307 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "42/42 - 0s - loss: 4.2664 - accuracy: 0.0000e+00 - val_loss: 9.9828 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "42/42 - 0s - loss: 3.7313 - accuracy: 0.0000e+00 - val_loss: 10.8513 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "42/42 - 0s - loss: 3.4593 - accuracy: 0.0000e+00 - val_loss: 1.0175 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "42/42 - 0s - loss: 2.4563 - accuracy: 0.0000e+00 - val_loss: 0.5649 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "42/42 - 0s - loss: 4.0947 - accuracy: 0.0000e+00 - val_loss: 3.7056 - val_accuracy: 0.0000e+00\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 4.292801826960722\n",
      "Test MAPE------------------- 6.793501547625332\n",
      "{'n_epoch': 50, 'n_timesteps': 1, 'n_units': 40}\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_39_input'), name='lstm_39_input', description=\"created by layer 'lstm_39_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_39_input'), name='lstm_39_input', description=\"created by layer 'lstm_39_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_39_input'), name='lstm_39_input', description=\"created by layer 'lstm_39_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 212.5600 - accuracy: 0.0000e+00 - val_loss: 7.0989 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "42/42 - 0s - loss: 7.1954 - accuracy: 0.0000e+00 - val_loss: 2.7711 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "42/42 - 0s - loss: 2.9854 - accuracy: 0.0000e+00 - val_loss: 0.4792 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "42/42 - 0s - loss: 4.8138 - accuracy: 0.0000e+00 - val_loss: 3.8754 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "42/42 - 0s - loss: 3.2636 - accuracy: 0.0000e+00 - val_loss: 0.0974 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "42/42 - 0s - loss: 1.7880 - accuracy: 0.0000e+00 - val_loss: 2.5281 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "42/42 - 0s - loss: 3.0651 - accuracy: 0.0000e+00 - val_loss: 2.6651 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "42/42 - 0s - loss: 3.4254 - accuracy: 0.0000e+00 - val_loss: 0.1510 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "42/42 - 0s - loss: 1.8849 - accuracy: 0.0000e+00 - val_loss: 3.0273 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "42/42 - 0s - loss: 3.4225 - accuracy: 0.0000e+00 - val_loss: 3.8018 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "42/42 - 0s - loss: 1.7749 - accuracy: 0.0000e+00 - val_loss: 0.0824 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "42/42 - 0s - loss: 4.0570 - accuracy: 0.0000e+00 - val_loss: 0.0714 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "42/42 - 0s - loss: 3.4360 - accuracy: 0.0000e+00 - val_loss: 0.2424 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "42/42 - 0s - loss: 4.5382 - accuracy: 0.0000e+00 - val_loss: 1.5272 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "42/42 - 0s - loss: 2.2937 - accuracy: 0.0000e+00 - val_loss: 0.4684 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "42/42 - 0s - loss: 1.9006 - accuracy: 0.0000e+00 - val_loss: 0.0854 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "42/42 - 0s - loss: 1.9498 - accuracy: 0.0000e+00 - val_loss: 1.2406 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "42/42 - 0s - loss: 2.3875 - accuracy: 0.0000e+00 - val_loss: 0.1306 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "42/42 - 0s - loss: 1.7259 - accuracy: 0.0000e+00 - val_loss: 0.0740 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "42/42 - 0s - loss: 3.7266 - accuracy: 0.0000e+00 - val_loss: 0.4981 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "42/42 - 0s - loss: 2.1680 - accuracy: 0.0000e+00 - val_loss: 0.5051 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "42/42 - 0s - loss: 5.7764 - accuracy: 0.0000e+00 - val_loss: 2.6858 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "42/42 - 0s - loss: 2.7356 - accuracy: 0.0000e+00 - val_loss: 0.1715 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "42/42 - 0s - loss: 1.9874 - accuracy: 0.0000e+00 - val_loss: 0.4118 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "42/42 - 0s - loss: 2.0852 - accuracy: 0.0000e+00 - val_loss: 0.0628 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "42/42 - 0s - loss: 2.9923 - accuracy: 0.0000e+00 - val_loss: 0.0812 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "42/42 - 0s - loss: 4.8965 - accuracy: 0.0000e+00 - val_loss: 0.0576 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "42/42 - 0s - loss: 4.1483 - accuracy: 0.0000e+00 - val_loss: 0.9312 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "42/42 - 0s - loss: 2.0033 - accuracy: 0.0000e+00 - val_loss: 0.3770 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "42/42 - 0s - loss: 4.4540 - accuracy: 0.0000e+00 - val_loss: 1.5436 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "42/42 - 0s - loss: 1.4554 - accuracy: 0.0000e+00 - val_loss: 0.2408 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "42/42 - 0s - loss: 3.2062 - accuracy: 0.0000e+00 - val_loss: 0.0608 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "42/42 - 0s - loss: 1.9379 - accuracy: 0.0000e+00 - val_loss: 0.2373 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "42/42 - 0s - loss: 3.1416 - accuracy: 0.0000e+00 - val_loss: 7.9088 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "42/42 - 0s - loss: 3.9862 - accuracy: 0.0000e+00 - val_loss: 0.3571 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "42/42 - 0s - loss: 3.8621 - accuracy: 0.0000e+00 - val_loss: 0.7790 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "42/42 - 0s - loss: 3.1981 - accuracy: 0.0000e+00 - val_loss: 0.2651 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "42/42 - 0s - loss: 1.7549 - accuracy: 0.0000e+00 - val_loss: 0.4125 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "42/42 - 0s - loss: 2.1988 - accuracy: 0.0000e+00 - val_loss: 0.2851 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "42/42 - 0s - loss: 5.5931 - accuracy: 0.0000e+00 - val_loss: 11.8204 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "42/42 - 0s - loss: 2.4889 - accuracy: 0.0000e+00 - val_loss: 0.9859 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "42/42 - 0s - loss: 3.9329 - accuracy: 0.0000e+00 - val_loss: 2.0270 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "42/42 - 0s - loss: 1.8894 - accuracy: 0.0000e+00 - val_loss: 0.2688 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "42/42 - 0s - loss: 2.1188 - accuracy: 0.0000e+00 - val_loss: 3.3801 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "42/42 - 0s - loss: 4.4278 - accuracy: 0.0000e+00 - val_loss: 0.1178 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "42/42 - 0s - loss: 2.8959 - accuracy: 0.0000e+00 - val_loss: 3.3198 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "42/42 - 0s - loss: 2.6390 - accuracy: 0.0000e+00 - val_loss: 2.1409 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "42/42 - 0s - loss: 2.6204 - accuracy: 0.0000e+00 - val_loss: 1.1479 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "42/42 - 0s - loss: 2.4379 - accuracy: 0.0000e+00 - val_loss: 5.3170 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "42/42 - 0s - loss: 4.1183 - accuracy: 0.0000e+00 - val_loss: 0.0748 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_39_input'), name='lstm_39_input', description=\"created by layer 'lstm_39_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 2.0820789398476713\n",
      "Test MAPE------------------- 2.189469501807769\n",
      "{'n_epoch': 50, 'n_timesteps': 1, 'n_units': 50}\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_42_input'), name='lstm_42_input', description=\"created by layer 'lstm_42_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_42_input'), name='lstm_42_input', description=\"created by layer 'lstm_42_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_42_input'), name='lstm_42_input', description=\"created by layer 'lstm_42_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 227.5620 - accuracy: 0.0000e+00 - val_loss: 1.1514 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "42/42 - 0s - loss: 1.1879 - accuracy: 0.0000e+00 - val_loss: 0.0808 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "42/42 - 0s - loss: 1.6130 - accuracy: 0.0000e+00 - val_loss: 2.5861 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "42/42 - 0s - loss: 2.5659 - accuracy: 0.0000e+00 - val_loss: 0.2941 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "42/42 - 0s - loss: 1.8663 - accuracy: 0.0000e+00 - val_loss: 0.0766 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "42/42 - 0s - loss: 2.0207 - accuracy: 0.0000e+00 - val_loss: 0.4993 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "42/42 - 0s - loss: 2.5615 - accuracy: 0.0000e+00 - val_loss: 4.4274 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "42/42 - 0s - loss: 2.8642 - accuracy: 0.0000e+00 - val_loss: 0.1222 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "42/42 - 0s - loss: 1.8867 - accuracy: 0.0000e+00 - val_loss: 2.1901 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "42/42 - 0s - loss: 2.1761 - accuracy: 0.0000e+00 - val_loss: 0.0599 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "42/42 - 0s - loss: 2.6201 - accuracy: 0.0000e+00 - val_loss: 0.9025 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "42/42 - 0s - loss: 1.8909 - accuracy: 0.0000e+00 - val_loss: 8.0804 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "42/42 - 0s - loss: 3.6758 - accuracy: 0.0000e+00 - val_loss: 0.5735 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "42/42 - 0s - loss: 7.8585 - accuracy: 0.0000e+00 - val_loss: 3.2289 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "42/42 - 0s - loss: 4.1473 - accuracy: 0.0000e+00 - val_loss: 0.7862 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "42/42 - 0s - loss: 4.6922 - accuracy: 0.0000e+00 - val_loss: 0.0814 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "42/42 - 0s - loss: 3.3550 - accuracy: 0.0000e+00 - val_loss: 4.4398 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "42/42 - 0s - loss: 4.4132 - accuracy: 0.0000e+00 - val_loss: 10.7692 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "42/42 - 0s - loss: 4.0303 - accuracy: 0.0000e+00 - val_loss: 5.4230 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "42/42 - 0s - loss: 3.0688 - accuracy: 0.0000e+00 - val_loss: 2.0224 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "42/42 - 0s - loss: 2.5890 - accuracy: 0.0000e+00 - val_loss: 0.2441 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "42/42 - 0s - loss: 8.1172 - accuracy: 0.0000e+00 - val_loss: 2.5727 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "42/42 - 0s - loss: 2.1994 - accuracy: 0.0000e+00 - val_loss: 3.1259 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "42/42 - 0s - loss: 8.4682 - accuracy: 0.0000e+00 - val_loss: 1.1983 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "42/42 - 0s - loss: 2.6303 - accuracy: 0.0000e+00 - val_loss: 3.6699 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "42/42 - 0s - loss: 3.4166 - accuracy: 0.0000e+00 - val_loss: 14.6260 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "42/42 - 0s - loss: 4.1092 - accuracy: 0.0000e+00 - val_loss: 2.8322 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "42/42 - 0s - loss: 4.0180 - accuracy: 0.0000e+00 - val_loss: 0.0716 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "42/42 - 0s - loss: 1.7577 - accuracy: 0.0000e+00 - val_loss: 0.7256 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "42/42 - 0s - loss: 7.3148 - accuracy: 0.0000e+00 - val_loss: 2.3533 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "42/42 - 0s - loss: 10.6253 - accuracy: 0.0000e+00 - val_loss: 5.5399 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "42/42 - 0s - loss: 5.4831 - accuracy: 0.0000e+00 - val_loss: 1.1645 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "42/42 - 0s - loss: 1.4861 - accuracy: 0.0000e+00 - val_loss: 0.3082 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "42/42 - 0s - loss: 2.2935 - accuracy: 0.0000e+00 - val_loss: 2.5069 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "42/42 - 0s - loss: 1.8735 - accuracy: 0.0000e+00 - val_loss: 0.1255 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "42/42 - 0s - loss: 1.4511 - accuracy: 0.0000e+00 - val_loss: 0.1040 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "42/42 - 0s - loss: 1.2175 - accuracy: 0.0000e+00 - val_loss: 0.0659 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "42/42 - 0s - loss: 1.6310 - accuracy: 0.0000e+00 - val_loss: 2.1718 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "42/42 - 0s - loss: 5.2057 - accuracy: 0.0000e+00 - val_loss: 5.6559 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "42/42 - 0s - loss: 5.2223 - accuracy: 0.0000e+00 - val_loss: 9.6413 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "42/42 - 0s - loss: 5.0214 - accuracy: 0.0000e+00 - val_loss: 5.1498 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "42/42 - 0s - loss: 4.8347 - accuracy: 0.0000e+00 - val_loss: 1.4317 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "42/42 - 0s - loss: 2.2930 - accuracy: 0.0000e+00 - val_loss: 1.0080 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "42/42 - 0s - loss: 2.5325 - accuracy: 0.0000e+00 - val_loss: 0.1731 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "42/42 - 0s - loss: 2.7426 - accuracy: 0.0000e+00 - val_loss: 1.9745 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "42/42 - 0s - loss: 1.6569 - accuracy: 0.0000e+00 - val_loss: 1.6397 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "42/42 - 0s - loss: 1.6348 - accuracy: 0.0000e+00 - val_loss: 0.1396 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "42/42 - 0s - loss: 3.7558 - accuracy: 0.0000e+00 - val_loss: 4.1362 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "42/42 - 0s - loss: 6.0147 - accuracy: 0.0000e+00 - val_loss: 0.0911 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "42/42 - 0s - loss: 4.1920 - accuracy: 0.0000e+00 - val_loss: 0.5038 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_42_input'), name='lstm_42_input', description=\"created by layer 'lstm_42_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 2.6334986535920044\n",
      "Test MAPE------------------- 0.9267764971563609\n",
      "{'n_epoch': 50, 'n_timesteps': 1, 'n_units': 60}\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_45_input'), name='lstm_45_input', description=\"created by layer 'lstm_45_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_45_input'), name='lstm_45_input', description=\"created by layer 'lstm_45_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_45_input'), name='lstm_45_input', description=\"created by layer 'lstm_45_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 487.1141 - accuracy: 0.0000e+00 - val_loss: 17.2333 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "42/42 - 0s - loss: 4.3517 - accuracy: 0.0000e+00 - val_loss: 0.6339 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "42/42 - 0s - loss: 1.0985 - accuracy: 0.0000e+00 - val_loss: 0.6783 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "42/42 - 0s - loss: 1.3906 - accuracy: 0.0000e+00 - val_loss: 0.1931 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "42/42 - 0s - loss: 2.8930 - accuracy: 0.0000e+00 - val_loss: 0.8935 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "42/42 - 0s - loss: 2.4054 - accuracy: 0.0000e+00 - val_loss: 0.0681 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "42/42 - 0s - loss: 2.2711 - accuracy: 0.0000e+00 - val_loss: 0.1413 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "42/42 - 0s - loss: 2.2816 - accuracy: 0.0000e+00 - val_loss: 1.2921 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "42/42 - 0s - loss: 1.6248 - accuracy: 0.0000e+00 - val_loss: 1.4452 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "42/42 - 0s - loss: 2.4157 - accuracy: 0.0000e+00 - val_loss: 0.9546 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "42/42 - 0s - loss: 2.4029 - accuracy: 0.0000e+00 - val_loss: 8.9923 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "42/42 - 0s - loss: 3.2669 - accuracy: 0.0000e+00 - val_loss: 3.2139 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "42/42 - 0s - loss: 1.5117 - accuracy: 0.0000e+00 - val_loss: 0.8607 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "42/42 - 0s - loss: 2.9155 - accuracy: 0.0000e+00 - val_loss: 1.7284 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "42/42 - 0s - loss: 2.5663 - accuracy: 0.0000e+00 - val_loss: 1.7863 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "42/42 - 0s - loss: 2.1343 - accuracy: 0.0000e+00 - val_loss: 1.0484 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "42/42 - 0s - loss: 1.8447 - accuracy: 0.0000e+00 - val_loss: 0.1690 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "42/42 - 0s - loss: 1.6781 - accuracy: 0.0000e+00 - val_loss: 0.1259 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "42/42 - 0s - loss: 2.8972 - accuracy: 0.0000e+00 - val_loss: 3.2231 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "42/42 - 0s - loss: 7.2636 - accuracy: 0.0000e+00 - val_loss: 0.4915 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "42/42 - 0s - loss: 2.5730 - accuracy: 0.0000e+00 - val_loss: 0.9441 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "42/42 - 0s - loss: 2.6116 - accuracy: 0.0000e+00 - val_loss: 3.2106 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "42/42 - 0s - loss: 2.3484 - accuracy: 0.0000e+00 - val_loss: 0.1202 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "42/42 - 0s - loss: 2.8297 - accuracy: 0.0000e+00 - val_loss: 1.3550 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "42/42 - 0s - loss: 1.4930 - accuracy: 0.0000e+00 - val_loss: 1.6101 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "42/42 - 0s - loss: 2.5818 - accuracy: 0.0000e+00 - val_loss: 0.5394 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "42/42 - 0s - loss: 1.7734 - accuracy: 0.0000e+00 - val_loss: 0.0704 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "42/42 - 0s - loss: 5.0346 - accuracy: 0.0000e+00 - val_loss: 7.9692 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "42/42 - 0s - loss: 3.5556 - accuracy: 0.0000e+00 - val_loss: 0.3841 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "42/42 - 0s - loss: 3.3990 - accuracy: 0.0000e+00 - val_loss: 1.9774 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "42/42 - 0s - loss: 4.6272 - accuracy: 0.0000e+00 - val_loss: 8.4125 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "42/42 - 0s - loss: 4.2450 - accuracy: 0.0000e+00 - val_loss: 0.1467 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "42/42 - 0s - loss: 2.3460 - accuracy: 0.0000e+00 - val_loss: 4.8987 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "42/42 - 0s - loss: 4.7898 - accuracy: 0.0000e+00 - val_loss: 0.6261 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "42/42 - 0s - loss: 2.8644 - accuracy: 0.0000e+00 - val_loss: 1.7994 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "42/42 - 0s - loss: 2.6237 - accuracy: 0.0000e+00 - val_loss: 5.8092 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "42/42 - 0s - loss: 4.0992 - accuracy: 0.0000e+00 - val_loss: 5.5668 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "42/42 - 0s - loss: 3.1516 - accuracy: 0.0000e+00 - val_loss: 0.1071 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "42/42 - 0s - loss: 6.0968 - accuracy: 0.0000e+00 - val_loss: 1.3966 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "42/42 - 0s - loss: 6.5522 - accuracy: 0.0000e+00 - val_loss: 2.8612 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "42/42 - 0s - loss: 3.1271 - accuracy: 0.0000e+00 - val_loss: 0.2607 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "42/42 - 0s - loss: 2.0782 - accuracy: 0.0000e+00 - val_loss: 0.5508 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "42/42 - 0s - loss: 1.7616 - accuracy: 0.0000e+00 - val_loss: 0.2438 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "42/42 - 0s - loss: 4.8075 - accuracy: 0.0000e+00 - val_loss: 4.5007 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "42/42 - 0s - loss: 4.2720 - accuracy: 0.0000e+00 - val_loss: 0.2929 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "42/42 - 0s - loss: 4.6355 - accuracy: 0.0000e+00 - val_loss: 1.7010 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "42/42 - 0s - loss: 5.7974 - accuracy: 0.0000e+00 - val_loss: 0.4592 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "42/42 - 0s - loss: 2.9604 - accuracy: 0.0000e+00 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "42/42 - 0s - loss: 1.7378 - accuracy: 0.0000e+00 - val_loss: 2.8768 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "42/42 - 0s - loss: 2.8290 - accuracy: 0.0000e+00 - val_loss: 0.1562 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_45_input'), name='lstm_45_input', description=\"created by layer 'lstm_45_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 1.5250655211657431\n",
      "Test MAPE------------------- 2.7755943684275945\n",
      "{'n_epoch': 50, 'n_timesteps': 2, 'n_units': 40}\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_48_input'), name='lstm_48_input', description=\"created by layer 'lstm_48_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_48_input'), name='lstm_48_input', description=\"created by layer 'lstm_48_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_48_input'), name='lstm_48_input', description=\"created by layer 'lstm_48_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 147.2165 - accuracy: 0.0000e+00 - val_loss: 6.9081 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "42/42 - 0s - loss: 3.1966 - accuracy: 0.0000e+00 - val_loss: 3.2842 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "42/42 - 0s - loss: 4.9774 - accuracy: 0.0000e+00 - val_loss: 5.6124 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "42/42 - 0s - loss: 3.8380 - accuracy: 0.0000e+00 - val_loss: 0.6882 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "42/42 - 0s - loss: 2.6030 - accuracy: 0.0000e+00 - val_loss: 2.3074 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "42/42 - 0s - loss: 2.4227 - accuracy: 0.0000e+00 - val_loss: 0.1151 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "42/42 - 0s - loss: 2.1060 - accuracy: 0.0000e+00 - val_loss: 1.1882 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "42/42 - 0s - loss: 6.8981 - accuracy: 0.0000e+00 - val_loss: 0.6481 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "42/42 - 0s - loss: 4.2782 - accuracy: 0.0000e+00 - val_loss: 0.6417 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "42/42 - 0s - loss: 4.2854 - accuracy: 0.0000e+00 - val_loss: 0.1841 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "42/42 - 0s - loss: 1.2739 - accuracy: 0.0000e+00 - val_loss: 7.5398 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "42/42 - 0s - loss: 2.8911 - accuracy: 0.0000e+00 - val_loss: 1.3611 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "42/42 - 0s - loss: 2.1663 - accuracy: 0.0000e+00 - val_loss: 0.3938 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "42/42 - 0s - loss: 1.9975 - accuracy: 0.0000e+00 - val_loss: 0.0755 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "42/42 - 0s - loss: 1.6264 - accuracy: 0.0000e+00 - val_loss: 0.4211 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "42/42 - 0s - loss: 2.9697 - accuracy: 0.0000e+00 - val_loss: 0.8477 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "42/42 - 0s - loss: 4.3125 - accuracy: 0.0000e+00 - val_loss: 10.4640 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "42/42 - 0s - loss: 4.8471 - accuracy: 0.0000e+00 - val_loss: 8.5279 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "42/42 - 0s - loss: 5.9392 - accuracy: 0.0000e+00 - val_loss: 13.0324 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "42/42 - 0s - loss: 5.8562 - accuracy: 0.0000e+00 - val_loss: 10.9357 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "42/42 - 0s - loss: 3.4392 - accuracy: 0.0000e+00 - val_loss: 0.2432 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "42/42 - 0s - loss: 4.1697 - accuracy: 0.0000e+00 - val_loss: 0.7131 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "42/42 - 0s - loss: 1.7531 - accuracy: 0.0000e+00 - val_loss: 1.9681 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "42/42 - 0s - loss: 5.7846 - accuracy: 0.0000e+00 - val_loss: 3.0270 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "42/42 - 0s - loss: 6.6907 - accuracy: 0.0000e+00 - val_loss: 1.5425 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "42/42 - 0s - loss: 2.7849 - accuracy: 0.0000e+00 - val_loss: 0.7683 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "42/42 - 0s - loss: 3.2247 - accuracy: 0.0000e+00 - val_loss: 0.3637 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "42/42 - 0s - loss: 5.0531 - accuracy: 0.0000e+00 - val_loss: 0.3398 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "42/42 - 0s - loss: 2.6446 - accuracy: 0.0000e+00 - val_loss: 0.1976 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "42/42 - 0s - loss: 2.4355 - accuracy: 0.0000e+00 - val_loss: 1.0320 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "42/42 - 0s - loss: 2.8248 - accuracy: 0.0000e+00 - val_loss: 0.2185 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "42/42 - 0s - loss: 2.9644 - accuracy: 0.0000e+00 - val_loss: 0.2961 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "42/42 - 0s - loss: 3.6587 - accuracy: 0.0000e+00 - val_loss: 0.1006 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "42/42 - 0s - loss: 1.3284 - accuracy: 0.0000e+00 - val_loss: 0.1775 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "42/42 - 0s - loss: 1.4831 - accuracy: 0.0000e+00 - val_loss: 0.0857 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "42/42 - 0s - loss: 3.1372 - accuracy: 0.0000e+00 - val_loss: 0.3230 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "42/42 - 0s - loss: 3.8744 - accuracy: 0.0000e+00 - val_loss: 0.8248 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "42/42 - 0s - loss: 3.1415 - accuracy: 0.0000e+00 - val_loss: 1.8471 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "42/42 - 0s - loss: 2.2011 - accuracy: 0.0000e+00 - val_loss: 1.2961 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "42/42 - 0s - loss: 2.7994 - accuracy: 0.0000e+00 - val_loss: 3.2545 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "42/42 - 0s - loss: 2.4162 - accuracy: 0.0000e+00 - val_loss: 1.6312 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "42/42 - 0s - loss: 2.3043 - accuracy: 0.0000e+00 - val_loss: 0.3952 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "42/42 - 0s - loss: 3.3884 - accuracy: 0.0000e+00 - val_loss: 1.6619 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "42/42 - 0s - loss: 3.2084 - accuracy: 0.0000e+00 - val_loss: 0.3225 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "42/42 - 0s - loss: 2.2878 - accuracy: 0.0000e+00 - val_loss: 0.7904 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "42/42 - 0s - loss: 2.1312 - accuracy: 0.0000e+00 - val_loss: 0.1872 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "42/42 - 0s - loss: 3.6458 - accuracy: 0.0000e+00 - val_loss: 0.1925 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "42/42 - 0s - loss: 1.1570 - accuracy: 0.0000e+00 - val_loss: 4.2923 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "42/42 - 0s - loss: 4.4453 - accuracy: 0.0000e+00 - val_loss: 0.0935 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "42/42 - 0s - loss: 3.1240 - accuracy: 0.0000e+00 - val_loss: 0.8398 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_48_input'), name='lstm_48_input', description=\"created by layer 'lstm_48_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 3.456287143744221\n",
      "Test MAPE------------------- 1.0650330554441303\n",
      "{'n_epoch': 50, 'n_timesteps': 2, 'n_units': 50}\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_51_input'), name='lstm_51_input', description=\"created by layer 'lstm_51_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_51_input'), name='lstm_51_input', description=\"created by layer 'lstm_51_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_51_input'), name='lstm_51_input', description=\"created by layer 'lstm_51_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 293.1687 - accuracy: 0.0000e+00 - val_loss: 0.0257 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "42/42 - 0s - loss: 1.9255 - accuracy: 0.0000e+00 - val_loss: 2.1154 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "42/42 - 0s - loss: 1.2558 - accuracy: 0.0000e+00 - val_loss: 0.6681 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "42/42 - 0s - loss: 1.2629 - accuracy: 0.0000e+00 - val_loss: 0.0499 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "42/42 - 0s - loss: 1.6711 - accuracy: 0.0000e+00 - val_loss: 0.1963 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "42/42 - 0s - loss: 1.4896 - accuracy: 0.0000e+00 - val_loss: 0.2417 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "42/42 - 0s - loss: 3.2473 - accuracy: 0.0000e+00 - val_loss: 0.5351 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "42/42 - 0s - loss: 1.6700 - accuracy: 0.0000e+00 - val_loss: 0.2394 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "42/42 - 0s - loss: 2.5561 - accuracy: 0.0000e+00 - val_loss: 0.6341 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "42/42 - 0s - loss: 1.2957 - accuracy: 0.0000e+00 - val_loss: 0.9026 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "42/42 - 0s - loss: 1.7539 - accuracy: 0.0000e+00 - val_loss: 0.1247 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "42/42 - 0s - loss: 1.8143 - accuracy: 0.0000e+00 - val_loss: 0.5087 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "42/42 - 0s - loss: 2.5529 - accuracy: 0.0000e+00 - val_loss: 2.4969 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "42/42 - 0s - loss: 1.7561 - accuracy: 0.0000e+00 - val_loss: 0.1120 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "42/42 - 0s - loss: 7.6163 - accuracy: 0.0000e+00 - val_loss: 2.0353 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "42/42 - 0s - loss: 8.7218 - accuracy: 0.0000e+00 - val_loss: 1.7355 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "42/42 - 0s - loss: 5.4644 - accuracy: 0.0000e+00 - val_loss: 8.3757 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "42/42 - 0s - loss: 3.0877 - accuracy: 0.0000e+00 - val_loss: 0.3697 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "42/42 - 0s - loss: 2.2636 - accuracy: 0.0000e+00 - val_loss: 1.3185 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "42/42 - 0s - loss: 4.3951 - accuracy: 0.0000e+00 - val_loss: 0.0550 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "42/42 - 0s - loss: 1.9121 - accuracy: 0.0000e+00 - val_loss: 1.1941 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "42/42 - 0s - loss: 2.2882 - accuracy: 0.0000e+00 - val_loss: 1.4881 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "42/42 - 0s - loss: 1.5636 - accuracy: 0.0000e+00 - val_loss: 0.2178 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "42/42 - 0s - loss: 1.5764 - accuracy: 0.0000e+00 - val_loss: 0.0686 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "42/42 - 0s - loss: 2.0785 - accuracy: 0.0000e+00 - val_loss: 4.1345 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "42/42 - 0s - loss: 2.4389 - accuracy: 0.0000e+00 - val_loss: 2.3545 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "42/42 - 0s - loss: 4.0558 - accuracy: 0.0000e+00 - val_loss: 2.7660 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "42/42 - 0s - loss: 6.6202 - accuracy: 0.0000e+00 - val_loss: 10.7317 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "42/42 - 0s - loss: 3.7632 - accuracy: 0.0000e+00 - val_loss: 0.2441 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "42/42 - 0s - loss: 4.0233 - accuracy: 0.0000e+00 - val_loss: 0.1096 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "42/42 - 0s - loss: 3.8483 - accuracy: 0.0000e+00 - val_loss: 7.9198 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "42/42 - 0s - loss: 9.7368 - accuracy: 0.0000e+00 - val_loss: 20.7661 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "42/42 - 0s - loss: 3.4780 - accuracy: 0.0000e+00 - val_loss: 1.7381 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "42/42 - 0s - loss: 6.3075 - accuracy: 0.0000e+00 - val_loss: 0.3655 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "42/42 - 0s - loss: 3.3482 - accuracy: 0.0000e+00 - val_loss: 3.0823 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "42/42 - 0s - loss: 4.2347 - accuracy: 0.0000e+00 - val_loss: 1.0368 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "42/42 - 0s - loss: 2.8599 - accuracy: 0.0000e+00 - val_loss: 0.1362 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "42/42 - 0s - loss: 1.4500 - accuracy: 0.0000e+00 - val_loss: 1.0181 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "42/42 - 0s - loss: 3.3498 - accuracy: 0.0000e+00 - val_loss: 0.5254 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "42/42 - 0s - loss: 4.2145 - accuracy: 0.0000e+00 - val_loss: 10.3502 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "42/42 - 0s - loss: 2.8617 - accuracy: 0.0000e+00 - val_loss: 1.1186 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "42/42 - 0s - loss: 1.6014 - accuracy: 0.0000e+00 - val_loss: 0.0609 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "42/42 - 0s - loss: 3.9362 - accuracy: 0.0000e+00 - val_loss: 10.1238 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "42/42 - 0s - loss: 4.3091 - accuracy: 0.0000e+00 - val_loss: 4.6817 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "42/42 - 0s - loss: 2.1307 - accuracy: 0.0000e+00 - val_loss: 0.1198 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "42/42 - 0s - loss: 1.6263 - accuracy: 0.0000e+00 - val_loss: 1.1027 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "42/42 - 0s - loss: 3.5492 - accuracy: 0.0000e+00 - val_loss: 0.2969 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "42/42 - 0s - loss: 4.1853 - accuracy: 0.0000e+00 - val_loss: 2.4102 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "42/42 - 0s - loss: 4.8584 - accuracy: 0.0000e+00 - val_loss: 0.2257 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "42/42 - 0s - loss: 1.4454 - accuracy: 0.0000e+00 - val_loss: 2.6754 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_51_input'), name='lstm_51_input', description=\"created by layer 'lstm_51_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 5.356636314612711\n",
      "Test MAPE------------------- 3.535951072965037\n",
      "{'n_epoch': 50, 'n_timesteps': 2, 'n_units': 60}\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_54_input'), name='lstm_54_input', description=\"created by layer 'lstm_54_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_54_input'), name='lstm_54_input', description=\"created by layer 'lstm_54_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_54_input'), name='lstm_54_input', description=\"created by layer 'lstm_54_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 218.2829 - accuracy: 0.0000e+00 - val_loss: 8.2916 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "42/42 - 0s - loss: 2.5923 - accuracy: 0.0000e+00 - val_loss: 0.5116 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "42/42 - 0s - loss: 5.2764 - accuracy: 0.0000e+00 - val_loss: 2.1031 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "42/42 - 0s - loss: 2.9926 - accuracy: 0.0000e+00 - val_loss: 0.7793 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "42/42 - 0s - loss: 3.2847 - accuracy: 0.0000e+00 - val_loss: 0.7240 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "42/42 - 0s - loss: 2.2414 - accuracy: 0.0000e+00 - val_loss: 0.8945 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "42/42 - 0s - loss: 2.4836 - accuracy: 0.0000e+00 - val_loss: 2.9687 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "42/42 - 0s - loss: 4.1908 - accuracy: 0.0000e+00 - val_loss: 1.2063 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "42/42 - 0s - loss: 2.6102 - accuracy: 0.0000e+00 - val_loss: 0.9884 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "42/42 - 0s - loss: 2.7484 - accuracy: 0.0000e+00 - val_loss: 6.0987 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "42/42 - 0s - loss: 6.2017 - accuracy: 0.0000e+00 - val_loss: 0.9516 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "42/42 - 0s - loss: 1.8966 - accuracy: 0.0000e+00 - val_loss: 0.3303 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "42/42 - 0s - loss: 3.4256 - accuracy: 0.0000e+00 - val_loss: 1.6536 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "42/42 - 0s - loss: 9.0274 - accuracy: 0.0000e+00 - val_loss: 0.7207 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "42/42 - 0s - loss: 3.8608 - accuracy: 0.0000e+00 - val_loss: 0.0486 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "42/42 - 0s - loss: 4.3458 - accuracy: 0.0000e+00 - val_loss: 0.0621 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "42/42 - 0s - loss: 1.8284 - accuracy: 0.0000e+00 - val_loss: 2.6670 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "42/42 - 0s - loss: 6.3173 - accuracy: 0.0000e+00 - val_loss: 0.4538 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "42/42 - 0s - loss: 1.7662 - accuracy: 0.0000e+00 - val_loss: 1.1935 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "42/42 - 0s - loss: 2.4684 - accuracy: 0.0000e+00 - val_loss: 1.1954 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "42/42 - 0s - loss: 4.9298 - accuracy: 0.0000e+00 - val_loss: 2.2280 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "42/42 - 0s - loss: 1.9875 - accuracy: 0.0000e+00 - val_loss: 0.2431 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "42/42 - 0s - loss: 5.1313 - accuracy: 0.0000e+00 - val_loss: 5.0888 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "42/42 - 0s - loss: 6.5427 - accuracy: 0.0000e+00 - val_loss: 0.1885 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "42/42 - 0s - loss: 7.5012 - accuracy: 0.0000e+00 - val_loss: 2.6747 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "42/42 - 0s - loss: 4.5185 - accuracy: 0.0000e+00 - val_loss: 8.9793 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "42/42 - 0s - loss: 4.6359 - accuracy: 0.0000e+00 - val_loss: 0.4711 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "42/42 - 0s - loss: 5.7462 - accuracy: 0.0000e+00 - val_loss: 0.1057 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "42/42 - 0s - loss: 2.0033 - accuracy: 0.0000e+00 - val_loss: 0.2239 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "42/42 - 0s - loss: 1.8939 - accuracy: 0.0000e+00 - val_loss: 0.6913 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "42/42 - 0s - loss: 1.6256 - accuracy: 0.0000e+00 - val_loss: 1.3506 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "42/42 - 0s - loss: 2.2395 - accuracy: 0.0000e+00 - val_loss: 0.0854 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "42/42 - 0s - loss: 3.3858 - accuracy: 0.0000e+00 - val_loss: 0.5774 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "42/42 - 0s - loss: 4.8421 - accuracy: 0.0000e+00 - val_loss: 1.2327 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "42/42 - 0s - loss: 2.0771 - accuracy: 0.0000e+00 - val_loss: 0.0772 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "42/42 - 0s - loss: 4.5549 - accuracy: 0.0000e+00 - val_loss: 3.1509 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "42/42 - 0s - loss: 3.1246 - accuracy: 0.0000e+00 - val_loss: 0.1982 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "42/42 - 0s - loss: 1.6780 - accuracy: 0.0000e+00 - val_loss: 0.2911 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "42/42 - 0s - loss: 3.7161 - accuracy: 0.0000e+00 - val_loss: 4.0522 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "42/42 - 0s - loss: 3.1366 - accuracy: 0.0000e+00 - val_loss: 3.9556 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "42/42 - 0s - loss: 2.6331 - accuracy: 0.0000e+00 - val_loss: 3.2716 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "42/42 - 0s - loss: 2.6336 - accuracy: 0.0000e+00 - val_loss: 1.3820 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "42/42 - 0s - loss: 8.8104 - accuracy: 0.0000e+00 - val_loss: 11.7099 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "42/42 - 0s - loss: 3.6181 - accuracy: 0.0000e+00 - val_loss: 0.1679 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "42/42 - 0s - loss: 2.7303 - accuracy: 0.0000e+00 - val_loss: 5.8960 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "42/42 - 0s - loss: 4.1268 - accuracy: 0.0000e+00 - val_loss: 1.7943 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "42/42 - 0s - loss: 2.4183 - accuracy: 0.0000e+00 - val_loss: 6.1437 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "42/42 - 0s - loss: 3.6739 - accuracy: 0.0000e+00 - val_loss: 0.2205 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "42/42 - 0s - loss: 3.0030 - accuracy: 0.0000e+00 - val_loss: 0.4108 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "42/42 - 0s - loss: 2.7798 - accuracy: 0.0000e+00 - val_loss: 0.7508 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_54_input'), name='lstm_54_input', description=\"created by layer 'lstm_54_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 1.4598095223090726\n",
      "Test MAPE------------------- 4.321441322491954\n",
      "{'n_epoch': 50, 'n_timesteps': 3, 'n_units': 40}\n",
      "Epoch 1/50\n",
      "42/42 - 2s - loss: 306.8093 - accuracy: 0.0000e+00 - val_loss: 5.5920 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "42/42 - 0s - loss: 2.7005 - accuracy: 0.0000e+00 - val_loss: 0.0700 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "42/42 - 0s - loss: 1.8081 - accuracy: 0.0000e+00 - val_loss: 1.9979 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "42/42 - 0s - loss: 2.7261 - accuracy: 0.0000e+00 - val_loss: 0.9102 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "42/42 - 0s - loss: 1.1655 - accuracy: 0.0000e+00 - val_loss: 0.9345 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "42/42 - 0s - loss: 4.6599 - accuracy: 0.0000e+00 - val_loss: 2.8683 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "42/42 - 0s - loss: 2.1141 - accuracy: 0.0000e+00 - val_loss: 1.2391 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "42/42 - 0s - loss: 1.5729 - accuracy: 0.0000e+00 - val_loss: 1.0027 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "42/42 - 0s - loss: 1.3336 - accuracy: 0.0000e+00 - val_loss: 0.1722 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "42/42 - 0s - loss: 1.8435 - accuracy: 0.0000e+00 - val_loss: 0.7820 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "42/42 - 0s - loss: 3.5112 - accuracy: 0.0000e+00 - val_loss: 0.0780 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "42/42 - 0s - loss: 2.0323 - accuracy: 0.0000e+00 - val_loss: 0.0774 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "42/42 - 0s - loss: 4.4918 - accuracy: 0.0000e+00 - val_loss: 5.2408 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "42/42 - 0s - loss: 2.7285 - accuracy: 0.0000e+00 - val_loss: 0.6697 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "42/42 - 0s - loss: 2.4308 - accuracy: 0.0000e+00 - val_loss: 0.0786 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "42/42 - 0s - loss: 6.7976 - accuracy: 0.0000e+00 - val_loss: 23.6142 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "42/42 - 0s - loss: 9.2633 - accuracy: 0.0000e+00 - val_loss: 0.5144 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "42/42 - 0s - loss: 1.9628 - accuracy: 0.0000e+00 - val_loss: 0.5434 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "42/42 - 0s - loss: 4.2230 - accuracy: 0.0000e+00 - val_loss: 7.7575 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "42/42 - 0s - loss: 4.7671 - accuracy: 0.0000e+00 - val_loss: 2.4080 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "42/42 - 0s - loss: 2.4759 - accuracy: 0.0000e+00 - val_loss: 1.0912 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "42/42 - 0s - loss: 3.4791 - accuracy: 0.0000e+00 - val_loss: 0.1057 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "42/42 - 0s - loss: 3.3364 - accuracy: 0.0000e+00 - val_loss: 0.1359 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "42/42 - 0s - loss: 1.6510 - accuracy: 0.0000e+00 - val_loss: 0.9809 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "42/42 - 0s - loss: 2.8625 - accuracy: 0.0000e+00 - val_loss: 0.4577 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "42/42 - 0s - loss: 1.8763 - accuracy: 0.0000e+00 - val_loss: 1.2862 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "42/42 - 0s - loss: 3.2957 - accuracy: 0.0000e+00 - val_loss: 2.4099 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "42/42 - 0s - loss: 1.8927 - accuracy: 0.0000e+00 - val_loss: 0.4697 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "42/42 - 0s - loss: 3.8935 - accuracy: 0.0000e+00 - val_loss: 4.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "42/42 - 0s - loss: 1.9028 - accuracy: 0.0000e+00 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "42/42 - 0s - loss: 2.3125 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "42/42 - 0s - loss: 2.7333 - accuracy: 0.0000e+00 - val_loss: 0.8223 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "42/42 - 0s - loss: 3.8969 - accuracy: 0.0000e+00 - val_loss: 0.0623 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "42/42 - 0s - loss: 1.9785 - accuracy: 0.0000e+00 - val_loss: 1.3900 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "42/42 - 0s - loss: 1.1065 - accuracy: 0.0000e+00 - val_loss: 0.0596 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "42/42 - 0s - loss: 4.8846 - accuracy: 0.0000e+00 - val_loss: 0.3828 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "42/42 - 0s - loss: 4.4308 - accuracy: 0.0000e+00 - val_loss: 27.4950 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "42/42 - 0s - loss: 9.2564 - accuracy: 0.0000e+00 - val_loss: 2.9956 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "42/42 - 0s - loss: 3.8998 - accuracy: 0.0000e+00 - val_loss: 12.1684 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "42/42 - 0s - loss: 2.9891 - accuracy: 0.0000e+00 - val_loss: 8.7207 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "42/42 - 0s - loss: 4.0301 - accuracy: 0.0000e+00 - val_loss: 0.9675 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "42/42 - 0s - loss: 2.4795 - accuracy: 0.0000e+00 - val_loss: 1.7939 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "42/42 - 0s - loss: 1.3826 - accuracy: 0.0000e+00 - val_loss: 3.0818 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "42/42 - 0s - loss: 3.3731 - accuracy: 0.0000e+00 - val_loss: 1.6372 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "42/42 - 0s - loss: 8.9588 - accuracy: 0.0000e+00 - val_loss: 1.4083 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "42/42 - 0s - loss: 5.9921 - accuracy: 0.0000e+00 - val_loss: 3.3436 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "42/42 - 0s - loss: 2.0186 - accuracy: 0.0000e+00 - val_loss: 0.1051 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "42/42 - 0s - loss: 1.7769 - accuracy: 0.0000e+00 - val_loss: 0.0876 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "42/42 - 0s - loss: 5.1207 - accuracy: 0.0000e+00 - val_loss: 3.0168 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "42/42 - 0s - loss: 3.8502 - accuracy: 0.0000e+00 - val_loss: 0.6119 - val_accuracy: 0.0000e+00\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 1.4220730331900742\n",
      "Test MAPE------------------- 4.279818867628632\n",
      "{'n_epoch': 50, 'n_timesteps': 3, 'n_units': 50}\n",
      "Epoch 1/50\n",
      "42/42 - 2s - loss: 249.3632 - accuracy: 0.0000e+00 - val_loss: 6.2943 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "42/42 - 0s - loss: 3.2143 - accuracy: 0.0000e+00 - val_loss: 1.0203 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "42/42 - 0s - loss: 3.0122 - accuracy: 0.0000e+00 - val_loss: 2.6830 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "42/42 - 0s - loss: 5.4662 - accuracy: 0.0000e+00 - val_loss: 1.6259 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "42/42 - 0s - loss: 5.7255 - accuracy: 0.0000e+00 - val_loss: 1.0453 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "42/42 - 0s - loss: 3.1507 - accuracy: 0.0000e+00 - val_loss: 0.9479 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "42/42 - 0s - loss: 1.6552 - accuracy: 0.0000e+00 - val_loss: 1.2084 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "42/42 - 0s - loss: 1.7967 - accuracy: 0.0000e+00 - val_loss: 0.4769 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "42/42 - 0s - loss: 3.2745 - accuracy: 0.0000e+00 - val_loss: 0.0586 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "42/42 - 0s - loss: 2.1236 - accuracy: 0.0000e+00 - val_loss: 2.5821 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "42/42 - 0s - loss: 1.7981 - accuracy: 0.0000e+00 - val_loss: 0.0585 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "42/42 - 0s - loss: 3.4215 - accuracy: 0.0000e+00 - val_loss: 0.2818 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "42/42 - 0s - loss: 2.6760 - accuracy: 0.0000e+00 - val_loss: 0.6134 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "42/42 - 0s - loss: 4.1813 - accuracy: 0.0000e+00 - val_loss: 0.1874 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "42/42 - 0s - loss: 2.7584 - accuracy: 0.0000e+00 - val_loss: 0.4370 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "42/42 - 0s - loss: 1.6165 - accuracy: 0.0000e+00 - val_loss: 0.8990 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "42/42 - 0s - loss: 1.6872 - accuracy: 0.0000e+00 - val_loss: 1.5768 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "42/42 - 0s - loss: 2.9117 - accuracy: 0.0000e+00 - val_loss: 2.7777 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "42/42 - 0s - loss: 6.1298 - accuracy: 0.0000e+00 - val_loss: 1.0142 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "42/42 - 0s - loss: 3.3081 - accuracy: 0.0000e+00 - val_loss: 0.1594 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "42/42 - 0s - loss: 5.3327 - accuracy: 0.0000e+00 - val_loss: 13.6444 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "42/42 - 0s - loss: 6.7280 - accuracy: 0.0000e+00 - val_loss: 0.9980 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "42/42 - 0s - loss: 1.5363 - accuracy: 0.0000e+00 - val_loss: 0.6057 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "42/42 - 0s - loss: 2.8073 - accuracy: 0.0000e+00 - val_loss: 18.1127 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "42/42 - 0s - loss: 8.6070 - accuracy: 0.0000e+00 - val_loss: 0.0630 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "42/42 - 0s - loss: 4.3151 - accuracy: 0.0000e+00 - val_loss: 13.1274 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "42/42 - 0s - loss: 2.7743 - accuracy: 0.0000e+00 - val_loss: 0.1324 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "42/42 - 0s - loss: 2.0757 - accuracy: 0.0000e+00 - val_loss: 0.5390 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "42/42 - 0s - loss: 5.3495 - accuracy: 0.0000e+00 - val_loss: 0.1798 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "42/42 - 0s - loss: 2.0909 - accuracy: 0.0000e+00 - val_loss: 1.0887 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "42/42 - 0s - loss: 3.8978 - accuracy: 0.0000e+00 - val_loss: 0.0605 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "42/42 - 0s - loss: 3.8716 - accuracy: 0.0000e+00 - val_loss: 2.3801 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "42/42 - 0s - loss: 2.3610 - accuracy: 0.0000e+00 - val_loss: 3.8368 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "42/42 - 0s - loss: 5.0017 - accuracy: 0.0000e+00 - val_loss: 0.1481 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "42/42 - 0s - loss: 6.7105 - accuracy: 0.0000e+00 - val_loss: 2.0726 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "42/42 - 0s - loss: 2.2578 - accuracy: 0.0000e+00 - val_loss: 0.6137 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "42/42 - 0s - loss: 5.7249 - accuracy: 0.0000e+00 - val_loss: 0.9472 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "42/42 - 0s - loss: 1.6695 - accuracy: 0.0000e+00 - val_loss: 2.3688 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "42/42 - 0s - loss: 6.3447 - accuracy: 0.0000e+00 - val_loss: 1.2985 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "42/42 - 0s - loss: 1.7916 - accuracy: 0.0000e+00 - val_loss: 0.1176 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "42/42 - 0s - loss: 2.7109 - accuracy: 0.0000e+00 - val_loss: 0.9541 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "42/42 - 0s - loss: 4.8699 - accuracy: 0.0000e+00 - val_loss: 2.6094 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "42/42 - 0s - loss: 4.0452 - accuracy: 0.0000e+00 - val_loss: 2.0709 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "42/42 - 0s - loss: 2.1661 - accuracy: 0.0000e+00 - val_loss: 0.2484 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "42/42 - 0s - loss: 1.1599 - accuracy: 0.0000e+00 - val_loss: 0.9401 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "42/42 - 0s - loss: 2.4301 - accuracy: 0.0000e+00 - val_loss: 1.1509 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "42/42 - 0s - loss: 2.6883 - accuracy: 0.0000e+00 - val_loss: 0.8238 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "42/42 - 0s - loss: 4.6143 - accuracy: 0.0000e+00 - val_loss: 8.4194 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "42/42 - 0s - loss: 3.2276 - accuracy: 0.0000e+00 - val_loss: 0.0600 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "42/42 - 0s - loss: 1.6308 - accuracy: 0.0000e+00 - val_loss: 0.0877 - val_accuracy: 0.0000e+00\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 1.2574997591380914\n",
      "Test MAPE------------------- 1.7955856813297053\n",
      "{'n_epoch': 50, 'n_timesteps': 3, 'n_units': 60}\n",
      "Epoch 1/50\n",
      "42/42 - 2s - loss: 249.5104 - accuracy: 0.0000e+00 - val_loss: 1.6762 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "42/42 - 0s - loss: 1.5269 - accuracy: 0.0000e+00 - val_loss: 0.2908 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "42/42 - 0s - loss: 3.1377 - accuracy: 0.0000e+00 - val_loss: 0.0958 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "42/42 - 0s - loss: 3.1453 - accuracy: 0.0000e+00 - val_loss: 0.8817 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "42/42 - 0s - loss: 2.3634 - accuracy: 0.0000e+00 - val_loss: 1.7876 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "42/42 - 0s - loss: 3.1494 - accuracy: 0.0000e+00 - val_loss: 1.2110 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "42/42 - 0s - loss: 2.9445 - accuracy: 0.0000e+00 - val_loss: 0.5275 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "42/42 - 0s - loss: 3.1480 - accuracy: 0.0000e+00 - val_loss: 0.1052 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "42/42 - 0s - loss: 1.7230 - accuracy: 0.0000e+00 - val_loss: 0.1621 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "42/42 - 0s - loss: 1.2615 - accuracy: 0.0000e+00 - val_loss: 0.3002 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "42/42 - 0s - loss: 1.6874 - accuracy: 0.0000e+00 - val_loss: 1.4667 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "42/42 - 0s - loss: 2.8955 - accuracy: 0.0000e+00 - val_loss: 0.0821 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "42/42 - 0s - loss: 2.6373 - accuracy: 0.0000e+00 - val_loss: 5.5031 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "42/42 - 0s - loss: 8.5169 - accuracy: 0.0000e+00 - val_loss: 1.0197 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "42/42 - 0s - loss: 4.5189 - accuracy: 0.0000e+00 - val_loss: 0.2655 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "42/42 - 0s - loss: 3.1539 - accuracy: 0.0000e+00 - val_loss: 1.5156 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "42/42 - 0s - loss: 1.9831 - accuracy: 0.0000e+00 - val_loss: 1.0600 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "42/42 - 0s - loss: 4.4137 - accuracy: 0.0000e+00 - val_loss: 2.6465 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "42/42 - 0s - loss: 6.5450 - accuracy: 0.0000e+00 - val_loss: 0.4685 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "42/42 - 0s - loss: 4.3850 - accuracy: 0.0000e+00 - val_loss: 4.5606 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "42/42 - 0s - loss: 2.2234 - accuracy: 0.0000e+00 - val_loss: 0.3562 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "42/42 - 0s - loss: 4.6776 - accuracy: 0.0000e+00 - val_loss: 11.5192 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "42/42 - 0s - loss: 4.2367 - accuracy: 0.0000e+00 - val_loss: 4.6972 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "42/42 - 0s - loss: 12.1501 - accuracy: 0.0000e+00 - val_loss: 0.9138 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "42/42 - 0s - loss: 3.3001 - accuracy: 0.0000e+00 - val_loss: 0.0621 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "42/42 - 0s - loss: 2.3664 - accuracy: 0.0000e+00 - val_loss: 0.0878 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "42/42 - 0s - loss: 1.4585 - accuracy: 0.0000e+00 - val_loss: 3.2156 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "42/42 - 0s - loss: 2.3253 - accuracy: 0.0000e+00 - val_loss: 1.4440 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "42/42 - 0s - loss: 2.8925 - accuracy: 0.0000e+00 - val_loss: 0.9315 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "42/42 - 0s - loss: 1.8613 - accuracy: 0.0000e+00 - val_loss: 0.0497 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "42/42 - 0s - loss: 2.5847 - accuracy: 0.0000e+00 - val_loss: 0.0547 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "42/42 - 0s - loss: 1.2453 - accuracy: 0.0000e+00 - val_loss: 0.4171 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "42/42 - 0s - loss: 3.7719 - accuracy: 0.0000e+00 - val_loss: 0.3085 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "42/42 - 0s - loss: 3.1331 - accuracy: 0.0000e+00 - val_loss: 2.9869 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "42/42 - 0s - loss: 2.9306 - accuracy: 0.0000e+00 - val_loss: 0.8702 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "42/42 - 0s - loss: 5.3969 - accuracy: 0.0000e+00 - val_loss: 1.8938 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "42/42 - 0s - loss: 2.1045 - accuracy: 0.0000e+00 - val_loss: 3.1229 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "42/42 - 0s - loss: 4.0580 - accuracy: 0.0000e+00 - val_loss: 11.8805 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "42/42 - 0s - loss: 2.3851 - accuracy: 0.0000e+00 - val_loss: 0.1555 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "42/42 - 0s - loss: 2.7518 - accuracy: 0.0000e+00 - val_loss: 0.2653 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "42/42 - 0s - loss: 1.4924 - accuracy: 0.0000e+00 - val_loss: 0.2197 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "42/42 - 0s - loss: 8.3240 - accuracy: 0.0000e+00 - val_loss: 11.9616 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "42/42 - 0s - loss: 2.8209 - accuracy: 0.0000e+00 - val_loss: 3.1885 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "42/42 - 0s - loss: 2.0743 - accuracy: 0.0000e+00 - val_loss: 0.9463 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "42/42 - 0s - loss: 3.4641 - accuracy: 0.0000e+00 - val_loss: 0.1545 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "42/42 - 0s - loss: 1.6514 - accuracy: 0.0000e+00 - val_loss: 0.1673 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "42/42 - 0s - loss: 4.9645 - accuracy: 0.0000e+00 - val_loss: 0.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "42/42 - 0s - loss: 1.8193 - accuracy: 0.0000e+00 - val_loss: 3.2907 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "42/42 - 0s - loss: 2.1078 - accuracy: 0.0000e+00 - val_loss: 0.4219 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "42/42 - 0s - loss: 2.0818 - accuracy: 0.0000e+00 - val_loss: 0.0746 - val_accuracy: 0.0000e+00\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 1.6506557003221642\n",
      "Test MAPE------------------- 2.0580457271523582\n",
      "{'n_epoch': 100, 'n_timesteps': 1, 'n_units': 40}\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_66_input'), name='lstm_66_input', description=\"created by layer 'lstm_66_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_66_input'), name='lstm_66_input', description=\"created by layer 'lstm_66_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_66_input'), name='lstm_66_input', description=\"created by layer 'lstm_66_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 233.2389 - accuracy: 0.0000e+00 - val_loss: 5.3347 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "42/42 - 0s - loss: 1.7368 - accuracy: 0.0000e+00 - val_loss: 2.7713 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "42/42 - 0s - loss: 1.4317 - accuracy: 0.0000e+00 - val_loss: 0.7941 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "42/42 - 0s - loss: 2.4887 - accuracy: 0.0000e+00 - val_loss: 8.7468 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "42/42 - 0s - loss: 2.0019 - accuracy: 0.0000e+00 - val_loss: 0.3079 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "42/42 - 0s - loss: 1.8465 - accuracy: 0.0000e+00 - val_loss: 4.4076 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "42/42 - 0s - loss: 4.9806 - accuracy: 0.0000e+00 - val_loss: 1.6893 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "42/42 - 0s - loss: 3.6787 - accuracy: 0.0000e+00 - val_loss: 0.3095 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "42/42 - 0s - loss: 1.5965 - accuracy: 0.0000e+00 - val_loss: 0.1579 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "42/42 - 0s - loss: 1.4167 - accuracy: 0.0000e+00 - val_loss: 0.3499 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "42/42 - 0s - loss: 1.8146 - accuracy: 0.0000e+00 - val_loss: 0.6845 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "42/42 - 0s - loss: 1.7806 - accuracy: 0.0000e+00 - val_loss: 0.0891 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "42/42 - 0s - loss: 1.4712 - accuracy: 0.0000e+00 - val_loss: 0.3575 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "42/42 - 0s - loss: 2.5652 - accuracy: 0.0000e+00 - val_loss: 0.2841 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "42/42 - 0s - loss: 1.5070 - accuracy: 0.0000e+00 - val_loss: 2.2800 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "42/42 - 0s - loss: 1.7461 - accuracy: 0.0000e+00 - val_loss: 1.7935 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "42/42 - 0s - loss: 3.8605 - accuracy: 0.0000e+00 - val_loss: 1.3641 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "42/42 - 0s - loss: 4.2561 - accuracy: 0.0000e+00 - val_loss: 0.2362 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "42/42 - 0s - loss: 2.3612 - accuracy: 0.0000e+00 - val_loss: 1.9618 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "42/42 - 0s - loss: 3.5650 - accuracy: 0.0000e+00 - val_loss: 4.2311 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "42/42 - 0s - loss: 3.5139 - accuracy: 0.0000e+00 - val_loss: 0.2921 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "42/42 - 0s - loss: 2.3355 - accuracy: 0.0000e+00 - val_loss: 1.4346 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "42/42 - 0s - loss: 1.4132 - accuracy: 0.0000e+00 - val_loss: 0.1902 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "42/42 - 0s - loss: 1.5817 - accuracy: 0.0000e+00 - val_loss: 2.4846 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "42/42 - 0s - loss: 1.4107 - accuracy: 0.0000e+00 - val_loss: 0.1730 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "42/42 - 0s - loss: 4.5223 - accuracy: 0.0000e+00 - val_loss: 4.1116 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "42/42 - 0s - loss: 1.3481 - accuracy: 0.0000e+00 - val_loss: 6.3882 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "42/42 - 0s - loss: 2.6244 - accuracy: 0.0000e+00 - val_loss: 0.1257 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "42/42 - 0s - loss: 3.0010 - accuracy: 0.0000e+00 - val_loss: 0.7091 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "42/42 - 0s - loss: 3.1696 - accuracy: 0.0000e+00 - val_loss: 2.5444 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "42/42 - 0s - loss: 3.4775 - accuracy: 0.0000e+00 - val_loss: 3.5014 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "42/42 - 0s - loss: 2.7881 - accuracy: 0.0000e+00 - val_loss: 3.1722 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "42/42 - 0s - loss: 1.5077 - accuracy: 0.0000e+00 - val_loss: 0.0750 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "42/42 - 0s - loss: 2.1557 - accuracy: 0.0000e+00 - val_loss: 2.3559 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "42/42 - 0s - loss: 3.5933 - accuracy: 0.0000e+00 - val_loss: 3.0304 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "42/42 - 0s - loss: 1.5365 - accuracy: 0.0000e+00 - val_loss: 4.8193 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "42/42 - 0s - loss: 6.3387 - accuracy: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "42/42 - 0s - loss: 4.9143 - accuracy: 0.0000e+00 - val_loss: 2.6058 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "42/42 - 0s - loss: 4.0633 - accuracy: 0.0000e+00 - val_loss: 0.0818 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "42/42 - 0s - loss: 2.4570 - accuracy: 0.0000e+00 - val_loss: 2.3524 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "42/42 - 0s - loss: 2.9900 - accuracy: 0.0000e+00 - val_loss: 0.2608 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "42/42 - 0s - loss: 0.9993 - accuracy: 0.0000e+00 - val_loss: 2.5705 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "42/42 - 0s - loss: 1.9912 - accuracy: 0.0000e+00 - val_loss: 4.4281 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "42/42 - 0s - loss: 3.4722 - accuracy: 0.0000e+00 - val_loss: 0.0848 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "42/42 - 0s - loss: 2.9995 - accuracy: 0.0000e+00 - val_loss: 2.6522 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "42/42 - 0s - loss: 2.4204 - accuracy: 0.0000e+00 - val_loss: 4.2745 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "42/42 - 0s - loss: 5.0055 - accuracy: 0.0000e+00 - val_loss: 22.6617 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "42/42 - 0s - loss: 13.0294 - accuracy: 0.0000e+00 - val_loss: 1.8859 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "42/42 - 0s - loss: 4.8173 - accuracy: 0.0000e+00 - val_loss: 2.3759 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "42/42 - 0s - loss: 5.4469 - accuracy: 0.0000e+00 - val_loss: 1.6736 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "42/42 - 0s - loss: 2.7376 - accuracy: 0.0000e+00 - val_loss: 2.2053 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "42/42 - 0s - loss: 4.0473 - accuracy: 0.0000e+00 - val_loss: 9.2065 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "42/42 - 0s - loss: 4.6731 - accuracy: 0.0000e+00 - val_loss: 0.4900 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "42/42 - 0s - loss: 2.1075 - accuracy: 0.0000e+00 - val_loss: 1.2862 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "42/42 - 0s - loss: 3.3274 - accuracy: 0.0000e+00 - val_loss: 0.1085 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "42/42 - 0s - loss: 2.8372 - accuracy: 0.0000e+00 - val_loss: 4.7111 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "42/42 - 0s - loss: 2.6407 - accuracy: 0.0000e+00 - val_loss: 1.8363 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "42/42 - 0s - loss: 2.4147 - accuracy: 0.0000e+00 - val_loss: 1.5633 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "42/42 - 0s - loss: 2.3372 - accuracy: 0.0000e+00 - val_loss: 0.8990 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "42/42 - 0s - loss: 1.5039 - accuracy: 0.0000e+00 - val_loss: 0.8753 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "42/42 - 0s - loss: 2.5203 - accuracy: 0.0000e+00 - val_loss: 1.0498 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "42/42 - 0s - loss: 4.4386 - accuracy: 0.0000e+00 - val_loss: 3.7482 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "42/42 - 0s - loss: 2.4006 - accuracy: 0.0000e+00 - val_loss: 0.8095 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "42/42 - 0s - loss: 3.0371 - accuracy: 0.0000e+00 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "42/42 - 0s - loss: 1.3979 - accuracy: 0.0000e+00 - val_loss: 0.1441 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "42/42 - 0s - loss: 1.5633 - accuracy: 0.0000e+00 - val_loss: 0.2228 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "42/42 - 0s - loss: 1.6579 - accuracy: 0.0000e+00 - val_loss: 0.0845 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "42/42 - 0s - loss: 1.3956 - accuracy: 0.0000e+00 - val_loss: 0.7200 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "42/42 - 0s - loss: 1.1420 - accuracy: 0.0000e+00 - val_loss: 0.4035 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "42/42 - 0s - loss: 2.1248 - accuracy: 0.0000e+00 - val_loss: 0.1723 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "42/42 - 0s - loss: 1.0517 - accuracy: 0.0000e+00 - val_loss: 0.4986 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "42/42 - 0s - loss: 1.8492 - accuracy: 0.0000e+00 - val_loss: 0.7656 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "42/42 - 0s - loss: 2.2291 - accuracy: 0.0000e+00 - val_loss: 1.4629 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "42/42 - 0s - loss: 1.7953 - accuracy: 0.0000e+00 - val_loss: 0.1099 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "42/42 - 0s - loss: 1.2077 - accuracy: 0.0000e+00 - val_loss: 0.1295 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "42/42 - 0s - loss: 1.6370 - accuracy: 0.0000e+00 - val_loss: 1.6724 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "42/42 - 0s - loss: 7.3805 - accuracy: 0.0000e+00 - val_loss: 1.7095 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "42/42 - 0s - loss: 3.3776 - accuracy: 0.0000e+00 - val_loss: 2.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "42/42 - 0s - loss: 1.7093 - accuracy: 0.0000e+00 - val_loss: 4.9551 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "42/42 - 0s - loss: 2.4218 - accuracy: 0.0000e+00 - val_loss: 4.6350 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "42/42 - 0s - loss: 2.7757 - accuracy: 0.0000e+00 - val_loss: 3.9385 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "42/42 - 0s - loss: 1.9105 - accuracy: 0.0000e+00 - val_loss: 0.8849 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "42/42 - 0s - loss: 1.5939 - accuracy: 0.0000e+00 - val_loss: 1.2735 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "42/42 - 0s - loss: 3.1965 - accuracy: 0.0000e+00 - val_loss: 1.8546 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "42/42 - 0s - loss: 3.1985 - accuracy: 0.0000e+00 - val_loss: 1.7782 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "42/42 - 0s - loss: 2.0342 - accuracy: 0.0000e+00 - val_loss: 0.1459 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "42/42 - 0s - loss: 1.9401 - accuracy: 0.0000e+00 - val_loss: 0.2060 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "42/42 - 0s - loss: 1.7711 - accuracy: 0.0000e+00 - val_loss: 0.0834 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "42/42 - 0s - loss: 1.9744 - accuracy: 0.0000e+00 - val_loss: 0.0881 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "42/42 - 0s - loss: 1.4538 - accuracy: 0.0000e+00 - val_loss: 0.1733 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "42/42 - 0s - loss: 1.7470 - accuracy: 0.0000e+00 - val_loss: 2.9600 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "42/42 - 0s - loss: 6.0598 - accuracy: 0.0000e+00 - val_loss: 1.3443 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "42/42 - 0s - loss: 1.6731 - accuracy: 0.0000e+00 - val_loss: 4.0607 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "42/42 - 0s - loss: 1.9547 - accuracy: 0.0000e+00 - val_loss: 1.5886 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "42/42 - 0s - loss: 2.1671 - accuracy: 0.0000e+00 - val_loss: 0.0929 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "42/42 - 0s - loss: 2.6656 - accuracy: 0.0000e+00 - val_loss: 3.1772 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "42/42 - 0s - loss: 3.5380 - accuracy: 0.0000e+00 - val_loss: 2.0865 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "42/42 - 0s - loss: 1.5795 - accuracy: 0.0000e+00 - val_loss: 0.0902 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "42/42 - 0s - loss: 1.9752 - accuracy: 0.0000e+00 - val_loss: 0.7835 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "42/42 - 0s - loss: 1.8034 - accuracy: 0.0000e+00 - val_loss: 0.4373 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_66_input'), name='lstm_66_input', description=\"created by layer 'lstm_66_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 2.27348777937769\n",
      "Test MAPE------------------- 1.431239906018055\n",
      "{'n_epoch': 100, 'n_timesteps': 1, 'n_units': 50}\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_69_input'), name='lstm_69_input', description=\"created by layer 'lstm_69_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_69_input'), name='lstm_69_input', description=\"created by layer 'lstm_69_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_69_input'), name='lstm_69_input', description=\"created by layer 'lstm_69_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 333.5627 - accuracy: 0.0000e+00 - val_loss: 10.9314 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "42/42 - 0s - loss: 2.7491 - accuracy: 0.0000e+00 - val_loss: 0.6301 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "42/42 - 0s - loss: 1.5598 - accuracy: 0.0000e+00 - val_loss: 0.0877 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "42/42 - 0s - loss: 2.2898 - accuracy: 0.0000e+00 - val_loss: 0.4869 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "42/42 - 0s - loss: 2.4824 - accuracy: 0.0000e+00 - val_loss: 0.9567 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "42/42 - 0s - loss: 1.8781 - accuracy: 0.0000e+00 - val_loss: 0.1739 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "42/42 - 0s - loss: 4.3964 - accuracy: 0.0000e+00 - val_loss: 0.7350 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "42/42 - 0s - loss: 1.9148 - accuracy: 0.0000e+00 - val_loss: 0.0443 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "42/42 - 0s - loss: 1.4690 - accuracy: 0.0000e+00 - val_loss: 0.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "42/42 - 0s - loss: 1.2667 - accuracy: 0.0000e+00 - val_loss: 0.0552 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "42/42 - 0s - loss: 2.1244 - accuracy: 0.0000e+00 - val_loss: 0.2096 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "42/42 - 0s - loss: 2.1159 - accuracy: 0.0000e+00 - val_loss: 1.0253 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "42/42 - 0s - loss: 4.6174 - accuracy: 0.0000e+00 - val_loss: 0.5416 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "42/42 - 0s - loss: 3.2300 - accuracy: 0.0000e+00 - val_loss: 0.1140 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "42/42 - 0s - loss: 2.3722 - accuracy: 0.0000e+00 - val_loss: 0.0992 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "42/42 - 0s - loss: 4.5766 - accuracy: 0.0000e+00 - val_loss: 0.4551 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "42/42 - 0s - loss: 3.1719 - accuracy: 0.0000e+00 - val_loss: 0.0566 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "42/42 - 0s - loss: 3.2559 - accuracy: 0.0000e+00 - val_loss: 6.5881 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "42/42 - 0s - loss: 3.3233 - accuracy: 0.0000e+00 - val_loss: 10.1488 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "42/42 - 0s - loss: 4.6461 - accuracy: 0.0000e+00 - val_loss: 6.2597 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "42/42 - 0s - loss: 3.3627 - accuracy: 0.0000e+00 - val_loss: 2.4728 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "42/42 - 0s - loss: 4.9737 - accuracy: 0.0000e+00 - val_loss: 6.3565 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "42/42 - 0s - loss: 4.8436 - accuracy: 0.0000e+00 - val_loss: 0.3888 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "42/42 - 0s - loss: 1.4172 - accuracy: 0.0000e+00 - val_loss: 0.5114 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "42/42 - 0s - loss: 3.7709 - accuracy: 0.0000e+00 - val_loss: 0.2061 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "42/42 - 0s - loss: 2.4045 - accuracy: 0.0000e+00 - val_loss: 4.6694 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "42/42 - 0s - loss: 2.2026 - accuracy: 0.0000e+00 - val_loss: 0.7650 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "42/42 - 0s - loss: 1.7168 - accuracy: 0.0000e+00 - val_loss: 4.4303 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "42/42 - 0s - loss: 4.4516 - accuracy: 0.0000e+00 - val_loss: 0.4420 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "42/42 - 0s - loss: 2.4510 - accuracy: 0.0000e+00 - val_loss: 0.0966 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "42/42 - 0s - loss: 6.3001 - accuracy: 0.0000e+00 - val_loss: 0.1772 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "42/42 - 0s - loss: 3.0280 - accuracy: 0.0000e+00 - val_loss: 0.5289 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "42/42 - 0s - loss: 5.9137 - accuracy: 0.0000e+00 - val_loss: 18.1711 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "42/42 - 0s - loss: 5.2077 - accuracy: 0.0000e+00 - val_loss: 0.4780 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "42/42 - 0s - loss: 1.6516 - accuracy: 0.0000e+00 - val_loss: 5.1256 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "42/42 - 0s - loss: 4.1982 - accuracy: 0.0000e+00 - val_loss: 2.0243 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "42/42 - 0s - loss: 4.1262 - accuracy: 0.0000e+00 - val_loss: 6.8352 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "42/42 - 0s - loss: 3.6939 - accuracy: 0.0000e+00 - val_loss: 0.3496 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "42/42 - 0s - loss: 3.7978 - accuracy: 0.0000e+00 - val_loss: 0.2761 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "42/42 - 0s - loss: 2.1298 - accuracy: 0.0000e+00 - val_loss: 0.9461 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "42/42 - 0s - loss: 4.1487 - accuracy: 0.0000e+00 - val_loss: 1.5445 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "42/42 - 0s - loss: 3.1720 - accuracy: 0.0000e+00 - val_loss: 3.8958 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "42/42 - 0s - loss: 4.0282 - accuracy: 0.0000e+00 - val_loss: 0.1576 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "42/42 - 0s - loss: 2.8163 - accuracy: 0.0000e+00 - val_loss: 0.2220 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "42/42 - 0s - loss: 3.6358 - accuracy: 0.0000e+00 - val_loss: 2.4377 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "42/42 - 0s - loss: 5.3427 - accuracy: 0.0000e+00 - val_loss: 9.0744 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "42/42 - 0s - loss: 1.2690 - accuracy: 0.0000e+00 - val_loss: 0.6040 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "42/42 - 0s - loss: 2.1743 - accuracy: 0.0000e+00 - val_loss: 0.6053 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "42/42 - 0s - loss: 1.5486 - accuracy: 0.0000e+00 - val_loss: 1.9019 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "42/42 - 0s - loss: 2.0737 - accuracy: 0.0000e+00 - val_loss: 0.6372 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "42/42 - 0s - loss: 5.8074 - accuracy: 0.0000e+00 - val_loss: 5.7653 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "42/42 - 0s - loss: 3.3675 - accuracy: 0.0000e+00 - val_loss: 0.7917 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "42/42 - 0s - loss: 3.8349 - accuracy: 0.0000e+00 - val_loss: 2.7496 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "42/42 - 0s - loss: 2.8167 - accuracy: 0.0000e+00 - val_loss: 0.2915 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "42/42 - 0s - loss: 1.2068 - accuracy: 0.0000e+00 - val_loss: 2.6955 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "42/42 - 0s - loss: 8.1932 - accuracy: 0.0000e+00 - val_loss: 2.5821 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "42/42 - 0s - loss: 2.3036 - accuracy: 0.0000e+00 - val_loss: 1.7044 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "42/42 - 0s - loss: 1.8713 - accuracy: 0.0000e+00 - val_loss: 1.5828 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "42/42 - 0s - loss: 2.4580 - accuracy: 0.0000e+00 - val_loss: 1.0540 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "42/42 - 0s - loss: 4.5217 - accuracy: 0.0000e+00 - val_loss: 4.4091 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "42/42 - 0s - loss: 2.5343 - accuracy: 0.0000e+00 - val_loss: 8.4991 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "42/42 - 0s - loss: 2.4559 - accuracy: 0.0000e+00 - val_loss: 0.1220 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "42/42 - 0s - loss: 2.6175 - accuracy: 0.0000e+00 - val_loss: 4.2790 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "42/42 - 0s - loss: 5.4842 - accuracy: 0.0000e+00 - val_loss: 3.6259 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "42/42 - 0s - loss: 2.7174 - accuracy: 0.0000e+00 - val_loss: 0.3668 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "42/42 - 0s - loss: 3.0046 - accuracy: 0.0000e+00 - val_loss: 0.3980 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "42/42 - 0s - loss: 1.5196 - accuracy: 0.0000e+00 - val_loss: 5.5088 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "42/42 - 0s - loss: 2.8371 - accuracy: 0.0000e+00 - val_loss: 5.2384 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "42/42 - 0s - loss: 9.4721 - accuracy: 0.0000e+00 - val_loss: 1.2220 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "42/42 - 0s - loss: 4.4988 - accuracy: 0.0000e+00 - val_loss: 0.4344 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "42/42 - 0s - loss: 2.4386 - accuracy: 0.0000e+00 - val_loss: 0.3702 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "42/42 - 0s - loss: 1.2118 - accuracy: 0.0000e+00 - val_loss: 2.3441 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "42/42 - 0s - loss: 3.9020 - accuracy: 0.0000e+00 - val_loss: 1.1437 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "42/42 - 0s - loss: 2.0835 - accuracy: 0.0000e+00 - val_loss: 0.1729 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "42/42 - 0s - loss: 5.9657 - accuracy: 0.0000e+00 - val_loss: 3.7213 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "42/42 - 0s - loss: 2.9688 - accuracy: 0.0000e+00 - val_loss: 0.3479 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "42/42 - 0s - loss: 1.3739 - accuracy: 0.0000e+00 - val_loss: 0.0872 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "42/42 - 0s - loss: 1.3423 - accuracy: 0.0000e+00 - val_loss: 5.2862 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "42/42 - 0s - loss: 2.7417 - accuracy: 0.0000e+00 - val_loss: 0.1914 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "42/42 - 0s - loss: 7.7707 - accuracy: 0.0000e+00 - val_loss: 0.9587 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "42/42 - 0s - loss: 2.3423 - accuracy: 0.0000e+00 - val_loss: 1.3687 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "42/42 - 0s - loss: 2.2448 - accuracy: 0.0000e+00 - val_loss: 1.0588 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "42/42 - 0s - loss: 3.2461 - accuracy: 0.0000e+00 - val_loss: 6.6992 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "42/42 - 0s - loss: 1.6295 - accuracy: 0.0000e+00 - val_loss: 1.6481 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "42/42 - 0s - loss: 2.7481 - accuracy: 0.0000e+00 - val_loss: 1.5452 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "42/42 - 0s - loss: 5.2754 - accuracy: 0.0000e+00 - val_loss: 3.6815 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "42/42 - 0s - loss: 8.9561 - accuracy: 0.0000e+00 - val_loss: 0.6949 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "42/42 - 0s - loss: 3.4931 - accuracy: 0.0000e+00 - val_loss: 0.1624 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "42/42 - 0s - loss: 2.0747 - accuracy: 0.0000e+00 - val_loss: 1.1242 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "42/42 - 0s - loss: 0.8433 - accuracy: 0.0000e+00 - val_loss: 1.8413 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "42/42 - 0s - loss: 3.3035 - accuracy: 0.0000e+00 - val_loss: 3.7670 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "42/42 - 0s - loss: 2.3132 - accuracy: 0.0000e+00 - val_loss: 3.8887 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "42/42 - 0s - loss: 2.9064 - accuracy: 0.0000e+00 - val_loss: 0.8724 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "42/42 - 0s - loss: 2.6720 - accuracy: 0.0000e+00 - val_loss: 6.4625 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "42/42 - 0s - loss: 1.4847 - accuracy: 0.0000e+00 - val_loss: 0.2949 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "42/42 - 0s - loss: 2.7268 - accuracy: 0.0000e+00 - val_loss: 0.7637 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "42/42 - 0s - loss: 1.9425 - accuracy: 0.0000e+00 - val_loss: 2.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "42/42 - 0s - loss: 3.1730 - accuracy: 0.0000e+00 - val_loss: 0.3395 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "42/42 - 0s - loss: 2.0151 - accuracy: 0.0000e+00 - val_loss: 0.7765 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "42/42 - 0s - loss: 1.4911 - accuracy: 0.0000e+00 - val_loss: 0.5463 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_69_input'), name='lstm_69_input', description=\"created by layer 'lstm_69_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 1.345572167130654\n",
      "Test MAPE------------------- 4.184708855782738\n",
      "{'n_epoch': 100, 'n_timesteps': 1, 'n_units': 60}\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_72_input'), name='lstm_72_input', description=\"created by layer 'lstm_72_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_72_input'), name='lstm_72_input', description=\"created by layer 'lstm_72_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_72_input'), name='lstm_72_input', description=\"created by layer 'lstm_72_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 366.7531 - accuracy: 0.0000e+00 - val_loss: 1.0732 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "42/42 - 0s - loss: 2.6983 - accuracy: 0.0000e+00 - val_loss: 1.1615 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "42/42 - 0s - loss: 1.6098 - accuracy: 0.0000e+00 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "42/42 - 0s - loss: 1.2763 - accuracy: 0.0000e+00 - val_loss: 0.0615 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "42/42 - 0s - loss: 1.2744 - accuracy: 0.0000e+00 - val_loss: 1.2370 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "42/42 - 0s - loss: 2.3492 - accuracy: 0.0000e+00 - val_loss: 4.8365 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "42/42 - 0s - loss: 3.2341 - accuracy: 0.0000e+00 - val_loss: 0.4466 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "42/42 - 0s - loss: 2.8950 - accuracy: 0.0000e+00 - val_loss: 0.0530 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "42/42 - 0s - loss: 1.1621 - accuracy: 0.0000e+00 - val_loss: 4.1780 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "42/42 - 0s - loss: 2.1349 - accuracy: 0.0000e+00 - val_loss: 1.5199 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "42/42 - 0s - loss: 2.1700 - accuracy: 0.0000e+00 - val_loss: 3.0498 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "42/42 - 0s - loss: 2.9004 - accuracy: 0.0000e+00 - val_loss: 2.1510 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "42/42 - 0s - loss: 2.7759 - accuracy: 0.0000e+00 - val_loss: 15.8174 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "42/42 - 0s - loss: 3.0354 - accuracy: 0.0000e+00 - val_loss: 2.6958 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "42/42 - 0s - loss: 3.6681 - accuracy: 0.0000e+00 - val_loss: 1.2182 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "42/42 - 0s - loss: 1.5507 - accuracy: 0.0000e+00 - val_loss: 0.2773 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "42/42 - 0s - loss: 1.6940 - accuracy: 0.0000e+00 - val_loss: 0.0818 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "42/42 - 0s - loss: 1.4220 - accuracy: 0.0000e+00 - val_loss: 0.2189 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "42/42 - 0s - loss: 2.3365 - accuracy: 0.0000e+00 - val_loss: 0.8626 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "42/42 - 0s - loss: 3.8082 - accuracy: 0.0000e+00 - val_loss: 0.2364 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "42/42 - 0s - loss: 2.1653 - accuracy: 0.0000e+00 - val_loss: 0.3089 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "42/42 - 0s - loss: 1.7905 - accuracy: 0.0000e+00 - val_loss: 0.4050 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "42/42 - 0s - loss: 2.9189 - accuracy: 0.0000e+00 - val_loss: 3.5632 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "42/42 - 0s - loss: 2.2018 - accuracy: 0.0000e+00 - val_loss: 0.3725 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "42/42 - 0s - loss: 1.8736 - accuracy: 0.0000e+00 - val_loss: 1.1022 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "42/42 - 0s - loss: 3.4690 - accuracy: 0.0000e+00 - val_loss: 4.4300 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "42/42 - 0s - loss: 2.0290 - accuracy: 0.0000e+00 - val_loss: 0.4280 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "42/42 - 0s - loss: 5.3318 - accuracy: 0.0000e+00 - val_loss: 3.4625 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "42/42 - 0s - loss: 5.5637 - accuracy: 0.0000e+00 - val_loss: 0.5557 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "42/42 - 0s - loss: 2.7862 - accuracy: 0.0000e+00 - val_loss: 5.2079 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "42/42 - 0s - loss: 4.8279 - accuracy: 0.0000e+00 - val_loss: 5.9813 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "42/42 - 0s - loss: 3.2549 - accuracy: 0.0000e+00 - val_loss: 0.0547 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "42/42 - 0s - loss: 1.6919 - accuracy: 0.0000e+00 - val_loss: 1.1777 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "42/42 - 0s - loss: 2.1285 - accuracy: 0.0000e+00 - val_loss: 0.2036 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "42/42 - 0s - loss: 3.6056 - accuracy: 0.0000e+00 - val_loss: 0.7070 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "42/42 - 0s - loss: 1.1086 - accuracy: 0.0000e+00 - val_loss: 1.1829 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "42/42 - 0s - loss: 1.7525 - accuracy: 0.0000e+00 - val_loss: 3.4861 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "42/42 - 0s - loss: 6.1531 - accuracy: 0.0000e+00 - val_loss: 2.1819 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "42/42 - 0s - loss: 2.6606 - accuracy: 0.0000e+00 - val_loss: 1.6137 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "42/42 - 0s - loss: 7.1167 - accuracy: 0.0000e+00 - val_loss: 1.1467 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "42/42 - 0s - loss: 5.7746 - accuracy: 0.0000e+00 - val_loss: 0.1841 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "42/42 - 0s - loss: 2.4405 - accuracy: 0.0000e+00 - val_loss: 0.1849 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "42/42 - 0s - loss: 2.6477 - accuracy: 0.0000e+00 - val_loss: 0.4884 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "42/42 - 0s - loss: 3.2356 - accuracy: 0.0000e+00 - val_loss: 4.6731 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "42/42 - 0s - loss: 3.7127 - accuracy: 0.0000e+00 - val_loss: 2.3705 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "42/42 - 0s - loss: 4.4060 - accuracy: 0.0000e+00 - val_loss: 2.7497 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "42/42 - 0s - loss: 2.1744 - accuracy: 0.0000e+00 - val_loss: 0.0844 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "42/42 - 0s - loss: 3.9387 - accuracy: 0.0000e+00 - val_loss: 5.8689 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "42/42 - 0s - loss: 6.1877 - accuracy: 0.0000e+00 - val_loss: 0.0629 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "42/42 - 0s - loss: 1.4689 - accuracy: 0.0000e+00 - val_loss: 1.6205 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "42/42 - 0s - loss: 2.7322 - accuracy: 0.0000e+00 - val_loss: 1.0959 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "42/42 - 0s - loss: 1.0440 - accuracy: 0.0000e+00 - val_loss: 2.9028 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "42/42 - 0s - loss: 2.0814 - accuracy: 0.0000e+00 - val_loss: 0.4100 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "42/42 - 0s - loss: 11.2143 - accuracy: 0.0000e+00 - val_loss: 0.7510 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "42/42 - 0s - loss: 1.1154 - accuracy: 0.0000e+00 - val_loss: 0.0663 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "42/42 - 0s - loss: 1.4907 - accuracy: 0.0000e+00 - val_loss: 0.1313 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "42/42 - 0s - loss: 2.5926 - accuracy: 0.0000e+00 - val_loss: 0.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "42/42 - 0s - loss: 1.7301 - accuracy: 0.0000e+00 - val_loss: 2.1421 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "42/42 - 0s - loss: 1.7623 - accuracy: 0.0000e+00 - val_loss: 0.3675 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "42/42 - 0s - loss: 1.5329 - accuracy: 0.0000e+00 - val_loss: 3.0493 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "42/42 - 0s - loss: 5.4421 - accuracy: 0.0000e+00 - val_loss: 6.1665 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "42/42 - 0s - loss: 8.8888 - accuracy: 0.0000e+00 - val_loss: 6.0834 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "42/42 - 0s - loss: 3.3345 - accuracy: 0.0000e+00 - val_loss: 0.1830 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "42/42 - 0s - loss: 1.7865 - accuracy: 0.0000e+00 - val_loss: 0.0987 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "42/42 - 0s - loss: 0.9986 - accuracy: 0.0000e+00 - val_loss: 0.6429 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "42/42 - 0s - loss: 3.5749 - accuracy: 0.0000e+00 - val_loss: 0.4383 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "42/42 - 0s - loss: 1.2639 - accuracy: 0.0000e+00 - val_loss: 0.0752 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "42/42 - 0s - loss: 1.4581 - accuracy: 0.0000e+00 - val_loss: 0.0865 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "42/42 - 0s - loss: 0.9018 - accuracy: 0.0000e+00 - val_loss: 3.2388 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "42/42 - 0s - loss: 1.7941 - accuracy: 0.0000e+00 - val_loss: 1.2446 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "42/42 - 0s - loss: 2.2095 - accuracy: 0.0000e+00 - val_loss: 2.1899 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "42/42 - 0s - loss: 2.7357 - accuracy: 0.0000e+00 - val_loss: 2.0899 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "42/42 - 0s - loss: 2.6243 - accuracy: 0.0000e+00 - val_loss: 0.3673 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "42/42 - 0s - loss: 1.9941 - accuracy: 0.0000e+00 - val_loss: 0.6044 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "42/42 - 0s - loss: 1.2592 - accuracy: 0.0000e+00 - val_loss: 0.1365 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "42/42 - 0s - loss: 2.4959 - accuracy: 0.0000e+00 - val_loss: 4.4653 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "42/42 - 0s - loss: 1.4488 - accuracy: 0.0000e+00 - val_loss: 0.2474 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "42/42 - 0s - loss: 0.9747 - accuracy: 0.0000e+00 - val_loss: 0.0830 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "42/42 - 0s - loss: 1.0263 - accuracy: 0.0000e+00 - val_loss: 0.3353 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "42/42 - 0s - loss: 1.0935 - accuracy: 0.0000e+00 - val_loss: 0.4422 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "42/42 - 0s - loss: 3.2431 - accuracy: 0.0000e+00 - val_loss: 0.7314 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "42/42 - 0s - loss: 5.1168 - accuracy: 0.0000e+00 - val_loss: 2.3733 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "42/42 - 0s - loss: 2.1028 - accuracy: 0.0000e+00 - val_loss: 0.7343 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "42/42 - 0s - loss: 5.8874 - accuracy: 0.0000e+00 - val_loss: 0.3144 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "42/42 - 0s - loss: 2.9471 - accuracy: 0.0000e+00 - val_loss: 0.0710 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "42/42 - 0s - loss: 1.9061 - accuracy: 0.0000e+00 - val_loss: 0.4029 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "42/42 - 0s - loss: 1.1191 - accuracy: 0.0000e+00 - val_loss: 0.7543 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "42/42 - 0s - loss: 1.1812 - accuracy: 0.0000e+00 - val_loss: 0.5256 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "42/42 - 0s - loss: 1.1134 - accuracy: 0.0000e+00 - val_loss: 0.0507 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "42/42 - 0s - loss: 1.3007 - accuracy: 0.0000e+00 - val_loss: 0.0406 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "42/42 - 0s - loss: 2.8749 - accuracy: 0.0000e+00 - val_loss: 2.1491 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "42/42 - 0s - loss: 1.3990 - accuracy: 0.0000e+00 - val_loss: 0.1177 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "42/42 - 0s - loss: 1.6506 - accuracy: 0.0000e+00 - val_loss: 0.0349 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "42/42 - 0s - loss: 0.8001 - accuracy: 0.0000e+00 - val_loss: 0.0344 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "42/42 - 0s - loss: 0.9839 - accuracy: 0.0000e+00 - val_loss: 0.0980 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "42/42 - 0s - loss: 2.6092 - accuracy: 0.0000e+00 - val_loss: 0.0673 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "42/42 - 0s - loss: 4.8591 - accuracy: 0.0000e+00 - val_loss: 1.0743 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "42/42 - 0s - loss: 2.7136 - accuracy: 0.0000e+00 - val_loss: 1.4052 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "42/42 - 0s - loss: 1.0126 - accuracy: 0.0000e+00 - val_loss: 0.1359 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "42/42 - 0s - loss: 2.3637 - accuracy: 0.0000e+00 - val_loss: 0.5761 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_72_input'), name='lstm_72_input', description=\"created by layer 'lstm_72_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 2.6988442760662235\n",
      "Test MAPE------------------- 0.9312078429094323\n",
      "{'n_epoch': 100, 'n_timesteps': 2, 'n_units': 40}\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_75_input'), name='lstm_75_input', description=\"created by layer 'lstm_75_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_75_input'), name='lstm_75_input', description=\"created by layer 'lstm_75_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_75_input'), name='lstm_75_input', description=\"created by layer 'lstm_75_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 461.1039 - accuracy: 0.0000e+00 - val_loss: 1.1287 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "42/42 - 0s - loss: 2.5011 - accuracy: 0.0000e+00 - val_loss: 1.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "42/42 - 0s - loss: 1.2571 - accuracy: 0.0000e+00 - val_loss: 0.8040 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "42/42 - 0s - loss: 1.2589 - accuracy: 0.0000e+00 - val_loss: 1.1458 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "42/42 - 0s - loss: 1.1427 - accuracy: 0.0000e+00 - val_loss: 0.4253 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "42/42 - 0s - loss: 1.9949 - accuracy: 0.0000e+00 - val_loss: 0.9503 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "42/42 - 0s - loss: 1.7153 - accuracy: 0.0000e+00 - val_loss: 4.2881 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "42/42 - 0s - loss: 1.6021 - accuracy: 0.0000e+00 - val_loss: 0.0736 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "42/42 - 0s - loss: 1.4120 - accuracy: 0.0000e+00 - val_loss: 1.9427 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "42/42 - 0s - loss: 2.1907 - accuracy: 0.0000e+00 - val_loss: 0.1153 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "42/42 - 0s - loss: 2.2230 - accuracy: 0.0000e+00 - val_loss: 0.8123 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "42/42 - 0s - loss: 2.1827 - accuracy: 0.0000e+00 - val_loss: 0.7366 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "42/42 - 0s - loss: 2.7831 - accuracy: 0.0000e+00 - val_loss: 2.2567 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "42/42 - 0s - loss: 2.0622 - accuracy: 0.0000e+00 - val_loss: 0.4015 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "42/42 - 0s - loss: 2.8063 - accuracy: 0.0000e+00 - val_loss: 1.1448 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "42/42 - 0s - loss: 1.7234 - accuracy: 0.0000e+00 - val_loss: 0.1071 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "42/42 - 0s - loss: 1.3444 - accuracy: 0.0000e+00 - val_loss: 1.1684 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "42/42 - 0s - loss: 2.5697 - accuracy: 0.0000e+00 - val_loss: 5.0990 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "42/42 - 0s - loss: 2.1846 - accuracy: 0.0000e+00 - val_loss: 0.6870 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "42/42 - 0s - loss: 2.7642 - accuracy: 0.0000e+00 - val_loss: 0.5994 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "42/42 - 0s - loss: 1.5004 - accuracy: 0.0000e+00 - val_loss: 0.1635 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "42/42 - 0s - loss: 1.5186 - accuracy: 0.0000e+00 - val_loss: 0.1450 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "42/42 - 0s - loss: 1.8424 - accuracy: 0.0000e+00 - val_loss: 0.6078 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "42/42 - 0s - loss: 1.4498 - accuracy: 0.0000e+00 - val_loss: 0.9217 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "42/42 - 0s - loss: 1.4286 - accuracy: 0.0000e+00 - val_loss: 0.4299 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "42/42 - 0s - loss: 9.5422 - accuracy: 0.0000e+00 - val_loss: 1.9627 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "42/42 - 0s - loss: 2.6692 - accuracy: 0.0000e+00 - val_loss: 0.0715 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "42/42 - 0s - loss: 2.3370 - accuracy: 0.0000e+00 - val_loss: 0.3852 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "42/42 - 0s - loss: 1.8035 - accuracy: 0.0000e+00 - val_loss: 0.1014 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "42/42 - 0s - loss: 2.0902 - accuracy: 0.0000e+00 - val_loss: 0.6733 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "42/42 - 0s - loss: 3.4949 - accuracy: 0.0000e+00 - val_loss: 0.0971 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "42/42 - 0s - loss: 1.9026 - accuracy: 0.0000e+00 - val_loss: 2.3356 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "42/42 - 0s - loss: 4.0858 - accuracy: 0.0000e+00 - val_loss: 2.4359 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "42/42 - 0s - loss: 2.2576 - accuracy: 0.0000e+00 - val_loss: 5.6626 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "42/42 - 0s - loss: 2.6092 - accuracy: 0.0000e+00 - val_loss: 0.3794 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "42/42 - 0s - loss: 2.0435 - accuracy: 0.0000e+00 - val_loss: 0.1664 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "42/42 - 0s - loss: 3.8091 - accuracy: 0.0000e+00 - val_loss: 3.4829 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "42/42 - 0s - loss: 4.3360 - accuracy: 0.0000e+00 - val_loss: 0.5546 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "42/42 - 0s - loss: 5.6646 - accuracy: 0.0000e+00 - val_loss: 1.5572 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "42/42 - 0s - loss: 4.1948 - accuracy: 0.0000e+00 - val_loss: 0.9198 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "42/42 - 0s - loss: 2.7209 - accuracy: 0.0000e+00 - val_loss: 1.3088 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "42/42 - 0s - loss: 2.5262 - accuracy: 0.0000e+00 - val_loss: 1.1606 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "42/42 - 0s - loss: 5.9937 - accuracy: 0.0000e+00 - val_loss: 1.0492 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "42/42 - 0s - loss: 1.9440 - accuracy: 0.0000e+00 - val_loss: 10.2704 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "42/42 - 0s - loss: 4.0331 - accuracy: 0.0000e+00 - val_loss: 2.3341 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "42/42 - 0s - loss: 5.4172 - accuracy: 0.0000e+00 - val_loss: 0.1886 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "42/42 - 0s - loss: 1.9889 - accuracy: 0.0000e+00 - val_loss: 0.9049 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "42/42 - 0s - loss: 3.0284 - accuracy: 0.0000e+00 - val_loss: 15.1547 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "42/42 - 0s - loss: 2.7934 - accuracy: 0.0000e+00 - val_loss: 0.8125 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "42/42 - 0s - loss: 2.6088 - accuracy: 0.0000e+00 - val_loss: 1.1571 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "42/42 - 0s - loss: 2.4316 - accuracy: 0.0000e+00 - val_loss: 0.1416 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "42/42 - 0s - loss: 5.5080 - accuracy: 0.0000e+00 - val_loss: 2.7168 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "42/42 - 0s - loss: 2.4439 - accuracy: 0.0000e+00 - val_loss: 0.0964 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "42/42 - 0s - loss: 2.4837 - accuracy: 0.0000e+00 - val_loss: 0.1332 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "42/42 - 0s - loss: 2.3942 - accuracy: 0.0000e+00 - val_loss: 0.0716 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "42/42 - 0s - loss: 1.7364 - accuracy: 0.0000e+00 - val_loss: 0.0842 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "42/42 - 0s - loss: 1.9864 - accuracy: 0.0000e+00 - val_loss: 0.0970 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "42/42 - 0s - loss: 2.0105 - accuracy: 0.0000e+00 - val_loss: 2.7242 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "42/42 - 0s - loss: 1.6026 - accuracy: 0.0000e+00 - val_loss: 1.7521 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "42/42 - 0s - loss: 1.8478 - accuracy: 0.0000e+00 - val_loss: 2.2076 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "42/42 - 0s - loss: 4.6609 - accuracy: 0.0000e+00 - val_loss: 6.6462 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "42/42 - 0s - loss: 3.4716 - accuracy: 0.0000e+00 - val_loss: 0.0832 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "42/42 - 0s - loss: 3.6321 - accuracy: 0.0000e+00 - val_loss: 0.7085 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "42/42 - 0s - loss: 6.0986 - accuracy: 0.0000e+00 - val_loss: 6.1181 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "42/42 - 0s - loss: 10.2794 - accuracy: 0.0000e+00 - val_loss: 3.9871 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "42/42 - 0s - loss: 2.9762 - accuracy: 0.0000e+00 - val_loss: 1.8312 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "42/42 - 0s - loss: 2.4803 - accuracy: 0.0000e+00 - val_loss: 2.2576 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "42/42 - 0s - loss: 5.6110 - accuracy: 0.0000e+00 - val_loss: 1.8174 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "42/42 - 0s - loss: 2.4831 - accuracy: 0.0000e+00 - val_loss: 0.1083 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "42/42 - 0s - loss: 1.8282 - accuracy: 0.0000e+00 - val_loss: 0.4193 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "42/42 - 0s - loss: 1.8571 - accuracy: 0.0000e+00 - val_loss: 0.3230 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "42/42 - 0s - loss: 4.0054 - accuracy: 0.0000e+00 - val_loss: 2.0402 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "42/42 - 0s - loss: 3.7454 - accuracy: 0.0000e+00 - val_loss: 0.2937 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "42/42 - 0s - loss: 2.3363 - accuracy: 0.0000e+00 - val_loss: 1.4820 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "42/42 - 0s - loss: 1.2318 - accuracy: 0.0000e+00 - val_loss: 0.1141 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "42/42 - 0s - loss: 2.7588 - accuracy: 0.0000e+00 - val_loss: 0.2053 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "42/42 - 0s - loss: 6.2659 - accuracy: 0.0000e+00 - val_loss: 11.1291 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "42/42 - 0s - loss: 4.8673 - accuracy: 0.0000e+00 - val_loss: 1.3991 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "42/42 - 0s - loss: 2.0599 - accuracy: 0.0000e+00 - val_loss: 5.5521 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "42/42 - 0s - loss: 1.8100 - accuracy: 0.0000e+00 - val_loss: 0.7094 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "42/42 - 0s - loss: 1.3829 - accuracy: 0.0000e+00 - val_loss: 0.5567 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "42/42 - 0s - loss: 3.5602 - accuracy: 0.0000e+00 - val_loss: 0.8971 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "42/42 - 0s - loss: 1.4136 - accuracy: 0.0000e+00 - val_loss: 0.0636 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "42/42 - 0s - loss: 0.8340 - accuracy: 0.0000e+00 - val_loss: 4.1019 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "42/42 - 0s - loss: 2.6762 - accuracy: 0.0000e+00 - val_loss: 0.0778 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "42/42 - 0s - loss: 2.5880 - accuracy: 0.0000e+00 - val_loss: 2.0002 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "42/42 - 0s - loss: 1.8638 - accuracy: 0.0000e+00 - val_loss: 1.7349 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "42/42 - 0s - loss: 1.6019 - accuracy: 0.0000e+00 - val_loss: 1.1304 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "42/42 - 0s - loss: 2.4805 - accuracy: 0.0000e+00 - val_loss: 0.0847 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "42/42 - 0s - loss: 2.3740 - accuracy: 0.0000e+00 - val_loss: 0.1384 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "42/42 - 0s - loss: 2.8512 - accuracy: 0.0000e+00 - val_loss: 0.2017 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "42/42 - 0s - loss: 4.1708 - accuracy: 0.0000e+00 - val_loss: 0.1122 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "42/42 - 0s - loss: 1.5272 - accuracy: 0.0000e+00 - val_loss: 2.5160 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "42/42 - 0s - loss: 1.7290 - accuracy: 0.0000e+00 - val_loss: 0.4568 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "42/42 - 0s - loss: 1.7270 - accuracy: 0.0000e+00 - val_loss: 0.1152 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "42/42 - 0s - loss: 1.7506 - accuracy: 0.0000e+00 - val_loss: 1.8050 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "42/42 - 0s - loss: 1.2133 - accuracy: 0.0000e+00 - val_loss: 0.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "42/42 - 0s - loss: 3.1275 - accuracy: 0.0000e+00 - val_loss: 1.2392 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "42/42 - 0s - loss: 6.5951 - accuracy: 0.0000e+00 - val_loss: 1.3890 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "42/42 - 0s - loss: 1.5256 - accuracy: 0.0000e+00 - val_loss: 6.1772 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_75_input'), name='lstm_75_input', description=\"created by layer 'lstm_75_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 5.953502829724634\n",
      "Test MAPE------------------- 7.64555664802246\n",
      "{'n_epoch': 100, 'n_timesteps': 2, 'n_units': 50}\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_78_input'), name='lstm_78_input', description=\"created by layer 'lstm_78_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_78_input'), name='lstm_78_input', description=\"created by layer 'lstm_78_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_78_input'), name='lstm_78_input', description=\"created by layer 'lstm_78_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 504.3015 - accuracy: 0.0000e+00 - val_loss: 0.8643 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "42/42 - 0s - loss: 2.9298 - accuracy: 0.0000e+00 - val_loss: 1.0740 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "42/42 - 0s - loss: 1.7733 - accuracy: 0.0000e+00 - val_loss: 0.5519 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "42/42 - 0s - loss: 3.6376 - accuracy: 0.0000e+00 - val_loss: 9.2416 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "42/42 - 0s - loss: 1.6194 - accuracy: 0.0000e+00 - val_loss: 1.2654 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "42/42 - 0s - loss: 2.2161 - accuracy: 0.0000e+00 - val_loss: 0.9261 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "42/42 - 0s - loss: 3.7582 - accuracy: 0.0000e+00 - val_loss: 1.7771 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "42/42 - 0s - loss: 6.9925 - accuracy: 0.0000e+00 - val_loss: 2.9918 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "42/42 - 0s - loss: 1.6732 - accuracy: 0.0000e+00 - val_loss: 0.0734 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "42/42 - 0s - loss: 2.0815 - accuracy: 0.0000e+00 - val_loss: 7.0227 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "42/42 - 0s - loss: 3.2924 - accuracy: 0.0000e+00 - val_loss: 0.0876 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "42/42 - 0s - loss: 1.7686 - accuracy: 0.0000e+00 - val_loss: 1.6040 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "42/42 - 0s - loss: 1.8024 - accuracy: 0.0000e+00 - val_loss: 2.7060 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "42/42 - 0s - loss: 2.5200 - accuracy: 0.0000e+00 - val_loss: 0.1326 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "42/42 - 0s - loss: 2.5971 - accuracy: 0.0000e+00 - val_loss: 0.5551 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "42/42 - 0s - loss: 1.7175 - accuracy: 0.0000e+00 - val_loss: 3.5516 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "42/42 - 0s - loss: 2.0027 - accuracy: 0.0000e+00 - val_loss: 2.4997 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "42/42 - 0s - loss: 2.7475 - accuracy: 0.0000e+00 - val_loss: 0.2703 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "42/42 - 0s - loss: 1.5101 - accuracy: 0.0000e+00 - val_loss: 0.5043 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "42/42 - 0s - loss: 1.3885 - accuracy: 0.0000e+00 - val_loss: 3.3556 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "42/42 - 0s - loss: 1.7195 - accuracy: 0.0000e+00 - val_loss: 0.2785 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "42/42 - 0s - loss: 2.3151 - accuracy: 0.0000e+00 - val_loss: 4.2160 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "42/42 - 0s - loss: 7.4977 - accuracy: 0.0000e+00 - val_loss: 6.8163 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "42/42 - 0s - loss: 2.1239 - accuracy: 0.0000e+00 - val_loss: 0.3020 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "42/42 - 0s - loss: 2.7724 - accuracy: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "42/42 - 0s - loss: 2.2508 - accuracy: 0.0000e+00 - val_loss: 1.0342 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "42/42 - 0s - loss: 2.2058 - accuracy: 0.0000e+00 - val_loss: 3.7396 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "42/42 - 0s - loss: 1.9728 - accuracy: 0.0000e+00 - val_loss: 1.7523 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "42/42 - 0s - loss: 3.0111 - accuracy: 0.0000e+00 - val_loss: 4.3403 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "42/42 - 0s - loss: 3.0065 - accuracy: 0.0000e+00 - val_loss: 1.1336 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "42/42 - 0s - loss: 2.3901 - accuracy: 0.0000e+00 - val_loss: 0.0783 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "42/42 - 0s - loss: 2.7330 - accuracy: 0.0000e+00 - val_loss: 0.4555 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "42/42 - 0s - loss: 2.6681 - accuracy: 0.0000e+00 - val_loss: 0.4119 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "42/42 - 0s - loss: 2.3953 - accuracy: 0.0000e+00 - val_loss: 1.0262 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "42/42 - 0s - loss: 3.4187 - accuracy: 0.0000e+00 - val_loss: 4.0475 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "42/42 - 0s - loss: 3.7614 - accuracy: 0.0000e+00 - val_loss: 3.7168 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "42/42 - 0s - loss: 2.8680 - accuracy: 0.0000e+00 - val_loss: 1.1169 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "42/42 - 0s - loss: 4.2330 - accuracy: 0.0000e+00 - val_loss: 1.5993 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "42/42 - 0s - loss: 1.8055 - accuracy: 0.0000e+00 - val_loss: 2.4137 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "42/42 - 0s - loss: 2.6501 - accuracy: 0.0000e+00 - val_loss: 0.0792 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "42/42 - 0s - loss: 2.9512 - accuracy: 0.0000e+00 - val_loss: 0.2975 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "42/42 - 0s - loss: 4.2076 - accuracy: 0.0000e+00 - val_loss: 2.6135 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "42/42 - 0s - loss: 2.4755 - accuracy: 0.0000e+00 - val_loss: 1.7413 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "42/42 - 0s - loss: 1.8391 - accuracy: 0.0000e+00 - val_loss: 0.1973 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "42/42 - 0s - loss: 2.4078 - accuracy: 0.0000e+00 - val_loss: 0.4101 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "42/42 - 0s - loss: 1.7609 - accuracy: 0.0000e+00 - val_loss: 0.1893 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "42/42 - 0s - loss: 2.9500 - accuracy: 0.0000e+00 - val_loss: 4.9341 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "42/42 - 0s - loss: 3.9605 - accuracy: 0.0000e+00 - val_loss: 1.4340 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "42/42 - 0s - loss: 2.5507 - accuracy: 0.0000e+00 - val_loss: 0.0935 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "42/42 - 0s - loss: 6.1432 - accuracy: 0.0000e+00 - val_loss: 0.9156 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "42/42 - 0s - loss: 3.2430 - accuracy: 0.0000e+00 - val_loss: 0.9978 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "42/42 - 0s - loss: 1.6765 - accuracy: 0.0000e+00 - val_loss: 1.9974 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "42/42 - 0s - loss: 2.6446 - accuracy: 0.0000e+00 - val_loss: 0.4108 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "42/42 - 0s - loss: 2.1225 - accuracy: 0.0000e+00 - val_loss: 0.5975 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "42/42 - 0s - loss: 5.0199 - accuracy: 0.0000e+00 - val_loss: 4.1631 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "42/42 - 0s - loss: 2.1192 - accuracy: 0.0000e+00 - val_loss: 0.3112 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "42/42 - 0s - loss: 4.7456 - accuracy: 0.0000e+00 - val_loss: 4.5216 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "42/42 - 0s - loss: 2.9670 - accuracy: 0.0000e+00 - val_loss: 0.9694 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "42/42 - 0s - loss: 1.9155 - accuracy: 0.0000e+00 - val_loss: 0.9292 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "42/42 - 0s - loss: 1.8766 - accuracy: 0.0000e+00 - val_loss: 0.5676 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "42/42 - 0s - loss: 3.3452 - accuracy: 0.0000e+00 - val_loss: 0.0831 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "42/42 - 0s - loss: 2.1181 - accuracy: 0.0000e+00 - val_loss: 0.2390 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "42/42 - 0s - loss: 3.7263 - accuracy: 0.0000e+00 - val_loss: 3.0375 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "42/42 - 0s - loss: 3.8315 - accuracy: 0.0000e+00 - val_loss: 7.0334 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "42/42 - 0s - loss: 2.5360 - accuracy: 0.0000e+00 - val_loss: 4.4311 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "42/42 - 0s - loss: 1.4048 - accuracy: 0.0000e+00 - val_loss: 0.0562 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "42/42 - 0s - loss: 2.1263 - accuracy: 0.0000e+00 - val_loss: 0.7909 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "42/42 - 0s - loss: 1.2141 - accuracy: 0.0000e+00 - val_loss: 0.5491 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "42/42 - 0s - loss: 1.2789 - accuracy: 0.0000e+00 - val_loss: 0.8719 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "42/42 - 0s - loss: 2.4601 - accuracy: 0.0000e+00 - val_loss: 1.1367 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "42/42 - 0s - loss: 2.1835 - accuracy: 0.0000e+00 - val_loss: 2.0840 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "42/42 - 0s - loss: 2.5068 - accuracy: 0.0000e+00 - val_loss: 0.0739 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "42/42 - 0s - loss: 1.7934 - accuracy: 0.0000e+00 - val_loss: 2.3498 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "42/42 - 0s - loss: 3.1894 - accuracy: 0.0000e+00 - val_loss: 0.1783 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "42/42 - 0s - loss: 1.8938 - accuracy: 0.0000e+00 - val_loss: 1.1546 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "42/42 - 0s - loss: 1.8346 - accuracy: 0.0000e+00 - val_loss: 0.0748 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "42/42 - 0s - loss: 1.6693 - accuracy: 0.0000e+00 - val_loss: 0.4960 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "42/42 - 0s - loss: 2.1859 - accuracy: 0.0000e+00 - val_loss: 0.0853 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "42/42 - 0s - loss: 1.1962 - accuracy: 0.0000e+00 - val_loss: 0.2979 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "42/42 - 0s - loss: 3.8400 - accuracy: 0.0000e+00 - val_loss: 2.1675 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "42/42 - 0s - loss: 0.9448 - accuracy: 0.0000e+00 - val_loss: 3.0640 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "42/42 - 0s - loss: 2.1753 - accuracy: 0.0000e+00 - val_loss: 0.2225 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "42/42 - 0s - loss: 1.3385 - accuracy: 0.0000e+00 - val_loss: 5.3643 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "42/42 - 0s - loss: 1.7337 - accuracy: 0.0000e+00 - val_loss: 0.5716 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "42/42 - 0s - loss: 1.8784 - accuracy: 0.0000e+00 - val_loss: 3.3441 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "42/42 - 0s - loss: 4.2950 - accuracy: 0.0000e+00 - val_loss: 0.5926 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "42/42 - 0s - loss: 1.4594 - accuracy: 0.0000e+00 - val_loss: 0.4064 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "42/42 - 0s - loss: 1.5141 - accuracy: 0.0000e+00 - val_loss: 0.0656 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "42/42 - 0s - loss: 1.0326 - accuracy: 0.0000e+00 - val_loss: 0.0901 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "42/42 - 0s - loss: 0.9629 - accuracy: 0.0000e+00 - val_loss: 2.2936 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "42/42 - 0s - loss: 1.7326 - accuracy: 0.0000e+00 - val_loss: 1.7525 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "42/42 - 0s - loss: 1.2430 - accuracy: 0.0000e+00 - val_loss: 1.4199 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "42/42 - 0s - loss: 1.3539 - accuracy: 0.0000e+00 - val_loss: 0.1708 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "42/42 - 0s - loss: 1.7376 - accuracy: 0.0000e+00 - val_loss: 0.0651 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "42/42 - 0s - loss: 1.7557 - accuracy: 0.0000e+00 - val_loss: 0.0570 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "42/42 - 0s - loss: 1.2253 - accuracy: 0.0000e+00 - val_loss: 0.5782 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "42/42 - 0s - loss: 2.3503 - accuracy: 0.0000e+00 - val_loss: 0.4054 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "42/42 - 0s - loss: 1.7085 - accuracy: 0.0000e+00 - val_loss: 0.6072 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "42/42 - 0s - loss: 2.2041 - accuracy: 0.0000e+00 - val_loss: 1.7898 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "42/42 - 0s - loss: 1.5473 - accuracy: 0.0000e+00 - val_loss: 0.7756 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_78_input'), name='lstm_78_input', description=\"created by layer 'lstm_78_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 1.304431023454778\n",
      "Test MAPE------------------- 4.291149613731498\n",
      "{'n_epoch': 100, 'n_timesteps': 2, 'n_units': 60}\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_81_input'), name='lstm_81_input', description=\"created by layer 'lstm_81_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_81_input'), name='lstm_81_input', description=\"created by layer 'lstm_81_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_81_input'), name='lstm_81_input', description=\"created by layer 'lstm_81_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 233.6711 - accuracy: 0.0000e+00 - val_loss: 3.0468 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "42/42 - 0s - loss: 2.0649 - accuracy: 0.0000e+00 - val_loss: 0.1286 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "42/42 - 0s - loss: 2.4020 - accuracy: 0.0000e+00 - val_loss: 0.2337 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "42/42 - 0s - loss: 1.6131 - accuracy: 0.0000e+00 - val_loss: 0.0733 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "42/42 - 0s - loss: 2.6961 - accuracy: 0.0000e+00 - val_loss: 0.1878 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "42/42 - 0s - loss: 3.5094 - accuracy: 0.0000e+00 - val_loss: 0.2406 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "42/42 - 0s - loss: 1.7454 - accuracy: 0.0000e+00 - val_loss: 0.3060 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "42/42 - 0s - loss: 2.8446 - accuracy: 0.0000e+00 - val_loss: 0.0806 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "42/42 - 0s - loss: 5.5759 - accuracy: 0.0000e+00 - val_loss: 4.1976 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "42/42 - 0s - loss: 2.1951 - accuracy: 0.0000e+00 - val_loss: 0.0829 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "42/42 - 0s - loss: 1.5091 - accuracy: 0.0000e+00 - val_loss: 0.3550 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "42/42 - 0s - loss: 2.6743 - accuracy: 0.0000e+00 - val_loss: 7.0903 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "42/42 - 0s - loss: 9.6403 - accuracy: 0.0000e+00 - val_loss: 1.8058 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "42/42 - 0s - loss: 6.3694 - accuracy: 0.0000e+00 - val_loss: 0.7680 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "42/42 - 0s - loss: 2.4242 - accuracy: 0.0000e+00 - val_loss: 0.0693 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "42/42 - 0s - loss: 2.3472 - accuracy: 0.0000e+00 - val_loss: 0.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "42/42 - 0s - loss: 3.4865 - accuracy: 0.0000e+00 - val_loss: 3.4708 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "42/42 - 0s - loss: 5.0663 - accuracy: 0.0000e+00 - val_loss: 10.7179 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "42/42 - 0s - loss: 4.0809 - accuracy: 0.0000e+00 - val_loss: 3.2151 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "42/42 - 0s - loss: 7.4468 - accuracy: 0.0000e+00 - val_loss: 4.2023 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "42/42 - 0s - loss: 5.7102 - accuracy: 0.0000e+00 - val_loss: 2.5696 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "42/42 - 0s - loss: 6.5064 - accuracy: 0.0000e+00 - val_loss: 7.8110 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "42/42 - 0s - loss: 4.5198 - accuracy: 0.0000e+00 - val_loss: 0.1541 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "42/42 - 0s - loss: 1.6258 - accuracy: 0.0000e+00 - val_loss: 0.0925 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "42/42 - 0s - loss: 1.3974 - accuracy: 0.0000e+00 - val_loss: 1.6061 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "42/42 - 0s - loss: 1.9886 - accuracy: 0.0000e+00 - val_loss: 2.9598 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "42/42 - 0s - loss: 5.2953 - accuracy: 0.0000e+00 - val_loss: 1.0744 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "42/42 - 0s - loss: 3.5502 - accuracy: 0.0000e+00 - val_loss: 9.2981 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "42/42 - 0s - loss: 4.0944 - accuracy: 0.0000e+00 - val_loss: 2.3075 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "42/42 - 0s - loss: 3.4568 - accuracy: 0.0000e+00 - val_loss: 0.9460 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "42/42 - 0s - loss: 4.5124 - accuracy: 0.0000e+00 - val_loss: 1.0902 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "42/42 - 0s - loss: 3.4045 - accuracy: 0.0000e+00 - val_loss: 1.6561 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "42/42 - 0s - loss: 4.2660 - accuracy: 0.0000e+00 - val_loss: 3.7380 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "42/42 - 0s - loss: 5.0040 - accuracy: 0.0000e+00 - val_loss: 1.2879 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "42/42 - 0s - loss: 7.5153 - accuracy: 0.0000e+00 - val_loss: 5.4855 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "42/42 - 0s - loss: 2.2630 - accuracy: 0.0000e+00 - val_loss: 1.8448 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "42/42 - 0s - loss: 2.1294 - accuracy: 0.0000e+00 - val_loss: 0.2801 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "42/42 - 0s - loss: 2.7548 - accuracy: 0.0000e+00 - val_loss: 1.1819 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "42/42 - 0s - loss: 2.8702 - accuracy: 0.0000e+00 - val_loss: 0.8974 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "42/42 - 0s - loss: 4.9241 - accuracy: 0.0000e+00 - val_loss: 0.3522 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "42/42 - 0s - loss: 2.8158 - accuracy: 0.0000e+00 - val_loss: 0.1365 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "42/42 - 0s - loss: 2.9144 - accuracy: 0.0000e+00 - val_loss: 2.3538 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "42/42 - 0s - loss: 2.2707 - accuracy: 0.0000e+00 - val_loss: 0.2028 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "42/42 - 0s - loss: 1.5308 - accuracy: 0.0000e+00 - val_loss: 2.9736 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "42/42 - 0s - loss: 2.2993 - accuracy: 0.0000e+00 - val_loss: 0.3550 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "42/42 - 0s - loss: 2.0908 - accuracy: 0.0000e+00 - val_loss: 0.6056 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "42/42 - 0s - loss: 3.0887 - accuracy: 0.0000e+00 - val_loss: 0.1106 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "42/42 - 0s - loss: 4.0479 - accuracy: 0.0000e+00 - val_loss: 9.7624 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "42/42 - 0s - loss: 4.9919 - accuracy: 0.0000e+00 - val_loss: 0.5619 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "42/42 - 0s - loss: 1.9832 - accuracy: 0.0000e+00 - val_loss: 1.0124 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "42/42 - 0s - loss: 2.0305 - accuracy: 0.0000e+00 - val_loss: 0.0808 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "42/42 - 0s - loss: 4.1764 - accuracy: 0.0000e+00 - val_loss: 0.9344 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "42/42 - 0s - loss: 2.6753 - accuracy: 0.0000e+00 - val_loss: 0.9421 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "42/42 - 0s - loss: 1.6839 - accuracy: 0.0000e+00 - val_loss: 0.0920 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "42/42 - 0s - loss: 1.9567 - accuracy: 0.0000e+00 - val_loss: 0.2157 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "42/42 - 0s - loss: 5.5997 - accuracy: 0.0000e+00 - val_loss: 15.7472 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "42/42 - 0s - loss: 2.4930 - accuracy: 0.0000e+00 - val_loss: 0.1726 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "42/42 - 0s - loss: 5.1267 - accuracy: 0.0000e+00 - val_loss: 2.6383 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "42/42 - 0s - loss: 4.7831 - accuracy: 0.0000e+00 - val_loss: 0.3832 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "42/42 - 0s - loss: 4.0091 - accuracy: 0.0000e+00 - val_loss: 0.8206 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "42/42 - 0s - loss: 5.1827 - accuracy: 0.0000e+00 - val_loss: 9.8017 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "42/42 - 0s - loss: 4.2958 - accuracy: 0.0000e+00 - val_loss: 3.9703 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "42/42 - 0s - loss: 1.8645 - accuracy: 0.0000e+00 - val_loss: 0.0693 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "42/42 - 0s - loss: 1.1774 - accuracy: 0.0000e+00 - val_loss: 0.5544 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "42/42 - 0s - loss: 2.3450 - accuracy: 0.0000e+00 - val_loss: 1.4892 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "42/42 - 0s - loss: 1.4727 - accuracy: 0.0000e+00 - val_loss: 0.2461 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "42/42 - 0s - loss: 2.3464 - accuracy: 0.0000e+00 - val_loss: 0.0647 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "42/42 - 0s - loss: 2.0789 - accuracy: 0.0000e+00 - val_loss: 0.3034 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "42/42 - 0s - loss: 4.4309 - accuracy: 0.0000e+00 - val_loss: 0.2586 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "42/42 - 0s - loss: 2.6877 - accuracy: 0.0000e+00 - val_loss: 4.4250 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "42/42 - 0s - loss: 2.4192 - accuracy: 0.0000e+00 - val_loss: 4.1086 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "42/42 - 0s - loss: 1.8069 - accuracy: 0.0000e+00 - val_loss: 1.5368 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "42/42 - 0s - loss: 1.5401 - accuracy: 0.0000e+00 - val_loss: 1.7201 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "42/42 - 0s - loss: 2.7884 - accuracy: 0.0000e+00 - val_loss: 0.2059 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "42/42 - 0s - loss: 3.7441 - accuracy: 0.0000e+00 - val_loss: 3.4438 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "42/42 - 0s - loss: 2.6386 - accuracy: 0.0000e+00 - val_loss: 0.9914 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "42/42 - 0s - loss: 1.6031 - accuracy: 0.0000e+00 - val_loss: 0.7279 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "42/42 - 0s - loss: 4.3126 - accuracy: 0.0000e+00 - val_loss: 3.0860 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "42/42 - 0s - loss: 4.3688 - accuracy: 0.0000e+00 - val_loss: 0.3010 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "42/42 - 0s - loss: 2.8187 - accuracy: 0.0000e+00 - val_loss: 6.9927 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "42/42 - 0s - loss: 4.4048 - accuracy: 0.0000e+00 - val_loss: 0.8602 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "42/42 - 0s - loss: 4.5096 - accuracy: 0.0000e+00 - val_loss: 1.4593 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "42/42 - 0s - loss: 3.8221 - accuracy: 0.0000e+00 - val_loss: 4.2911 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "42/42 - 0s - loss: 2.5057 - accuracy: 0.0000e+00 - val_loss: 0.1844 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "42/42 - 0s - loss: 1.5297 - accuracy: 0.0000e+00 - val_loss: 3.7643 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "42/42 - 0s - loss: 4.6356 - accuracy: 0.0000e+00 - val_loss: 7.3848 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "42/42 - 0s - loss: 3.8835 - accuracy: 0.0000e+00 - val_loss: 0.0950 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "42/42 - 0s - loss: 4.3492 - accuracy: 0.0000e+00 - val_loss: 0.7741 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "42/42 - 0s - loss: 1.6414 - accuracy: 0.0000e+00 - val_loss: 5.3348 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "42/42 - 0s - loss: 4.1074 - accuracy: 0.0000e+00 - val_loss: 1.5179 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "42/42 - 0s - loss: 1.6401 - accuracy: 0.0000e+00 - val_loss: 0.4345 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "42/42 - 0s - loss: 2.9929 - accuracy: 0.0000e+00 - val_loss: 0.3415 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "42/42 - 0s - loss: 2.3905 - accuracy: 0.0000e+00 - val_loss: 0.3996 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "42/42 - 0s - loss: 2.0405 - accuracy: 0.0000e+00 - val_loss: 0.5489 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "42/42 - 0s - loss: 1.7038 - accuracy: 0.0000e+00 - val_loss: 0.0581 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "42/42 - 0s - loss: 1.6316 - accuracy: 0.0000e+00 - val_loss: 0.1168 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "42/42 - 0s - loss: 3.8444 - accuracy: 0.0000e+00 - val_loss: 5.3921 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "42/42 - 0s - loss: 3.2688 - accuracy: 0.0000e+00 - val_loss: 5.5438 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "42/42 - 0s - loss: 4.1898 - accuracy: 0.0000e+00 - val_loss: 0.0712 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "42/42 - 0s - loss: 2.3661 - accuracy: 0.0000e+00 - val_loss: 0.2538 - val_accuracy: 0.0000e+00\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 2, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 2, 1), dtype=tf.float32, name='lstm_81_input'), name='lstm_81_input', description=\"created by layer 'lstm_81_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 1.3545435304454008\n",
      "Test MAPE------------------- 3.155777627736478\n",
      "{'n_epoch': 100, 'n_timesteps': 3, 'n_units': 40}\n",
      "Epoch 1/100\n",
      "42/42 - 2s - loss: 167.0653 - accuracy: 0.0000e+00 - val_loss: 12.6265 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "42/42 - 0s - loss: 4.7242 - accuracy: 0.0000e+00 - val_loss: 6.7931 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "42/42 - 0s - loss: 2.6798 - accuracy: 0.0000e+00 - val_loss: 0.0965 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "42/42 - 0s - loss: 2.0614 - accuracy: 0.0000e+00 - val_loss: 0.0792 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "42/42 - 0s - loss: 1.0305 - accuracy: 0.0000e+00 - val_loss: 0.1162 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "42/42 - 0s - loss: 2.0811 - accuracy: 0.0000e+00 - val_loss: 0.6247 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "42/42 - 0s - loss: 4.8041 - accuracy: 0.0000e+00 - val_loss: 1.5048 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "42/42 - 0s - loss: 4.6948 - accuracy: 0.0000e+00 - val_loss: 0.4560 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "42/42 - 0s - loss: 1.5877 - accuracy: 0.0000e+00 - val_loss: 0.2364 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "42/42 - 0s - loss: 2.3379 - accuracy: 0.0000e+00 - val_loss: 2.3165 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "42/42 - 0s - loss: 2.1289 - accuracy: 0.0000e+00 - val_loss: 1.6047 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "42/42 - 0s - loss: 3.1848 - accuracy: 0.0000e+00 - val_loss: 2.3907 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "42/42 - 0s - loss: 2.5069 - accuracy: 0.0000e+00 - val_loss: 0.8926 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "42/42 - 0s - loss: 5.5754 - accuracy: 0.0000e+00 - val_loss: 6.0499 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "42/42 - 0s - loss: 8.9328 - accuracy: 0.0000e+00 - val_loss: 0.4943 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "42/42 - 0s - loss: 2.2924 - accuracy: 0.0000e+00 - val_loss: 3.4122 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "42/42 - 0s - loss: 2.0707 - accuracy: 0.0000e+00 - val_loss: 0.1946 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "42/42 - 0s - loss: 4.4927 - accuracy: 0.0000e+00 - val_loss: 0.3106 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "42/42 - 0s - loss: 4.0919 - accuracy: 0.0000e+00 - val_loss: 0.0794 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "42/42 - 0s - loss: 3.5580 - accuracy: 0.0000e+00 - val_loss: 3.8348 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "42/42 - 0s - loss: 4.3599 - accuracy: 0.0000e+00 - val_loss: 0.6428 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "42/42 - 0s - loss: 1.4261 - accuracy: 0.0000e+00 - val_loss: 2.4784 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "42/42 - 0s - loss: 1.6852 - accuracy: 0.0000e+00 - val_loss: 0.1260 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "42/42 - 0s - loss: 1.6256 - accuracy: 0.0000e+00 - val_loss: 0.0589 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "42/42 - 0s - loss: 1.2854 - accuracy: 0.0000e+00 - val_loss: 0.1577 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "42/42 - 0s - loss: 2.8562 - accuracy: 0.0000e+00 - val_loss: 0.0747 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "42/42 - 0s - loss: 2.5566 - accuracy: 0.0000e+00 - val_loss: 0.0979 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "42/42 - 0s - loss: 3.0929 - accuracy: 0.0000e+00 - val_loss: 6.0070 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "42/42 - 0s - loss: 3.8782 - accuracy: 0.0000e+00 - val_loss: 0.2424 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "42/42 - 0s - loss: 3.1919 - accuracy: 0.0000e+00 - val_loss: 6.4685 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "42/42 - 0s - loss: 2.5434 - accuracy: 0.0000e+00 - val_loss: 0.8662 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "42/42 - 0s - loss: 2.5983 - accuracy: 0.0000e+00 - val_loss: 0.0740 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "42/42 - 0s - loss: 3.6337 - accuracy: 0.0000e+00 - val_loss: 0.1294 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "42/42 - 0s - loss: 1.8247 - accuracy: 0.0000e+00 - val_loss: 4.2283 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "42/42 - 0s - loss: 2.7176 - accuracy: 0.0000e+00 - val_loss: 5.2010 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "42/42 - 0s - loss: 3.3445 - accuracy: 0.0000e+00 - val_loss: 5.7043 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "42/42 - 0s - loss: 2.5931 - accuracy: 0.0000e+00 - val_loss: 0.0891 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "42/42 - 0s - loss: 2.8986 - accuracy: 0.0000e+00 - val_loss: 0.0855 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "42/42 - 0s - loss: 1.8802 - accuracy: 0.0000e+00 - val_loss: 0.2863 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "42/42 - 0s - loss: 2.4165 - accuracy: 0.0000e+00 - val_loss: 5.4115 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "42/42 - 0s - loss: 4.0741 - accuracy: 0.0000e+00 - val_loss: 0.3027 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "42/42 - 0s - loss: 2.2508 - accuracy: 0.0000e+00 - val_loss: 6.3116 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "42/42 - 0s - loss: 2.1962 - accuracy: 0.0000e+00 - val_loss: 1.4549 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "42/42 - 0s - loss: 3.1366 - accuracy: 0.0000e+00 - val_loss: 7.0663 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "42/42 - 0s - loss: 2.1777 - accuracy: 0.0000e+00 - val_loss: 0.6295 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "42/42 - 0s - loss: 2.4335 - accuracy: 0.0000e+00 - val_loss: 6.0257 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "42/42 - 0s - loss: 4.3770 - accuracy: 0.0000e+00 - val_loss: 0.6000 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "42/42 - 0s - loss: 1.6326 - accuracy: 0.0000e+00 - val_loss: 0.4409 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "42/42 - 0s - loss: 2.8218 - accuracy: 0.0000e+00 - val_loss: 0.0793 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "42/42 - 0s - loss: 1.6851 - accuracy: 0.0000e+00 - val_loss: 0.0901 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "42/42 - 0s - loss: 1.8811 - accuracy: 0.0000e+00 - val_loss: 2.3584 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "42/42 - 0s - loss: 2.1949 - accuracy: 0.0000e+00 - val_loss: 3.1270 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "42/42 - 0s - loss: 1.3760 - accuracy: 0.0000e+00 - val_loss: 0.9068 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "42/42 - 0s - loss: 3.8354 - accuracy: 0.0000e+00 - val_loss: 4.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "42/42 - 0s - loss: 19.9790 - accuracy: 0.0000e+00 - val_loss: 26.9168 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "42/42 - 0s - loss: 17.4014 - accuracy: 0.0000e+00 - val_loss: 0.6098 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "42/42 - 0s - loss: 6.2635 - accuracy: 0.0000e+00 - val_loss: 1.4162 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "42/42 - 0s - loss: 1.6788 - accuracy: 0.0000e+00 - val_loss: 1.2228 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "42/42 - 0s - loss: 2.6084 - accuracy: 0.0000e+00 - val_loss: 0.4332 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "42/42 - 0s - loss: 1.2383 - accuracy: 0.0000e+00 - val_loss: 0.0993 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "42/42 - 0s - loss: 2.8205 - accuracy: 0.0000e+00 - val_loss: 4.3153 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "42/42 - 0s - loss: 2.0994 - accuracy: 0.0000e+00 - val_loss: 2.7186 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "42/42 - 0s - loss: 1.1913 - accuracy: 0.0000e+00 - val_loss: 3.3869 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "42/42 - 0s - loss: 3.8067 - accuracy: 0.0000e+00 - val_loss: 3.4586 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "42/42 - 0s - loss: 2.4098 - accuracy: 0.0000e+00 - val_loss: 0.0793 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "42/42 - 0s - loss: 2.8302 - accuracy: 0.0000e+00 - val_loss: 2.5811 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "42/42 - 0s - loss: 1.5724 - accuracy: 0.0000e+00 - val_loss: 0.5856 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "42/42 - 0s - loss: 5.5645 - accuracy: 0.0000e+00 - val_loss: 0.1173 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "42/42 - 0s - loss: 2.5163 - accuracy: 0.0000e+00 - val_loss: 0.1084 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "42/42 - 0s - loss: 2.1370 - accuracy: 0.0000e+00 - val_loss: 0.0859 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "42/42 - 0s - loss: 1.5528 - accuracy: 0.0000e+00 - val_loss: 1.1017 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "42/42 - 0s - loss: 2.6902 - accuracy: 0.0000e+00 - val_loss: 4.1185 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "42/42 - 0s - loss: 1.5746 - accuracy: 0.0000e+00 - val_loss: 2.2766 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "42/42 - 0s - loss: 0.7944 - accuracy: 0.0000e+00 - val_loss: 0.5703 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "42/42 - 0s - loss: 1.7973 - accuracy: 0.0000e+00 - val_loss: 0.0610 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "42/42 - 0s - loss: 2.8907 - accuracy: 0.0000e+00 - val_loss: 0.5559 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "42/42 - 0s - loss: 1.5469 - accuracy: 0.0000e+00 - val_loss: 0.0650 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "42/42 - 0s - loss: 2.2740 - accuracy: 0.0000e+00 - val_loss: 1.3411 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "42/42 - 0s - loss: 4.2230 - accuracy: 0.0000e+00 - val_loss: 0.8649 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "42/42 - 0s - loss: 2.4197 - accuracy: 0.0000e+00 - val_loss: 0.1608 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "42/42 - 0s - loss: 1.7410 - accuracy: 0.0000e+00 - val_loss: 3.9659 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "42/42 - 0s - loss: 2.6790 - accuracy: 0.0000e+00 - val_loss: 0.0636 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "42/42 - 0s - loss: 1.8328 - accuracy: 0.0000e+00 - val_loss: 3.9512 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "42/42 - 0s - loss: 2.0273 - accuracy: 0.0000e+00 - val_loss: 4.7492 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "42/42 - 0s - loss: 4.2825 - accuracy: 0.0000e+00 - val_loss: 0.8141 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "42/42 - 0s - loss: 1.6434 - accuracy: 0.0000e+00 - val_loss: 0.0891 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "42/42 - 0s - loss: 3.6781 - accuracy: 0.0000e+00 - val_loss: 2.5354 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "42/42 - 0s - loss: 2.7381 - accuracy: 0.0000e+00 - val_loss: 0.1186 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "42/42 - 0s - loss: 2.1636 - accuracy: 0.0000e+00 - val_loss: 1.2733 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "42/42 - 0s - loss: 1.2658 - accuracy: 0.0000e+00 - val_loss: 0.0772 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "42/42 - 0s - loss: 2.3432 - accuracy: 0.0000e+00 - val_loss: 0.3120 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "42/42 - 0s - loss: 4.2616 - accuracy: 0.0000e+00 - val_loss: 1.8398 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "42/42 - 0s - loss: 1.7102 - accuracy: 0.0000e+00 - val_loss: 0.6466 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "42/42 - 0s - loss: 1.6526 - accuracy: 0.0000e+00 - val_loss: 0.5897 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "42/42 - 0s - loss: 1.7423 - accuracy: 0.0000e+00 - val_loss: 0.8430 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "42/42 - 0s - loss: 1.8641 - accuracy: 0.0000e+00 - val_loss: 3.4948 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "42/42 - 0s - loss: 3.4147 - accuracy: 0.0000e+00 - val_loss: 2.2890 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "42/42 - 0s - loss: 3.2509 - accuracy: 0.0000e+00 - val_loss: 0.8688 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "42/42 - 0s - loss: 1.9765 - accuracy: 0.0000e+00 - val_loss: 1.9784 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "42/42 - 0s - loss: 2.0579 - accuracy: 0.0000e+00 - val_loss: 0.0554 - val_accuracy: 0.0000e+00\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 1.5792512698654904\n",
      "Test MAPE------------------- 1.5783909402826333\n",
      "{'n_epoch': 100, 'n_timesteps': 3, 'n_units': 50}\n",
      "Epoch 1/100\n",
      "42/42 - 2s - loss: 206.6953 - accuracy: 0.0000e+00 - val_loss: 1.3483 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "42/42 - 0s - loss: 3.7097 - accuracy: 0.0000e+00 - val_loss: 0.5127 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "42/42 - 0s - loss: 1.7342 - accuracy: 0.0000e+00 - val_loss: 1.3419 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "42/42 - 0s - loss: 1.9713 - accuracy: 0.0000e+00 - val_loss: 0.6835 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "42/42 - 0s - loss: 2.3480 - accuracy: 0.0000e+00 - val_loss: 3.0405 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "42/42 - 0s - loss: 3.0603 - accuracy: 0.0000e+00 - val_loss: 0.0930 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "42/42 - 0s - loss: 3.2030 - accuracy: 0.0000e+00 - val_loss: 12.2530 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "42/42 - 0s - loss: 4.8963 - accuracy: 0.0000e+00 - val_loss: 1.5102 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "42/42 - 0s - loss: 4.1558 - accuracy: 0.0000e+00 - val_loss: 0.0523 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "42/42 - 0s - loss: 1.7296 - accuracy: 0.0000e+00 - val_loss: 0.5554 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "42/42 - 0s - loss: 5.7678 - accuracy: 0.0000e+00 - val_loss: 6.7963 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "42/42 - 0s - loss: 6.4752 - accuracy: 0.0000e+00 - val_loss: 0.3412 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "42/42 - 0s - loss: 4.3776 - accuracy: 0.0000e+00 - val_loss: 11.6873 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "42/42 - 0s - loss: 5.0178 - accuracy: 0.0000e+00 - val_loss: 0.0756 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "42/42 - 0s - loss: 1.4815 - accuracy: 0.0000e+00 - val_loss: 1.3508 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "42/42 - 0s - loss: 11.0882 - accuracy: 0.0000e+00 - val_loss: 0.5806 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "42/42 - 0s - loss: 8.3415 - accuracy: 0.0000e+00 - val_loss: 7.0594 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "42/42 - 0s - loss: 8.7438 - accuracy: 0.0000e+00 - val_loss: 3.2822 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "42/42 - 0s - loss: 4.8986 - accuracy: 0.0000e+00 - val_loss: 0.5612 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "42/42 - 0s - loss: 2.3258 - accuracy: 0.0000e+00 - val_loss: 6.4267 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "42/42 - 0s - loss: 3.8741 - accuracy: 0.0000e+00 - val_loss: 4.9579 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "42/42 - 0s - loss: 3.7766 - accuracy: 0.0000e+00 - val_loss: 0.1775 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "42/42 - 0s - loss: 2.1615 - accuracy: 0.0000e+00 - val_loss: 1.4041 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "42/42 - 0s - loss: 4.2667 - accuracy: 0.0000e+00 - val_loss: 1.3360 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "42/42 - 0s - loss: 3.1378 - accuracy: 0.0000e+00 - val_loss: 0.0641 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "42/42 - 0s - loss: 6.9101 - accuracy: 0.0000e+00 - val_loss: 0.4386 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "42/42 - 0s - loss: 7.1564 - accuracy: 0.0000e+00 - val_loss: 23.3390 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "42/42 - 0s - loss: 7.9717 - accuracy: 0.0000e+00 - val_loss: 2.2104 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "42/42 - 0s - loss: 2.5637 - accuracy: 0.0000e+00 - val_loss: 5.4085 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "42/42 - 0s - loss: 2.0997 - accuracy: 0.0000e+00 - val_loss: 0.2997 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "42/42 - 0s - loss: 1.9587 - accuracy: 0.0000e+00 - val_loss: 1.4020 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "42/42 - 0s - loss: 3.6877 - accuracy: 0.0000e+00 - val_loss: 0.0773 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "42/42 - 0s - loss: 3.3265 - accuracy: 0.0000e+00 - val_loss: 0.1262 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "42/42 - 0s - loss: 1.7753 - accuracy: 0.0000e+00 - val_loss: 4.7424 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "42/42 - 0s - loss: 2.8877 - accuracy: 0.0000e+00 - val_loss: 0.1116 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "42/42 - 0s - loss: 1.5260 - accuracy: 0.0000e+00 - val_loss: 0.6138 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "42/42 - 0s - loss: 4.8389 - accuracy: 0.0000e+00 - val_loss: 4.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "42/42 - 0s - loss: 11.1074 - accuracy: 0.0000e+00 - val_loss: 3.1538 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "42/42 - 0s - loss: 2.6666 - accuracy: 0.0000e+00 - val_loss: 0.1457 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "42/42 - 0s - loss: 2.2554 - accuracy: 0.0000e+00 - val_loss: 0.2365 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "42/42 - 0s - loss: 3.7926 - accuracy: 0.0000e+00 - val_loss: 0.2166 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "42/42 - 0s - loss: 2.3521 - accuracy: 0.0000e+00 - val_loss: 0.1310 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "42/42 - 0s - loss: 2.5638 - accuracy: 0.0000e+00 - val_loss: 0.0920 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "42/42 - 0s - loss: 2.1223 - accuracy: 0.0000e+00 - val_loss: 11.3764 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "42/42 - 0s - loss: 4.5924 - accuracy: 0.0000e+00 - val_loss: 0.2519 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "42/42 - 0s - loss: 2.3363 - accuracy: 0.0000e+00 - val_loss: 0.1221 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "42/42 - 0s - loss: 2.1872 - accuracy: 0.0000e+00 - val_loss: 0.1661 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "42/42 - 0s - loss: 9.8385 - accuracy: 0.0000e+00 - val_loss: 0.8081 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "42/42 - 0s - loss: 3.7630 - accuracy: 0.0000e+00 - val_loss: 0.2281 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "42/42 - 0s - loss: 3.6678 - accuracy: 0.0000e+00 - val_loss: 1.0494 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "42/42 - 0s - loss: 2.0700 - accuracy: 0.0000e+00 - val_loss: 0.6380 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "42/42 - 0s - loss: 7.6182 - accuracy: 0.0000e+00 - val_loss: 7.1523 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "42/42 - 0s - loss: 2.2570 - accuracy: 0.0000e+00 - val_loss: 0.1361 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "42/42 - 0s - loss: 3.3128 - accuracy: 0.0000e+00 - val_loss: 0.4547 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "42/42 - 0s - loss: 2.0060 - accuracy: 0.0000e+00 - val_loss: 0.7817 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "42/42 - 0s - loss: 1.8302 - accuracy: 0.0000e+00 - val_loss: 3.0132 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "42/42 - 0s - loss: 2.0709 - accuracy: 0.0000e+00 - val_loss: 1.1435 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "42/42 - 0s - loss: 2.4721 - accuracy: 0.0000e+00 - val_loss: 0.4366 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "42/42 - 0s - loss: 1.6797 - accuracy: 0.0000e+00 - val_loss: 0.0544 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "42/42 - 0s - loss: 3.3393 - accuracy: 0.0000e+00 - val_loss: 1.6946 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "42/42 - 0s - loss: 7.2280 - accuracy: 0.0000e+00 - val_loss: 4.3881 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "42/42 - 0s - loss: 6.6130 - accuracy: 0.0000e+00 - val_loss: 0.0921 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "42/42 - 0s - loss: 3.1569 - accuracy: 0.0000e+00 - val_loss: 2.4879 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "42/42 - 0s - loss: 2.2300 - accuracy: 0.0000e+00 - val_loss: 1.3343 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "42/42 - 0s - loss: 2.7852 - accuracy: 0.0000e+00 - val_loss: 0.2544 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "42/42 - 0s - loss: 1.2127 - accuracy: 0.0000e+00 - val_loss: 0.2429 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "42/42 - 0s - loss: 2.0424 - accuracy: 0.0000e+00 - val_loss: 4.7942 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "42/42 - 0s - loss: 5.8586 - accuracy: 0.0000e+00 - val_loss: 0.1665 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "42/42 - 0s - loss: 1.7100 - accuracy: 0.0000e+00 - val_loss: 2.3029 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "42/42 - 0s - loss: 1.8134 - accuracy: 0.0000e+00 - val_loss: 2.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "42/42 - 0s - loss: 3.0401 - accuracy: 0.0000e+00 - val_loss: 1.7834 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "42/42 - 0s - loss: 1.8438 - accuracy: 0.0000e+00 - val_loss: 0.0824 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "42/42 - 0s - loss: 1.9393 - accuracy: 0.0000e+00 - val_loss: 2.2184 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "42/42 - 0s - loss: 2.3755 - accuracy: 0.0000e+00 - val_loss: 3.5589 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "42/42 - 0s - loss: 3.7918 - accuracy: 0.0000e+00 - val_loss: 6.5680 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "42/42 - 0s - loss: 6.7235 - accuracy: 0.0000e+00 - val_loss: 1.0019 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "42/42 - 0s - loss: 2.8253 - accuracy: 0.0000e+00 - val_loss: 8.2494 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "42/42 - 0s - loss: 2.2510 - accuracy: 0.0000e+00 - val_loss: 2.4010 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "42/42 - 0s - loss: 2.2714 - accuracy: 0.0000e+00 - val_loss: 3.7391 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "42/42 - 0s - loss: 1.6800 - accuracy: 0.0000e+00 - val_loss: 0.0842 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "42/42 - 0s - loss: 3.8718 - accuracy: 0.0000e+00 - val_loss: 3.3407 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "42/42 - 0s - loss: 4.0905 - accuracy: 0.0000e+00 - val_loss: 2.5088 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "42/42 - 0s - loss: 2.8579 - accuracy: 0.0000e+00 - val_loss: 7.4243 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "42/42 - 0s - loss: 6.0571 - accuracy: 0.0000e+00 - val_loss: 2.7333 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "42/42 - 0s - loss: 6.5933 - accuracy: 0.0000e+00 - val_loss: 0.6632 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "42/42 - 0s - loss: 3.1128 - accuracy: 0.0000e+00 - val_loss: 0.9925 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "42/42 - 0s - loss: 3.0028 - accuracy: 0.0000e+00 - val_loss: 1.0975 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "42/42 - 0s - loss: 1.9489 - accuracy: 0.0000e+00 - val_loss: 2.3125 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "42/42 - 0s - loss: 4.2475 - accuracy: 0.0000e+00 - val_loss: 0.6512 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "42/42 - 0s - loss: 2.0830 - accuracy: 0.0000e+00 - val_loss: 0.0750 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "42/42 - 0s - loss: 2.2204 - accuracy: 0.0000e+00 - val_loss: 0.1589 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "42/42 - 0s - loss: 4.5723 - accuracy: 0.0000e+00 - val_loss: 5.8190 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "42/42 - 0s - loss: 4.5350 - accuracy: 0.0000e+00 - val_loss: 3.0053 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "42/42 - 0s - loss: 5.6825 - accuracy: 0.0000e+00 - val_loss: 0.4107 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "42/42 - 0s - loss: 2.1248 - accuracy: 0.0000e+00 - val_loss: 0.3172 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "42/42 - 0s - loss: 1.4635 - accuracy: 0.0000e+00 - val_loss: 3.1751 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "42/42 - 0s - loss: 1.4073 - accuracy: 0.0000e+00 - val_loss: 2.6145 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "42/42 - 0s - loss: 1.5906 - accuracy: 0.0000e+00 - val_loss: 0.3898 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "42/42 - 0s - loss: 2.5511 - accuracy: 0.0000e+00 - val_loss: 0.8321 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "42/42 - 0s - loss: 1.6176 - accuracy: 0.0000e+00 - val_loss: 4.5687 - val_accuracy: 0.0000e+00\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 4.0780996292451785\n",
      "Test MAPE------------------- 8.47630655956102\n",
      "{'n_epoch': 100, 'n_timesteps': 3, 'n_units': 60}\n",
      "Epoch 1/100\n",
      "42/42 - 2s - loss: 408.1186 - accuracy: 0.0000e+00 - val_loss: 2.8529 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "42/42 - 0s - loss: 2.4660 - accuracy: 0.0000e+00 - val_loss: 1.3871 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "42/42 - 0s - loss: 1.6108 - accuracy: 0.0000e+00 - val_loss: 1.6442 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "42/42 - 0s - loss: 2.0858 - accuracy: 0.0000e+00 - val_loss: 0.7229 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "42/42 - 0s - loss: 1.3211 - accuracy: 0.0000e+00 - val_loss: 0.2235 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "42/42 - 0s - loss: 1.5097 - accuracy: 0.0000e+00 - val_loss: 1.1767 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "42/42 - 0s - loss: 1.5277 - accuracy: 0.0000e+00 - val_loss: 0.7517 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "42/42 - 0s - loss: 1.8772 - accuracy: 0.0000e+00 - val_loss: 1.9368 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "42/42 - 0s - loss: 3.7700 - accuracy: 0.0000e+00 - val_loss: 0.1543 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "42/42 - 0s - loss: 1.9614 - accuracy: 0.0000e+00 - val_loss: 0.5665 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "42/42 - 0s - loss: 1.3214 - accuracy: 0.0000e+00 - val_loss: 0.1412 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "42/42 - 0s - loss: 2.4689 - accuracy: 0.0000e+00 - val_loss: 0.5988 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "42/42 - 0s - loss: 1.6540 - accuracy: 0.0000e+00 - val_loss: 1.2444 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "42/42 - 0s - loss: 3.1776 - accuracy: 0.0000e+00 - val_loss: 1.1746 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "42/42 - 0s - loss: 2.4468 - accuracy: 0.0000e+00 - val_loss: 0.1166 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "42/42 - 0s - loss: 2.7943 - accuracy: 0.0000e+00 - val_loss: 0.6385 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "42/42 - 0s - loss: 1.8882 - accuracy: 0.0000e+00 - val_loss: 1.3340 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "42/42 - 0s - loss: 1.2343 - accuracy: 0.0000e+00 - val_loss: 0.5901 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "42/42 - 0s - loss: 1.9732 - accuracy: 0.0000e+00 - val_loss: 0.2504 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "42/42 - 0s - loss: 2.6333 - accuracy: 0.0000e+00 - val_loss: 0.0736 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "42/42 - 0s - loss: 2.3117 - accuracy: 0.0000e+00 - val_loss: 0.0647 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "42/42 - 0s - loss: 1.5037 - accuracy: 0.0000e+00 - val_loss: 2.0810 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "42/42 - 0s - loss: 5.1982 - accuracy: 0.0000e+00 - val_loss: 0.2298 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "42/42 - 0s - loss: 1.6113 - accuracy: 0.0000e+00 - val_loss: 2.7089 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "42/42 - 0s - loss: 3.0912 - accuracy: 0.0000e+00 - val_loss: 0.1091 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "42/42 - 0s - loss: 1.9248 - accuracy: 0.0000e+00 - val_loss: 1.2318 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "42/42 - 0s - loss: 1.2677 - accuracy: 0.0000e+00 - val_loss: 0.3408 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "42/42 - 0s - loss: 3.2369 - accuracy: 0.0000e+00 - val_loss: 0.0621 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "42/42 - 0s - loss: 3.6986 - accuracy: 0.0000e+00 - val_loss: 0.0601 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "42/42 - 0s - loss: 2.5441 - accuracy: 0.0000e+00 - val_loss: 0.3483 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "42/42 - 0s - loss: 3.6475 - accuracy: 0.0000e+00 - val_loss: 0.2290 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "42/42 - 0s - loss: 2.2358 - accuracy: 0.0000e+00 - val_loss: 0.0754 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "42/42 - 0s - loss: 6.9935 - accuracy: 0.0000e+00 - val_loss: 8.3727 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "42/42 - 0s - loss: 7.0892 - accuracy: 0.0000e+00 - val_loss: 0.0611 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "42/42 - 0s - loss: 1.3644 - accuracy: 0.0000e+00 - val_loss: 0.0807 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "42/42 - 0s - loss: 1.5136 - accuracy: 0.0000e+00 - val_loss: 4.7906 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "42/42 - 0s - loss: 2.9408 - accuracy: 0.0000e+00 - val_loss: 0.1462 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "42/42 - 0s - loss: 4.2532 - accuracy: 0.0000e+00 - val_loss: 9.0073 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "42/42 - 0s - loss: 5.3362 - accuracy: 0.0000e+00 - val_loss: 0.1033 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "42/42 - 0s - loss: 3.5265 - accuracy: 0.0000e+00 - val_loss: 5.2223 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "42/42 - 0s - loss: 5.3870 - accuracy: 0.0000e+00 - val_loss: 0.8264 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "42/42 - 0s - loss: 2.0072 - accuracy: 0.0000e+00 - val_loss: 0.3676 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "42/42 - 0s - loss: 2.3088 - accuracy: 0.0000e+00 - val_loss: 0.0709 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "42/42 - 0s - loss: 1.6274 - accuracy: 0.0000e+00 - val_loss: 1.8540 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "42/42 - 0s - loss: 2.3718 - accuracy: 0.0000e+00 - val_loss: 2.5439 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "42/42 - 0s - loss: 7.9188 - accuracy: 0.0000e+00 - val_loss: 4.6102 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "42/42 - 0s - loss: 2.4113 - accuracy: 0.0000e+00 - val_loss: 2.1032 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "42/42 - 0s - loss: 3.3168 - accuracy: 0.0000e+00 - val_loss: 0.2530 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "42/42 - 0s - loss: 2.5615 - accuracy: 0.0000e+00 - val_loss: 0.3406 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "42/42 - 0s - loss: 3.7791 - accuracy: 0.0000e+00 - val_loss: 0.2510 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "42/42 - 0s - loss: 1.8000 - accuracy: 0.0000e+00 - val_loss: 3.3257 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "42/42 - 0s - loss: 3.7073 - accuracy: 0.0000e+00 - val_loss: 0.5512 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "42/42 - 0s - loss: 2.0622 - accuracy: 0.0000e+00 - val_loss: 1.5027 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "42/42 - 0s - loss: 2.2750 - accuracy: 0.0000e+00 - val_loss: 0.2584 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "42/42 - 0s - loss: 3.2333 - accuracy: 0.0000e+00 - val_loss: 2.6868 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "42/42 - 0s - loss: 1.6094 - accuracy: 0.0000e+00 - val_loss: 0.0612 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "42/42 - 0s - loss: 2.2507 - accuracy: 0.0000e+00 - val_loss: 0.1340 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "42/42 - 0s - loss: 1.5591 - accuracy: 0.0000e+00 - val_loss: 0.1725 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "42/42 - 0s - loss: 1.4672 - accuracy: 0.0000e+00 - val_loss: 1.0494 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "42/42 - 0s - loss: 3.5942 - accuracy: 0.0000e+00 - val_loss: 1.4169 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "42/42 - 0s - loss: 6.4499 - accuracy: 0.0000e+00 - val_loss: 0.3434 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "42/42 - 0s - loss: 5.2752 - accuracy: 0.0000e+00 - val_loss: 0.3779 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "42/42 - 0s - loss: 5.6029 - accuracy: 0.0000e+00 - val_loss: 5.1980 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "42/42 - 0s - loss: 4.2889 - accuracy: 0.0000e+00 - val_loss: 0.0791 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "42/42 - 0s - loss: 1.4128 - accuracy: 0.0000e+00 - val_loss: 0.7308 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "42/42 - 0s - loss: 2.4709 - accuracy: 0.0000e+00 - val_loss: 0.0544 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "42/42 - 0s - loss: 1.5754 - accuracy: 0.0000e+00 - val_loss: 5.3168 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "42/42 - 0s - loss: 2.5686 - accuracy: 0.0000e+00 - val_loss: 0.8647 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "42/42 - 0s - loss: 2.6384 - accuracy: 0.0000e+00 - val_loss: 0.5936 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "42/42 - 0s - loss: 2.4409 - accuracy: 0.0000e+00 - val_loss: 0.9002 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "42/42 - 0s - loss: 1.5899 - accuracy: 0.0000e+00 - val_loss: 0.0810 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "42/42 - 0s - loss: 1.8696 - accuracy: 0.0000e+00 - val_loss: 0.1092 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "42/42 - 0s - loss: 2.5262 - accuracy: 0.0000e+00 - val_loss: 1.6769 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "42/42 - 0s - loss: 2.3082 - accuracy: 0.0000e+00 - val_loss: 0.4527 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "42/42 - 0s - loss: 1.8092 - accuracy: 0.0000e+00 - val_loss: 1.3183 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "42/42 - 0s - loss: 3.1276 - accuracy: 0.0000e+00 - val_loss: 0.1862 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "42/42 - 0s - loss: 4.6059 - accuracy: 0.0000e+00 - val_loss: 0.8114 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "42/42 - 0s - loss: 1.5323 - accuracy: 0.0000e+00 - val_loss: 2.1638 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "42/42 - 0s - loss: 3.0533 - accuracy: 0.0000e+00 - val_loss: 0.1088 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "42/42 - 0s - loss: 1.5167 - accuracy: 0.0000e+00 - val_loss: 1.4238 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "42/42 - 0s - loss: 1.4646 - accuracy: 0.0000e+00 - val_loss: 0.0617 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "42/42 - 0s - loss: 3.2450 - accuracy: 0.0000e+00 - val_loss: 0.9075 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "42/42 - 0s - loss: 1.8042 - accuracy: 0.0000e+00 - val_loss: 0.6008 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "42/42 - 0s - loss: 2.2170 - accuracy: 0.0000e+00 - val_loss: 0.3400 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "42/42 - 0s - loss: 1.8487 - accuracy: 0.0000e+00 - val_loss: 0.1150 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "42/42 - 0s - loss: 3.5425 - accuracy: 0.0000e+00 - val_loss: 1.2151 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "42/42 - 0s - loss: 4.8401 - accuracy: 0.0000e+00 - val_loss: 1.4387 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "42/42 - 0s - loss: 1.5090 - accuracy: 0.0000e+00 - val_loss: 2.5411 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "42/42 - 0s - loss: 3.4038 - accuracy: 0.0000e+00 - val_loss: 1.9926 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "42/42 - 0s - loss: 1.4799 - accuracy: 0.0000e+00 - val_loss: 1.5315 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "42/42 - 0s - loss: 4.4421 - accuracy: 0.0000e+00 - val_loss: 5.0240 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "42/42 - 0s - loss: 3.8915 - accuracy: 0.0000e+00 - val_loss: 0.1536 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "42/42 - 0s - loss: 3.8213 - accuracy: 0.0000e+00 - val_loss: 0.3601 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "42/42 - 0s - loss: 1.8010 - accuracy: 0.0000e+00 - val_loss: 0.1024 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "42/42 - 0s - loss: 1.0571 - accuracy: 0.0000e+00 - val_loss: 0.1855 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "42/42 - 0s - loss: 1.8071 - accuracy: 0.0000e+00 - val_loss: 0.0802 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "42/42 - 0s - loss: 6.8895 - accuracy: 0.0000e+00 - val_loss: 0.0665 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "42/42 - 0s - loss: 2.0865 - accuracy: 0.0000e+00 - val_loss: 3.7785 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "42/42 - 0s - loss: 25.0912 - accuracy: 0.0000e+00 - val_loss: 1.3648 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "42/42 - 0s - loss: 12.8710 - accuracy: 0.0000e+00 - val_loss: 0.1864 - val_accuracy: 0.0000e+00\n",
      "47/47 - 0s\n",
      "7/7 - 0s\n",
      "Training MAPE------------------- 2.9069654003422203\n",
      "Test MAPE------------------- 2.130608386494893\n"
     ]
    }
   ],
   "source": [
    "model_parameters = pd.DataFrame(columns = ['training_MAPE','test_MAPE','Parameters'])\n",
    "for p in grid:\n",
    "    test = pd.DataFrame()\n",
    "    print(p)\n",
    "\n",
    "    model = Sequential([\n",
    "        LSTM(units=p['n_units'], input_shape=(p['n_timesteps'], n_features), activation='relu',return_sequences=True),\n",
    "        LSTM(p['n_units'], activation='relu',return_sequences=True),\n",
    "        LSTM(p['n_units'], activation='relu'),\n",
    "        Dense(units=1)\n",
    "    ])\n",
    "    #compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['accuracy'])\n",
    "    \n",
    "    #train the model\n",
    "    model.fit(x, y, batch_size=1, validation_split=0.1, epochs=p['n_epoch'], verbose=2)\n",
    "\n",
    "    #Predict\n",
    "    training_forecast = model.predict(x, batch_size = 1, verbose = 2)\n",
    "    test_forecast = model.predict(x_test, batch_size = 1, verbose = 2)\n",
    "    \n",
    "    training_mape = mean_absolute_percentage_error(mape_training_values,training_forecast,)\n",
    "    test_mape = mean_absolute_percentage_error(mape_test_values,test_forecast)\n",
    "    print('Training MAPE-------------------',training_mape)\n",
    "    print('Test MAPE-------------------',test_mape)\n",
    "    model_parameters = model_parameters.append({'training_MAPE':training_mape,\n",
    "                                                'test_MAPE':test_mape,\n",
    "                                                'Parameters':p},ignore_index=True)\n",
    "#     model_parameters = model_parameters.append({'MAPE':MAPE,'Parameters':p},ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_epoch': 50, 'n_timesteps': 1, 'n_units': 50}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = model_parameters.sort_values(by=['test_MAPE'])\n",
    "parameters = parameters.reset_index(drop=True)\n",
    "parameters.head()\n",
    "n_epoch = parameters['Parameters'][0]['n_epoch']\n",
    "n_timesteps = parameters['Parameters'][0]['n_timesteps']\n",
    "n_units = parameters['Parameters'][0]['n_units']\n",
    "parameters['Parameters'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_99 (LSTM)               (None, 1, 50)             10400     \n",
      "_________________________________________________________________\n",
      "lstm_100 (LSTM)              (None, 1, 50)             20200     \n",
      "_________________________________________________________________\n",
      "lstm_101 (LSTM)              (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 50,851\n",
      "Trainable params: 50,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_model = Sequential([\n",
    "        LSTM(units=n_units, input_shape=(n_timesteps, n_features), activation='relu',return_sequences=True),\n",
    "        LSTM(n_units, activation='relu',return_sequences=True),\n",
    "        LSTM(n_units, activation='relu'),\n",
    "        Dense(units=1)\n",
    "    ])\n",
    "n_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 1.3576 - accuracy: 0.0000e+00 - val_loss: 0.2249 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "42/42 - 0s - loss: 1.4143 - accuracy: 0.0000e+00 - val_loss: 1.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "42/42 - 0s - loss: 1.3493 - accuracy: 0.0000e+00 - val_loss: 1.2843 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "42/42 - 0s - loss: 1.0577 - accuracy: 0.0000e+00 - val_loss: 1.2115 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "42/42 - 0s - loss: 1.8142 - accuracy: 0.0000e+00 - val_loss: 0.0866 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "42/42 - 0s - loss: 1.1227 - accuracy: 0.0000e+00 - val_loss: 0.2166 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "42/42 - 0s - loss: 1.3033 - accuracy: 0.0000e+00 - val_loss: 0.7113 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "42/42 - 0s - loss: 1.7211 - accuracy: 0.0000e+00 - val_loss: 0.2908 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "42/42 - 0s - loss: 1.7453 - accuracy: 0.0000e+00 - val_loss: 0.8242 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "42/42 - 0s - loss: 1.4901 - accuracy: 0.0000e+00 - val_loss: 0.3259 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "42/42 - 0s - loss: 1.3522 - accuracy: 0.0000e+00 - val_loss: 0.3559 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "42/42 - 0s - loss: 0.7126 - accuracy: 0.0000e+00 - val_loss: 0.0667 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "42/42 - 0s - loss: 1.6902 - accuracy: 0.0000e+00 - val_loss: 0.1409 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "42/42 - 0s - loss: 1.2493 - accuracy: 0.0000e+00 - val_loss: 2.0168 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "42/42 - 0s - loss: 1.1074 - accuracy: 0.0000e+00 - val_loss: 0.3246 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "42/42 - 0s - loss: 1.1014 - accuracy: 0.0000e+00 - val_loss: 0.1405 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "42/42 - 0s - loss: 1.0934 - accuracy: 0.0000e+00 - val_loss: 1.2403 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "42/42 - 0s - loss: 0.8986 - accuracy: 0.0000e+00 - val_loss: 0.7446 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "42/42 - 0s - loss: 0.8755 - accuracy: 0.0000e+00 - val_loss: 0.2104 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "42/42 - 0s - loss: 1.7891 - accuracy: 0.0000e+00 - val_loss: 1.0549 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "42/42 - 0s - loss: 1.6779 - accuracy: 0.0000e+00 - val_loss: 0.1858 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "42/42 - 0s - loss: 0.7616 - accuracy: 0.0000e+00 - val_loss: 0.3014 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "42/42 - 0s - loss: 1.7503 - accuracy: 0.0000e+00 - val_loss: 0.5858 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "42/42 - 0s - loss: 1.6179 - accuracy: 0.0000e+00 - val_loss: 3.9617 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "42/42 - 0s - loss: 2.4953 - accuracy: 0.0000e+00 - val_loss: 0.0649 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "42/42 - 0s - loss: 1.1852 - accuracy: 0.0000e+00 - val_loss: 1.1916 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "42/42 - 0s - loss: 1.8139 - accuracy: 0.0000e+00 - val_loss: 0.5684 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "42/42 - 0s - loss: 0.9174 - accuracy: 0.0000e+00 - val_loss: 0.1895 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "42/42 - 0s - loss: 1.0136 - accuracy: 0.0000e+00 - val_loss: 0.8115 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "42/42 - 0s - loss: 0.9173 - accuracy: 0.0000e+00 - val_loss: 0.3598 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "42/42 - 0s - loss: 0.8412 - accuracy: 0.0000e+00 - val_loss: 0.5399 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "42/42 - 0s - loss: 1.5699 - accuracy: 0.0000e+00 - val_loss: 0.2432 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "42/42 - 0s - loss: 1.3554 - accuracy: 0.0000e+00 - val_loss: 2.5387 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "42/42 - 0s - loss: 1.3748 - accuracy: 0.0000e+00 - val_loss: 0.4220 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "42/42 - 0s - loss: 1.0376 - accuracy: 0.0000e+00 - val_loss: 0.6282 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "42/42 - 0s - loss: 0.8942 - accuracy: 0.0000e+00 - val_loss: 0.3425 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "42/42 - 0s - loss: 1.3924 - accuracy: 0.0000e+00 - val_loss: 0.3685 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "42/42 - 0s - loss: 1.4676 - accuracy: 0.0000e+00 - val_loss: 0.7009 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "42/42 - 0s - loss: 1.4034 - accuracy: 0.0000e+00 - val_loss: 0.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "42/42 - 0s - loss: 1.4286 - accuracy: 0.0000e+00 - val_loss: 1.6640 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "42/42 - 0s - loss: 1.5313 - accuracy: 0.0000e+00 - val_loss: 0.2080 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "42/42 - 0s - loss: 1.0370 - accuracy: 0.0000e+00 - val_loss: 0.0576 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "42/42 - 0s - loss: 0.7559 - accuracy: 0.0000e+00 - val_loss: 1.2848 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "42/42 - 0s - loss: 0.9643 - accuracy: 0.0000e+00 - val_loss: 0.3502 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "42/42 - 0s - loss: 1.4362 - accuracy: 0.0000e+00 - val_loss: 2.2578 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "42/42 - 0s - loss: 1.3249 - accuracy: 0.0000e+00 - val_loss: 0.9271 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "42/42 - 0s - loss: 1.1413 - accuracy: 0.0000e+00 - val_loss: 0.8618 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "42/42 - 0s - loss: 1.0295 - accuracy: 0.0000e+00 - val_loss: 0.1035 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "42/42 - 0s - loss: 1.2272 - accuracy: 0.0000e+00 - val_loss: 0.0701 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "42/42 - 0s - loss: 1.8176 - accuracy: 0.0000e+00 - val_loss: 0.7590 - val_accuracy: 0.0000e+00\n",
      "47/47 - 0s\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "7/7 - 0s\n",
      "count 9\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 2.2878 - accuracy: 0.0000e+00 - val_loss: 2.2618 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "42/42 - 0s - loss: 1.1662 - accuracy: 0.0000e+00 - val_loss: 0.4409 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "42/42 - 0s - loss: 0.8807 - accuracy: 0.0000e+00 - val_loss: 0.5570 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "42/42 - 0s - loss: 2.3401 - accuracy: 0.0000e+00 - val_loss: 0.1811 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "42/42 - 0s - loss: 1.6542 - accuracy: 0.0000e+00 - val_loss: 0.2728 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "42/42 - 0s - loss: 1.4741 - accuracy: 0.0000e+00 - val_loss: 0.0778 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "42/42 - 0s - loss: 1.1295 - accuracy: 0.0000e+00 - val_loss: 0.2329 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "42/42 - 0s - loss: 1.1744 - accuracy: 0.0000e+00 - val_loss: 0.0752 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "42/42 - 0s - loss: 1.5389 - accuracy: 0.0000e+00 - val_loss: 2.3774 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "42/42 - 0s - loss: 2.8452 - accuracy: 0.0000e+00 - val_loss: 0.9025 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "42/42 - 0s - loss: 0.9425 - accuracy: 0.0000e+00 - val_loss: 0.1162 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "42/42 - 0s - loss: 1.3090 - accuracy: 0.0000e+00 - val_loss: 0.9457 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "42/42 - 0s - loss: 0.9664 - accuracy: 0.0000e+00 - val_loss: 0.1155 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "42/42 - 0s - loss: 0.8450 - accuracy: 0.0000e+00 - val_loss: 0.5585 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "42/42 - 0s - loss: 1.0197 - accuracy: 0.0000e+00 - val_loss: 0.1335 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "42/42 - 0s - loss: 1.1938 - accuracy: 0.0000e+00 - val_loss: 0.0738 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "42/42 - 0s - loss: 1.0562 - accuracy: 0.0000e+00 - val_loss: 0.5639 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "42/42 - 0s - loss: 1.9710 - accuracy: 0.0000e+00 - val_loss: 1.1784 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "42/42 - 0s - loss: 3.0209 - accuracy: 0.0000e+00 - val_loss: 0.0626 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "42/42 - 0s - loss: 0.9447 - accuracy: 0.0000e+00 - val_loss: 1.8504 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "42/42 - 0s - loss: 1.0988 - accuracy: 0.0000e+00 - val_loss: 0.2590 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "42/42 - 0s - loss: 0.8927 - accuracy: 0.0000e+00 - val_loss: 0.1257 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "42/42 - 0s - loss: 0.7891 - accuracy: 0.0000e+00 - val_loss: 0.1936 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "42/42 - 0s - loss: 0.9870 - accuracy: 0.0000e+00 - val_loss: 1.0644 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "42/42 - 0s - loss: 1.6265 - accuracy: 0.0000e+00 - val_loss: 0.1946 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "42/42 - 0s - loss: 1.1950 - accuracy: 0.0000e+00 - val_loss: 0.0661 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "42/42 - 0s - loss: 1.5262 - accuracy: 0.0000e+00 - val_loss: 1.2466 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "42/42 - 0s - loss: 1.1092 - accuracy: 0.0000e+00 - val_loss: 0.5740 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "42/42 - 0s - loss: 0.9651 - accuracy: 0.0000e+00 - val_loss: 0.1844 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "42/42 - 0s - loss: 1.6661 - accuracy: 0.0000e+00 - val_loss: 0.4514 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "42/42 - 0s - loss: 1.0548 - accuracy: 0.0000e+00 - val_loss: 0.1869 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "42/42 - 0s - loss: 1.0147 - accuracy: 0.0000e+00 - val_loss: 0.1436 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "42/42 - 0s - loss: 0.7982 - accuracy: 0.0000e+00 - val_loss: 2.8381 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "42/42 - 0s - loss: 2.4716 - accuracy: 0.0000e+00 - val_loss: 0.1302 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "42/42 - 0s - loss: 1.0118 - accuracy: 0.0000e+00 - val_loss: 0.3813 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "42/42 - 0s - loss: 0.8456 - accuracy: 0.0000e+00 - val_loss: 0.1924 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "42/42 - 0s - loss: 0.8569 - accuracy: 0.0000e+00 - val_loss: 0.3271 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "42/42 - 0s - loss: 1.1805 - accuracy: 0.0000e+00 - val_loss: 0.0557 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "42/42 - 0s - loss: 0.7640 - accuracy: 0.0000e+00 - val_loss: 1.4459 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "42/42 - 0s - loss: 1.2758 - accuracy: 0.0000e+00 - val_loss: 0.1728 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "42/42 - 0s - loss: 0.8274 - accuracy: 0.0000e+00 - val_loss: 0.3926 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "42/42 - 0s - loss: 0.9973 - accuracy: 0.0000e+00 - val_loss: 0.2439 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "42/42 - 0s - loss: 0.9847 - accuracy: 0.0000e+00 - val_loss: 0.5420 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "42/42 - 0s - loss: 2.0610 - accuracy: 0.0000e+00 - val_loss: 0.3495 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "42/42 - 0s - loss: 0.9800 - accuracy: 0.0000e+00 - val_loss: 1.4147 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "42/42 - 0s - loss: 1.5223 - accuracy: 0.0000e+00 - val_loss: 0.1181 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "42/42 - 0s - loss: 2.4281 - accuracy: 0.0000e+00 - val_loss: 0.0914 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "42/42 - 0s - loss: 1.2990 - accuracy: 0.0000e+00 - val_loss: 0.1524 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "42/42 - 0s - loss: 1.2177 - accuracy: 0.0000e+00 - val_loss: 1.0479 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "42/42 - 0s - loss: 1.8690 - accuracy: 0.0000e+00 - val_loss: 0.2501 - val_accuracy: 0.0000e+00\n",
      "47/47 - 0s\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "7/7 - 0s\n",
      "count 8\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 2.6482 - accuracy: 0.0000e+00 - val_loss: 0.2151 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "42/42 - 0s - loss: 1.0917 - accuracy: 0.0000e+00 - val_loss: 0.2430 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "42/42 - 0s - loss: 1.0976 - accuracy: 0.0000e+00 - val_loss: 0.1262 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "42/42 - 0s - loss: 0.8672 - accuracy: 0.0000e+00 - val_loss: 0.0658 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "42/42 - 0s - loss: 2.0150 - accuracy: 0.0000e+00 - val_loss: 2.4158 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "42/42 - 0s - loss: 1.7499 - accuracy: 0.0000e+00 - val_loss: 0.0591 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "42/42 - 0s - loss: 0.9374 - accuracy: 0.0000e+00 - val_loss: 0.1009 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "42/42 - 0s - loss: 0.8690 - accuracy: 0.0000e+00 - val_loss: 0.6462 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "42/42 - 0s - loss: 1.4753 - accuracy: 0.0000e+00 - val_loss: 0.0791 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "42/42 - 0s - loss: 0.9857 - accuracy: 0.0000e+00 - val_loss: 0.6423 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "42/42 - 0s - loss: 1.5033 - accuracy: 0.0000e+00 - val_loss: 0.8196 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "42/42 - 0s - loss: 1.4379 - accuracy: 0.0000e+00 - val_loss: 0.0769 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "42/42 - 0s - loss: 1.7878 - accuracy: 0.0000e+00 - val_loss: 0.8245 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "42/42 - 0s - loss: 1.4904 - accuracy: 0.0000e+00 - val_loss: 0.3868 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "42/42 - 0s - loss: 0.9358 - accuracy: 0.0000e+00 - val_loss: 0.4935 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "42/42 - 0s - loss: 1.1645 - accuracy: 0.0000e+00 - val_loss: 0.1596 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "42/42 - 0s - loss: 1.7853 - accuracy: 0.0000e+00 - val_loss: 0.3791 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "42/42 - 0s - loss: 1.0855 - accuracy: 0.0000e+00 - val_loss: 0.0642 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "42/42 - 0s - loss: 0.9215 - accuracy: 0.0000e+00 - val_loss: 0.0624 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "42/42 - 0s - loss: 0.9676 - accuracy: 0.0000e+00 - val_loss: 1.1943 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "42/42 - 0s - loss: 0.9873 - accuracy: 0.0000e+00 - val_loss: 0.1229 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "42/42 - 0s - loss: 1.5067 - accuracy: 0.0000e+00 - val_loss: 0.0904 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "42/42 - 0s - loss: 2.1390 - accuracy: 0.0000e+00 - val_loss: 0.0642 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "42/42 - 0s - loss: 1.7792 - accuracy: 0.0000e+00 - val_loss: 0.0639 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "42/42 - 0s - loss: 1.1502 - accuracy: 0.0000e+00 - val_loss: 0.4628 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "42/42 - 0s - loss: 1.9578 - accuracy: 0.0000e+00 - val_loss: 0.4548 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "42/42 - 0s - loss: 1.4103 - accuracy: 0.0000e+00 - val_loss: 1.5911 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "42/42 - 0s - loss: 0.7521 - accuracy: 0.0000e+00 - val_loss: 0.0608 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "42/42 - 0s - loss: 1.3114 - accuracy: 0.0000e+00 - val_loss: 0.3206 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "42/42 - 0s - loss: 1.1948 - accuracy: 0.0000e+00 - val_loss: 0.0612 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "42/42 - 0s - loss: 1.4284 - accuracy: 0.0000e+00 - val_loss: 0.6260 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "42/42 - 0s - loss: 1.6024 - accuracy: 0.0000e+00 - val_loss: 0.0935 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "42/42 - 0s - loss: 0.6343 - accuracy: 0.0000e+00 - val_loss: 0.1119 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "42/42 - 0s - loss: 1.7121 - accuracy: 0.0000e+00 - val_loss: 1.5731 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "42/42 - 0s - loss: 2.3369 - accuracy: 0.0000e+00 - val_loss: 0.3252 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "42/42 - 0s - loss: 1.0623 - accuracy: 0.0000e+00 - val_loss: 0.1276 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "42/42 - 0s - loss: 1.0638 - accuracy: 0.0000e+00 - val_loss: 0.2395 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "42/42 - 0s - loss: 1.1118 - accuracy: 0.0000e+00 - val_loss: 0.0595 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "42/42 - 0s - loss: 1.2963 - accuracy: 0.0000e+00 - val_loss: 0.1979 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "42/42 - 0s - loss: 1.2450 - accuracy: 0.0000e+00 - val_loss: 0.3038 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "42/42 - 0s - loss: 1.7874 - accuracy: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "42/42 - 0s - loss: 1.4064 - accuracy: 0.0000e+00 - val_loss: 1.4655 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "42/42 - 0s - loss: 1.3822 - accuracy: 0.0000e+00 - val_loss: 0.4600 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "42/42 - 0s - loss: 1.3216 - accuracy: 0.0000e+00 - val_loss: 0.8582 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "42/42 - 0s - loss: 1.2244 - accuracy: 0.0000e+00 - val_loss: 0.6790 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "42/42 - 0s - loss: 0.7783 - accuracy: 0.0000e+00 - val_loss: 0.0636 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "42/42 - 0s - loss: 1.4306 - accuracy: 0.0000e+00 - val_loss: 0.0639 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "42/42 - 0s - loss: 1.5635 - accuracy: 0.0000e+00 - val_loss: 0.4894 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "42/42 - 0s - loss: 0.9843 - accuracy: 0.0000e+00 - val_loss: 1.9449 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "42/42 - 0s - loss: 1.6924 - accuracy: 0.0000e+00 - val_loss: 0.3146 - val_accuracy: 0.0000e+00\n",
      "47/47 - 0s\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "7/7 - 0s\n",
      "count 7\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 1.4928 - accuracy: 0.0000e+00 - val_loss: 1.4487 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "42/42 - 0s - loss: 2.4015 - accuracy: 0.0000e+00 - val_loss: 1.2612 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "42/42 - 0s - loss: 2.1287 - accuracy: 0.0000e+00 - val_loss: 0.0717 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "42/42 - 0s - loss: 0.8770 - accuracy: 0.0000e+00 - val_loss: 3.2608 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "42/42 - 0s - loss: 1.1753 - accuracy: 0.0000e+00 - val_loss: 0.3476 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "42/42 - 0s - loss: 1.2935 - accuracy: 0.0000e+00 - val_loss: 0.0611 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "42/42 - 0s - loss: 0.8829 - accuracy: 0.0000e+00 - val_loss: 0.1378 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "42/42 - 0s - loss: 1.0326 - accuracy: 0.0000e+00 - val_loss: 0.0589 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "42/42 - 0s - loss: 0.7142 - accuracy: 0.0000e+00 - val_loss: 0.6991 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "42/42 - 0s - loss: 1.1629 - accuracy: 0.0000e+00 - val_loss: 0.0926 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "42/42 - 0s - loss: 2.0836 - accuracy: 0.0000e+00 - val_loss: 0.1896 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "42/42 - 0s - loss: 1.3162 - accuracy: 0.0000e+00 - val_loss: 1.2390 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "42/42 - 0s - loss: 1.9462 - accuracy: 0.0000e+00 - val_loss: 1.5761 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "42/42 - 0s - loss: 1.3574 - accuracy: 0.0000e+00 - val_loss: 0.1305 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "42/42 - 0s - loss: 0.9578 - accuracy: 0.0000e+00 - val_loss: 1.4386 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "42/42 - 0s - loss: 1.1520 - accuracy: 0.0000e+00 - val_loss: 0.4104 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "42/42 - 0s - loss: 0.7317 - accuracy: 0.0000e+00 - val_loss: 0.3043 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "42/42 - 0s - loss: 0.8825 - accuracy: 0.0000e+00 - val_loss: 0.8975 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "42/42 - 0s - loss: 0.8654 - accuracy: 0.0000e+00 - val_loss: 0.3675 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "42/42 - 0s - loss: 0.9523 - accuracy: 0.0000e+00 - val_loss: 0.2044 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "42/42 - 0s - loss: 1.1896 - accuracy: 0.0000e+00 - val_loss: 0.0597 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "42/42 - 0s - loss: 0.8788 - accuracy: 0.0000e+00 - val_loss: 0.4960 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "42/42 - 0s - loss: 0.9125 - accuracy: 0.0000e+00 - val_loss: 1.0587 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "42/42 - 0s - loss: 1.3670 - accuracy: 0.0000e+00 - val_loss: 0.4808 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "42/42 - 0s - loss: 1.1001 - accuracy: 0.0000e+00 - val_loss: 0.6606 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "42/42 - 0s - loss: 1.3270 - accuracy: 0.0000e+00 - val_loss: 1.4898 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "42/42 - 0s - loss: 1.9571 - accuracy: 0.0000e+00 - val_loss: 0.0604 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "42/42 - 0s - loss: 0.7697 - accuracy: 0.0000e+00 - val_loss: 0.3080 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "42/42 - 0s - loss: 1.2954 - accuracy: 0.0000e+00 - val_loss: 2.8340 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "42/42 - 0s - loss: 1.6309 - accuracy: 0.0000e+00 - val_loss: 0.1302 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "42/42 - 0s - loss: 0.7731 - accuracy: 0.0000e+00 - val_loss: 1.4404 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "42/42 - 0s - loss: 1.7945 - accuracy: 0.0000e+00 - val_loss: 0.9055 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "42/42 - 0s - loss: 1.0303 - accuracy: 0.0000e+00 - val_loss: 0.9518 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "42/42 - 0s - loss: 1.5680 - accuracy: 0.0000e+00 - val_loss: 2.1973 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "42/42 - 0s - loss: 1.7961 - accuracy: 0.0000e+00 - val_loss: 0.3391 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "42/42 - 0s - loss: 0.9184 - accuracy: 0.0000e+00 - val_loss: 0.1857 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "42/42 - 0s - loss: 1.7521 - accuracy: 0.0000e+00 - val_loss: 1.0123 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "42/42 - 0s - loss: 0.8897 - accuracy: 0.0000e+00 - val_loss: 0.2502 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "42/42 - 0s - loss: 1.9806 - accuracy: 0.0000e+00 - val_loss: 2.1581 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "42/42 - 0s - loss: 1.5772 - accuracy: 0.0000e+00 - val_loss: 0.5338 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "42/42 - 0s - loss: 1.0438 - accuracy: 0.0000e+00 - val_loss: 2.5162 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "42/42 - 0s - loss: 1.6118 - accuracy: 0.0000e+00 - val_loss: 0.1869 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "42/42 - 0s - loss: 1.7743 - accuracy: 0.0000e+00 - val_loss: 3.7738 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "42/42 - 0s - loss: 1.8689 - accuracy: 0.0000e+00 - val_loss: 0.1772 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "42/42 - 0s - loss: 0.8855 - accuracy: 0.0000e+00 - val_loss: 1.8738 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "42/42 - 0s - loss: 2.7923 - accuracy: 0.0000e+00 - val_loss: 0.1242 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "42/42 - 0s - loss: 1.0571 - accuracy: 0.0000e+00 - val_loss: 0.3735 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "42/42 - 0s - loss: 1.1379 - accuracy: 0.0000e+00 - val_loss: 0.2804 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "42/42 - 0s - loss: 1.3567 - accuracy: 0.0000e+00 - val_loss: 2.5331 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "42/42 - 0s - loss: 1.3525 - accuracy: 0.0000e+00 - val_loss: 0.8919 - val_accuracy: 0.0000e+00\n",
      "47/47 - 0s\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "7/7 - 0s\n",
      "count 6\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 1.4922 - accuracy: 0.0000e+00 - val_loss: 0.5653 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "42/42 - 0s - loss: 0.9196 - accuracy: 0.0000e+00 - val_loss: 0.0829 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "42/42 - 0s - loss: 0.9450 - accuracy: 0.0000e+00 - val_loss: 0.8314 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "42/42 - 0s - loss: 1.6207 - accuracy: 0.0000e+00 - val_loss: 0.6445 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "42/42 - 0s - loss: 1.7524 - accuracy: 0.0000e+00 - val_loss: 0.1193 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "42/42 - 0s - loss: 1.6828 - accuracy: 0.0000e+00 - val_loss: 0.0589 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "42/42 - 0s - loss: 1.2252 - accuracy: 0.0000e+00 - val_loss: 0.0984 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "42/42 - 0s - loss: 1.4082 - accuracy: 0.0000e+00 - val_loss: 1.8160 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "42/42 - 0s - loss: 2.1418 - accuracy: 0.0000e+00 - val_loss: 0.7781 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "42/42 - 0s - loss: 2.1296 - accuracy: 0.0000e+00 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "42/42 - 0s - loss: 1.1095 - accuracy: 0.0000e+00 - val_loss: 0.1461 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "42/42 - 0s - loss: 1.2927 - accuracy: 0.0000e+00 - val_loss: 1.2654 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "42/42 - 0s - loss: 0.8076 - accuracy: 0.0000e+00 - val_loss: 0.9801 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "42/42 - 0s - loss: 1.0368 - accuracy: 0.0000e+00 - val_loss: 0.4978 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "42/42 - 0s - loss: 0.8878 - accuracy: 0.0000e+00 - val_loss: 0.2126 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "42/42 - 0s - loss: 0.9470 - accuracy: 0.0000e+00 - val_loss: 0.1641 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "42/42 - 0s - loss: 1.1351 - accuracy: 0.0000e+00 - val_loss: 1.5429 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "42/42 - 0s - loss: 1.1437 - accuracy: 0.0000e+00 - val_loss: 1.4020 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "42/42 - 0s - loss: 1.3666 - accuracy: 0.0000e+00 - val_loss: 0.0630 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "42/42 - 0s - loss: 0.7127 - accuracy: 0.0000e+00 - val_loss: 0.0764 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "42/42 - 0s - loss: 1.2143 - accuracy: 0.0000e+00 - val_loss: 0.1865 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "42/42 - 0s - loss: 1.1662 - accuracy: 0.0000e+00 - val_loss: 0.0646 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "42/42 - 0s - loss: 1.9258 - accuracy: 0.0000e+00 - val_loss: 0.3154 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "42/42 - 0s - loss: 1.1072 - accuracy: 0.0000e+00 - val_loss: 1.5098 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "42/42 - 0s - loss: 1.5253 - accuracy: 0.0000e+00 - val_loss: 0.6762 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "42/42 - 0s - loss: 1.1929 - accuracy: 0.0000e+00 - val_loss: 0.8458 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "42/42 - 0s - loss: 1.4336 - accuracy: 0.0000e+00 - val_loss: 0.3824 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "42/42 - 0s - loss: 0.8367 - accuracy: 0.0000e+00 - val_loss: 0.3591 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "42/42 - 0s - loss: 1.1386 - accuracy: 0.0000e+00 - val_loss: 0.1625 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "42/42 - 0s - loss: 1.4089 - accuracy: 0.0000e+00 - val_loss: 0.0641 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "42/42 - 0s - loss: 1.4409 - accuracy: 0.0000e+00 - val_loss: 0.0591 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "42/42 - 0s - loss: 0.9781 - accuracy: 0.0000e+00 - val_loss: 0.0898 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "42/42 - 0s - loss: 0.7933 - accuracy: 0.0000e+00 - val_loss: 0.3091 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "42/42 - 0s - loss: 0.9821 - accuracy: 0.0000e+00 - val_loss: 0.1812 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "42/42 - 0s - loss: 1.8960 - accuracy: 0.0000e+00 - val_loss: 0.1334 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "42/42 - 0s - loss: 1.6746 - accuracy: 0.0000e+00 - val_loss: 2.2681 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "42/42 - 0s - loss: 1.1040 - accuracy: 0.0000e+00 - val_loss: 0.1658 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "42/42 - 0s - loss: 1.2554 - accuracy: 0.0000e+00 - val_loss: 1.5806 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "42/42 - 0s - loss: 1.6748 - accuracy: 0.0000e+00 - val_loss: 0.4532 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "42/42 - 0s - loss: 1.4597 - accuracy: 0.0000e+00 - val_loss: 0.5299 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "42/42 - 0s - loss: 1.1524 - accuracy: 0.0000e+00 - val_loss: 0.1475 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "42/42 - 0s - loss: 1.0876 - accuracy: 0.0000e+00 - val_loss: 0.6962 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "42/42 - 0s - loss: 0.8075 - accuracy: 0.0000e+00 - val_loss: 0.0825 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "42/42 - 0s - loss: 1.4740 - accuracy: 0.0000e+00 - val_loss: 0.0621 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "42/42 - 0s - loss: 0.8604 - accuracy: 0.0000e+00 - val_loss: 1.0856 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "42/42 - 0s - loss: 1.4467 - accuracy: 0.0000e+00 - val_loss: 1.0852 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "42/42 - 0s - loss: 1.0839 - accuracy: 0.0000e+00 - val_loss: 0.6750 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "42/42 - 0s - loss: 1.4194 - accuracy: 0.0000e+00 - val_loss: 0.3380 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "42/42 - 0s - loss: 0.8971 - accuracy: 0.0000e+00 - val_loss: 0.6553 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "42/42 - 0s - loss: 0.8274 - accuracy: 0.0000e+00 - val_loss: 0.0901 - val_accuracy: 0.0000e+00\n",
      "47/47 - 0s\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "7/7 - 0s\n",
      "count 5\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 1.6406 - accuracy: 0.0000e+00 - val_loss: 0.3535 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "42/42 - 0s - loss: 1.0082 - accuracy: 0.0000e+00 - val_loss: 0.0585 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "42/42 - 0s - loss: 0.9545 - accuracy: 0.0000e+00 - val_loss: 0.0561 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "42/42 - 0s - loss: 1.3926 - accuracy: 0.0000e+00 - val_loss: 0.0630 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "42/42 - 0s - loss: 0.7981 - accuracy: 0.0000e+00 - val_loss: 0.9227 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "42/42 - 0s - loss: 0.8616 - accuracy: 0.0000e+00 - val_loss: 0.5510 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "42/42 - 0s - loss: 1.6838 - accuracy: 0.0000e+00 - val_loss: 0.5671 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "42/42 - 0s - loss: 1.0206 - accuracy: 0.0000e+00 - val_loss: 0.3191 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "42/42 - 0s - loss: 1.8587 - accuracy: 0.0000e+00 - val_loss: 0.1408 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "42/42 - 0s - loss: 1.3316 - accuracy: 0.0000e+00 - val_loss: 0.6374 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "42/42 - 0s - loss: 1.7286 - accuracy: 0.0000e+00 - val_loss: 1.2163 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "42/42 - 0s - loss: 0.9506 - accuracy: 0.0000e+00 - val_loss: 0.7754 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "42/42 - 0s - loss: 0.8063 - accuracy: 0.0000e+00 - val_loss: 0.3867 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "42/42 - 0s - loss: 0.9206 - accuracy: 0.0000e+00 - val_loss: 0.1737 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "42/42 - 0s - loss: 1.4223 - accuracy: 0.0000e+00 - val_loss: 0.0539 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "42/42 - 0s - loss: 0.8256 - accuracy: 0.0000e+00 - val_loss: 0.0576 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "42/42 - 0s - loss: 1.1751 - accuracy: 0.0000e+00 - val_loss: 0.4929 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "42/42 - 0s - loss: 1.8925 - accuracy: 0.0000e+00 - val_loss: 2.0049 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "42/42 - 0s - loss: 1.0921 - accuracy: 0.0000e+00 - val_loss: 0.0675 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "42/42 - 0s - loss: 1.6790 - accuracy: 0.0000e+00 - val_loss: 0.2194 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "42/42 - 0s - loss: 0.7527 - accuracy: 0.0000e+00 - val_loss: 0.1820 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "42/42 - 0s - loss: 0.8498 - accuracy: 0.0000e+00 - val_loss: 0.2812 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "42/42 - 0s - loss: 1.0265 - accuracy: 0.0000e+00 - val_loss: 0.8440 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "42/42 - 0s - loss: 0.9493 - accuracy: 0.0000e+00 - val_loss: 1.4350 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "42/42 - 0s - loss: 0.7395 - accuracy: 0.0000e+00 - val_loss: 0.9808 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "42/42 - 0s - loss: 1.6274 - accuracy: 0.0000e+00 - val_loss: 0.1499 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "42/42 - 0s - loss: 1.3428 - accuracy: 0.0000e+00 - val_loss: 0.1311 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "42/42 - 0s - loss: 0.9318 - accuracy: 0.0000e+00 - val_loss: 0.0827 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "42/42 - 0s - loss: 0.9598 - accuracy: 0.0000e+00 - val_loss: 1.7691 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "42/42 - 0s - loss: 1.5032 - accuracy: 0.0000e+00 - val_loss: 0.3655 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "42/42 - 0s - loss: 0.8265 - accuracy: 0.0000e+00 - val_loss: 0.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "42/42 - 0s - loss: 1.0512 - accuracy: 0.0000e+00 - val_loss: 1.1332 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "42/42 - 0s - loss: 0.9094 - accuracy: 0.0000e+00 - val_loss: 2.3770 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "42/42 - 0s - loss: 1.2417 - accuracy: 0.0000e+00 - val_loss: 0.0708 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "42/42 - 0s - loss: 1.1464 - accuracy: 0.0000e+00 - val_loss: 0.1131 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "42/42 - 0s - loss: 0.8599 - accuracy: 0.0000e+00 - val_loss: 0.1763 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "42/42 - 0s - loss: 0.7743 - accuracy: 0.0000e+00 - val_loss: 1.7951 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "42/42 - 0s - loss: 1.0892 - accuracy: 0.0000e+00 - val_loss: 0.2023 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "42/42 - 0s - loss: 0.7682 - accuracy: 0.0000e+00 - val_loss: 0.1760 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "42/42 - 0s - loss: 1.6626 - accuracy: 0.0000e+00 - val_loss: 0.6682 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "42/42 - 0s - loss: 0.8090 - accuracy: 0.0000e+00 - val_loss: 0.0782 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "42/42 - 0s - loss: 0.7526 - accuracy: 0.0000e+00 - val_loss: 0.0660 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "42/42 - 0s - loss: 0.7854 - accuracy: 0.0000e+00 - val_loss: 0.8656 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "42/42 - 0s - loss: 0.8534 - accuracy: 0.0000e+00 - val_loss: 0.0990 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "42/42 - 0s - loss: 1.1103 - accuracy: 0.0000e+00 - val_loss: 0.1823 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "42/42 - 0s - loss: 2.3440 - accuracy: 0.0000e+00 - val_loss: 2.6346 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "42/42 - 0s - loss: 0.8273 - accuracy: 0.0000e+00 - val_loss: 0.2475 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "42/42 - 0s - loss: 1.0515 - accuracy: 0.0000e+00 - val_loss: 1.3325 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "42/42 - 0s - loss: 0.8364 - accuracy: 0.0000e+00 - val_loss: 0.2801 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "42/42 - 0s - loss: 1.0042 - accuracy: 0.0000e+00 - val_loss: 0.2913 - val_accuracy: 0.0000e+00\n",
      "47/47 - 0s\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "7/7 - 0s\n",
      "count 4\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 1.4931 - accuracy: 0.0000e+00 - val_loss: 0.3653 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "42/42 - 0s - loss: 0.8823 - accuracy: 0.0000e+00 - val_loss: 0.5375 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "42/42 - 0s - loss: 1.3181 - accuracy: 0.0000e+00 - val_loss: 2.0858 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "42/42 - 0s - loss: 1.7457 - accuracy: 0.0000e+00 - val_loss: 0.1939 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "42/42 - 0s - loss: 1.4860 - accuracy: 0.0000e+00 - val_loss: 0.4191 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "42/42 - 0s - loss: 1.0921 - accuracy: 0.0000e+00 - val_loss: 0.1979 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "42/42 - 0s - loss: 1.0269 - accuracy: 0.0000e+00 - val_loss: 0.3456 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "42/42 - 0s - loss: 0.8832 - accuracy: 0.0000e+00 - val_loss: 0.1345 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "42/42 - 0s - loss: 0.7734 - accuracy: 0.0000e+00 - val_loss: 1.1676 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "42/42 - 0s - loss: 1.2005 - accuracy: 0.0000e+00 - val_loss: 0.4060 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "42/42 - 0s - loss: 1.2733 - accuracy: 0.0000e+00 - val_loss: 0.8152 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "42/42 - 0s - loss: 0.7265 - accuracy: 0.0000e+00 - val_loss: 0.4394 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "42/42 - 0s - loss: 1.2492 - accuracy: 0.0000e+00 - val_loss: 0.1967 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "42/42 - 0s - loss: 1.7236 - accuracy: 0.0000e+00 - val_loss: 0.4217 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "42/42 - 0s - loss: 1.0282 - accuracy: 0.0000e+00 - val_loss: 1.6152 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "42/42 - 0s - loss: 1.1488 - accuracy: 0.0000e+00 - val_loss: 0.2173 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "42/42 - 0s - loss: 1.4518 - accuracy: 0.0000e+00 - val_loss: 0.2761 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "42/42 - 0s - loss: 0.6688 - accuracy: 0.0000e+00 - val_loss: 0.7119 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "42/42 - 0s - loss: 1.3830 - accuracy: 0.0000e+00 - val_loss: 0.0734 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "42/42 - 0s - loss: 1.4580 - accuracy: 0.0000e+00 - val_loss: 0.0570 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "42/42 - 0s - loss: 1.3574 - accuracy: 0.0000e+00 - val_loss: 0.0976 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "42/42 - 0s - loss: 1.1402 - accuracy: 0.0000e+00 - val_loss: 0.5885 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "42/42 - 0s - loss: 2.0835 - accuracy: 0.0000e+00 - val_loss: 0.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "42/42 - 0s - loss: 1.2234 - accuracy: 0.0000e+00 - val_loss: 0.2710 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "42/42 - 0s - loss: 2.3443 - accuracy: 0.0000e+00 - val_loss: 0.3014 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "42/42 - 0s - loss: 1.1715 - accuracy: 0.0000e+00 - val_loss: 2.0185 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "42/42 - 0s - loss: 1.6301 - accuracy: 0.0000e+00 - val_loss: 2.4495 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "42/42 - 0s - loss: 1.6817 - accuracy: 0.0000e+00 - val_loss: 1.1431 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "42/42 - 0s - loss: 1.3804 - accuracy: 0.0000e+00 - val_loss: 0.6738 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "42/42 - 0s - loss: 0.9000 - accuracy: 0.0000e+00 - val_loss: 0.4500 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "42/42 - 0s - loss: 0.7656 - accuracy: 0.0000e+00 - val_loss: 0.0502 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "42/42 - 0s - loss: 1.5547 - accuracy: 0.0000e+00 - val_loss: 1.6638 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "42/42 - 0s - loss: 1.2372 - accuracy: 0.0000e+00 - val_loss: 0.1301 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "42/42 - 0s - loss: 0.8698 - accuracy: 0.0000e+00 - val_loss: 0.1576 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "42/42 - 0s - loss: 1.6119 - accuracy: 0.0000e+00 - val_loss: 0.2060 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "42/42 - 0s - loss: 0.8424 - accuracy: 0.0000e+00 - val_loss: 0.0519 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "42/42 - 0s - loss: 0.8334 - accuracy: 0.0000e+00 - val_loss: 0.0562 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "42/42 - 0s - loss: 0.9414 - accuracy: 0.0000e+00 - val_loss: 0.0513 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "42/42 - 0s - loss: 1.2385 - accuracy: 0.0000e+00 - val_loss: 1.4784 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "42/42 - 0s - loss: 1.4229 - accuracy: 0.0000e+00 - val_loss: 0.2089 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "42/42 - 0s - loss: 1.1863 - accuracy: 0.0000e+00 - val_loss: 1.2384 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "42/42 - 0s - loss: 0.8550 - accuracy: 0.0000e+00 - val_loss: 0.0519 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "42/42 - 0s - loss: 1.1120 - accuracy: 0.0000e+00 - val_loss: 0.5876 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "42/42 - 0s - loss: 1.1686 - accuracy: 0.0000e+00 - val_loss: 0.2238 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "42/42 - 0s - loss: 1.6078 - accuracy: 0.0000e+00 - val_loss: 0.1690 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "42/42 - 0s - loss: 1.4496 - accuracy: 0.0000e+00 - val_loss: 1.9477 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "42/42 - 0s - loss: 1.3987 - accuracy: 0.0000e+00 - val_loss: 1.1997 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "42/42 - 0s - loss: 1.1326 - accuracy: 0.0000e+00 - val_loss: 0.0506 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "42/42 - 0s - loss: 0.7580 - accuracy: 0.0000e+00 - val_loss: 1.6347 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "42/42 - 0s - loss: 1.0066 - accuracy: 0.0000e+00 - val_loss: 0.0510 - val_accuracy: 0.0000e+00\n",
      "47/47 - 0s\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "7/7 - 0s\n",
      "count 3\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 1.1406 - accuracy: 0.0000e+00 - val_loss: 0.2384 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "42/42 - 0s - loss: 1.0417 - accuracy: 0.0000e+00 - val_loss: 0.1473 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "42/42 - 0s - loss: 1.0988 - accuracy: 0.0000e+00 - val_loss: 0.1891 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "42/42 - 0s - loss: 1.2759 - accuracy: 0.0000e+00 - val_loss: 0.1475 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "42/42 - 0s - loss: 0.7574 - accuracy: 0.0000e+00 - val_loss: 1.3722 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "42/42 - 0s - loss: 2.1077 - accuracy: 0.0000e+00 - val_loss: 1.0309 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "42/42 - 0s - loss: 1.1753 - accuracy: 0.0000e+00 - val_loss: 1.0887 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "42/42 - 0s - loss: 1.1472 - accuracy: 0.0000e+00 - val_loss: 0.5229 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "42/42 - 0s - loss: 1.4517 - accuracy: 0.0000e+00 - val_loss: 0.5308 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "42/42 - 0s - loss: 1.4504 - accuracy: 0.0000e+00 - val_loss: 0.4714 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "42/42 - 0s - loss: 1.1182 - accuracy: 0.0000e+00 - val_loss: 0.0666 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "42/42 - 0s - loss: 1.0040 - accuracy: 0.0000e+00 - val_loss: 0.0784 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "42/42 - 0s - loss: 1.0170 - accuracy: 0.0000e+00 - val_loss: 0.2221 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "42/42 - 0s - loss: 0.9367 - accuracy: 0.0000e+00 - val_loss: 0.0612 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "42/42 - 0s - loss: 1.5424 - accuracy: 0.0000e+00 - val_loss: 1.0388 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "42/42 - 0s - loss: 0.7156 - accuracy: 0.0000e+00 - val_loss: 0.0521 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "42/42 - 0s - loss: 0.8161 - accuracy: 0.0000e+00 - val_loss: 0.4151 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "42/42 - 0s - loss: 0.8885 - accuracy: 0.0000e+00 - val_loss: 0.3145 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "42/42 - 0s - loss: 0.9958 - accuracy: 0.0000e+00 - val_loss: 0.1341 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "42/42 - 0s - loss: 0.8409 - accuracy: 0.0000e+00 - val_loss: 0.1707 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "42/42 - 0s - loss: 0.9189 - accuracy: 0.0000e+00 - val_loss: 0.1816 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "42/42 - 0s - loss: 1.5046 - accuracy: 0.0000e+00 - val_loss: 1.7250 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "42/42 - 0s - loss: 1.2642 - accuracy: 0.0000e+00 - val_loss: 0.0857 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "42/42 - 0s - loss: 1.0936 - accuracy: 0.0000e+00 - val_loss: 0.3284 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "42/42 - 0s - loss: 1.3976 - accuracy: 0.0000e+00 - val_loss: 0.0583 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "42/42 - 0s - loss: 1.6423 - accuracy: 0.0000e+00 - val_loss: 1.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "42/42 - 0s - loss: 0.7534 - accuracy: 0.0000e+00 - val_loss: 0.0869 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "42/42 - 0s - loss: 1.5478 - accuracy: 0.0000e+00 - val_loss: 1.2351 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "42/42 - 0s - loss: 1.2981 - accuracy: 0.0000e+00 - val_loss: 1.1613 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "42/42 - 0s - loss: 1.0128 - accuracy: 0.0000e+00 - val_loss: 0.5034 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "42/42 - 0s - loss: 1.4069 - accuracy: 0.0000e+00 - val_loss: 0.1073 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "42/42 - 0s - loss: 1.2765 - accuracy: 0.0000e+00 - val_loss: 0.7120 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "42/42 - 0s - loss: 1.1755 - accuracy: 0.0000e+00 - val_loss: 0.5060 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "42/42 - 0s - loss: 1.0236 - accuracy: 0.0000e+00 - val_loss: 0.0539 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "42/42 - 0s - loss: 1.7246 - accuracy: 0.0000e+00 - val_loss: 0.4982 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "42/42 - 0s - loss: 0.9266 - accuracy: 0.0000e+00 - val_loss: 2.3197 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "42/42 - 0s - loss: 1.4018 - accuracy: 0.0000e+00 - val_loss: 0.1755 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "42/42 - 0s - loss: 0.7494 - accuracy: 0.0000e+00 - val_loss: 1.4174 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "42/42 - 0s - loss: 1.3568 - accuracy: 0.0000e+00 - val_loss: 1.5678 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "42/42 - 0s - loss: 0.9121 - accuracy: 0.0000e+00 - val_loss: 0.0557 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "42/42 - 0s - loss: 1.1218 - accuracy: 0.0000e+00 - val_loss: 0.3920 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "42/42 - 0s - loss: 0.7793 - accuracy: 0.0000e+00 - val_loss: 0.6418 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "42/42 - 0s - loss: 1.0336 - accuracy: 0.0000e+00 - val_loss: 1.9744 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "42/42 - 0s - loss: 1.3345 - accuracy: 0.0000e+00 - val_loss: 0.7219 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "42/42 - 0s - loss: 0.6434 - accuracy: 0.0000e+00 - val_loss: 0.1681 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "42/42 - 0s - loss: 1.3828 - accuracy: 0.0000e+00 - val_loss: 1.0306 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "42/42 - 0s - loss: 1.0936 - accuracy: 0.0000e+00 - val_loss: 1.8944 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "42/42 - 0s - loss: 1.2611 - accuracy: 0.0000e+00 - val_loss: 0.5205 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "42/42 - 0s - loss: 1.4020 - accuracy: 0.0000e+00 - val_loss: 0.1107 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "42/42 - 0s - loss: 1.7695 - accuracy: 0.0000e+00 - val_loss: 0.0510 - val_accuracy: 0.0000e+00\n",
      "47/47 - 0s\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "7/7 - 0s\n",
      "count 2\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 1.3271 - accuracy: 0.0000e+00 - val_loss: 0.5242 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "42/42 - 0s - loss: 0.7060 - accuracy: 0.0000e+00 - val_loss: 0.0543 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "42/42 - 0s - loss: 0.9460 - accuracy: 0.0000e+00 - val_loss: 0.0510 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "42/42 - 0s - loss: 0.7913 - accuracy: 0.0000e+00 - val_loss: 0.0584 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "42/42 - 0s - loss: 0.8650 - accuracy: 0.0000e+00 - val_loss: 0.2197 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "42/42 - 0s - loss: 0.8882 - accuracy: 0.0000e+00 - val_loss: 0.1983 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "42/42 - 0s - loss: 1.2265 - accuracy: 0.0000e+00 - val_loss: 0.1077 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "42/42 - 0s - loss: 1.4982 - accuracy: 0.0000e+00 - val_loss: 1.7230 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "42/42 - 0s - loss: 1.5837 - accuracy: 0.0000e+00 - val_loss: 0.0669 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "42/42 - 0s - loss: 1.1694 - accuracy: 0.0000e+00 - val_loss: 0.2649 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "42/42 - 0s - loss: 1.9558 - accuracy: 0.0000e+00 - val_loss: 0.4268 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "42/42 - 0s - loss: 1.2250 - accuracy: 0.0000e+00 - val_loss: 0.2330 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "42/42 - 0s - loss: 0.9811 - accuracy: 0.0000e+00 - val_loss: 0.1627 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "42/42 - 0s - loss: 0.6848 - accuracy: 0.0000e+00 - val_loss: 0.0527 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "42/42 - 0s - loss: 1.1907 - accuracy: 0.0000e+00 - val_loss: 2.2909 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "42/42 - 0s - loss: 0.9120 - accuracy: 0.0000e+00 - val_loss: 2.4289 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "42/42 - 0s - loss: 1.1809 - accuracy: 0.0000e+00 - val_loss: 0.1377 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "42/42 - 0s - loss: 0.7496 - accuracy: 0.0000e+00 - val_loss: 0.0745 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "42/42 - 0s - loss: 0.7084 - accuracy: 0.0000e+00 - val_loss: 0.1421 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "42/42 - 0s - loss: 0.9783 - accuracy: 0.0000e+00 - val_loss: 1.8100 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "42/42 - 0s - loss: 2.6198 - accuracy: 0.0000e+00 - val_loss: 2.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "42/42 - 0s - loss: 1.3294 - accuracy: 0.0000e+00 - val_loss: 0.7849 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "42/42 - 0s - loss: 1.2676 - accuracy: 0.0000e+00 - val_loss: 0.3059 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "42/42 - 0s - loss: 1.8894 - accuracy: 0.0000e+00 - val_loss: 0.0960 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "42/42 - 0s - loss: 2.0833 - accuracy: 0.0000e+00 - val_loss: 2.5052 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "42/42 - 0s - loss: 2.5343 - accuracy: 0.0000e+00 - val_loss: 0.3160 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "42/42 - 0s - loss: 2.2196 - accuracy: 0.0000e+00 - val_loss: 0.2745 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "42/42 - 0s - loss: 1.9571 - accuracy: 0.0000e+00 - val_loss: 1.4667 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "42/42 - 0s - loss: 3.0036 - accuracy: 0.0000e+00 - val_loss: 0.1514 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "42/42 - 0s - loss: 2.1822 - accuracy: 0.0000e+00 - val_loss: 0.1076 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "42/42 - 0s - loss: 1.5274 - accuracy: 0.0000e+00 - val_loss: 0.0954 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "42/42 - 0s - loss: 1.6581 - accuracy: 0.0000e+00 - val_loss: 0.4353 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "42/42 - 0s - loss: 1.9697 - accuracy: 0.0000e+00 - val_loss: 1.9475 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "42/42 - 0s - loss: 1.9545 - accuracy: 0.0000e+00 - val_loss: 0.0894 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "42/42 - 0s - loss: 1.0878 - accuracy: 0.0000e+00 - val_loss: 0.2767 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "42/42 - 0s - loss: 1.3153 - accuracy: 0.0000e+00 - val_loss: 0.3311 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "42/42 - 0s - loss: 1.5676 - accuracy: 0.0000e+00 - val_loss: 3.6444 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "42/42 - 0s - loss: 2.2354 - accuracy: 0.0000e+00 - val_loss: 0.2697 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "42/42 - 0s - loss: 1.9068 - accuracy: 0.0000e+00 - val_loss: 0.4693 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "42/42 - 0s - loss: 1.3746 - accuracy: 0.0000e+00 - val_loss: 0.5081 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "42/42 - 0s - loss: 1.8822 - accuracy: 0.0000e+00 - val_loss: 0.4349 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "42/42 - 0s - loss: 1.6307 - accuracy: 0.0000e+00 - val_loss: 0.1722 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "42/42 - 0s - loss: 1.3755 - accuracy: 0.0000e+00 - val_loss: 0.1426 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "42/42 - 0s - loss: 1.4726 - accuracy: 0.0000e+00 - val_loss: 0.7306 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "42/42 - 0s - loss: 1.3128 - accuracy: 0.0000e+00 - val_loss: 0.1036 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "42/42 - 0s - loss: 1.4288 - accuracy: 0.0000e+00 - val_loss: 0.6723 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "42/42 - 0s - loss: 1.5346 - accuracy: 0.0000e+00 - val_loss: 0.2024 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "42/42 - 0s - loss: 1.3276 - accuracy: 0.0000e+00 - val_loss: 0.8728 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "42/42 - 0s - loss: 1.3924 - accuracy: 0.0000e+00 - val_loss: 1.8224 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "42/42 - 0s - loss: 1.7554 - accuracy: 0.0000e+00 - val_loss: 0.3060 - val_accuracy: 0.0000e+00\n",
      "47/47 - 0s\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "7/7 - 0s\n",
      "count 1\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "42/42 - 2s - loss: 2.4651 - accuracy: 0.0000e+00 - val_loss: 0.6109 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "42/42 - 0s - loss: 1.5221 - accuracy: 0.0000e+00 - val_loss: 0.1544 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "42/42 - 0s - loss: 1.6440 - accuracy: 0.0000e+00 - val_loss: 0.1580 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "42/42 - 0s - loss: 1.6320 - accuracy: 0.0000e+00 - val_loss: 0.0883 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "42/42 - 0s - loss: 1.8529 - accuracy: 0.0000e+00 - val_loss: 1.2592 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "42/42 - 0s - loss: 1.6814 - accuracy: 0.0000e+00 - val_loss: 0.2235 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "42/42 - 0s - loss: 1.1983 - accuracy: 0.0000e+00 - val_loss: 0.2880 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "42/42 - 0s - loss: 1.7206 - accuracy: 0.0000e+00 - val_loss: 0.6346 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "42/42 - 0s - loss: 1.4543 - accuracy: 0.0000e+00 - val_loss: 0.3043 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "42/42 - 0s - loss: 1.1073 - accuracy: 0.0000e+00 - val_loss: 2.8758 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "42/42 - 0s - loss: 2.2498 - accuracy: 0.0000e+00 - val_loss: 1.0904 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "42/42 - 0s - loss: 2.1084 - accuracy: 0.0000e+00 - val_loss: 0.9767 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "42/42 - 0s - loss: 1.4289 - accuracy: 0.0000e+00 - val_loss: 0.3359 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "42/42 - 0s - loss: 2.0458 - accuracy: 0.0000e+00 - val_loss: 1.0352 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "42/42 - 0s - loss: 1.5077 - accuracy: 0.0000e+00 - val_loss: 0.5887 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "42/42 - 0s - loss: 2.0397 - accuracy: 0.0000e+00 - val_loss: 0.3052 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "42/42 - 0s - loss: 1.3501 - accuracy: 0.0000e+00 - val_loss: 1.4355 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "42/42 - 0s - loss: 1.6943 - accuracy: 0.0000e+00 - val_loss: 0.5994 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "42/42 - 0s - loss: 1.5874 - accuracy: 0.0000e+00 - val_loss: 0.1750 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "42/42 - 0s - loss: 1.6621 - accuracy: 0.0000e+00 - val_loss: 0.0989 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "42/42 - 0s - loss: 1.1117 - accuracy: 0.0000e+00 - val_loss: 0.2191 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "42/42 - 0s - loss: 1.1889 - accuracy: 0.0000e+00 - val_loss: 0.2137 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "42/42 - 0s - loss: 1.6297 - accuracy: 0.0000e+00 - val_loss: 0.4168 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "42/42 - 0s - loss: 1.9835 - accuracy: 0.0000e+00 - val_loss: 1.1108 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "42/42 - 0s - loss: 1.5292 - accuracy: 0.0000e+00 - val_loss: 1.4114 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "42/42 - 0s - loss: 2.1671 - accuracy: 0.0000e+00 - val_loss: 0.1478 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "42/42 - 0s - loss: 1.2735 - accuracy: 0.0000e+00 - val_loss: 0.1801 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "42/42 - 0s - loss: 1.4369 - accuracy: 0.0000e+00 - val_loss: 0.8133 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "42/42 - 0s - loss: 1.5592 - accuracy: 0.0000e+00 - val_loss: 0.5865 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "42/42 - 0s - loss: 2.7237 - accuracy: 0.0000e+00 - val_loss: 1.3326 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "42/42 - 0s - loss: 1.3047 - accuracy: 0.0000e+00 - val_loss: 0.5593 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "42/42 - 0s - loss: 1.2698 - accuracy: 0.0000e+00 - val_loss: 0.5105 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "42/42 - 0s - loss: 1.5528 - accuracy: 0.0000e+00 - val_loss: 1.1570 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "42/42 - 1s - loss: 1.2255 - accuracy: 0.0000e+00 - val_loss: 0.0983 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "42/42 - 0s - loss: 1.6723 - accuracy: 0.0000e+00 - val_loss: 0.1012 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "42/42 - 0s - loss: 2.1468 - accuracy: 0.0000e+00 - val_loss: 0.7551 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "42/42 - 0s - loss: 1.7560 - accuracy: 0.0000e+00 - val_loss: 0.1053 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "42/42 - 0s - loss: 1.4248 - accuracy: 0.0000e+00 - val_loss: 0.2036 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "42/42 - 0s - loss: 1.3485 - accuracy: 0.0000e+00 - val_loss: 0.4166 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "42/42 - 0s - loss: 0.9766 - accuracy: 0.0000e+00 - val_loss: 0.0943 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "42/42 - 0s - loss: 1.3093 - accuracy: 0.0000e+00 - val_loss: 0.7459 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "42/42 - 0s - loss: 1.2186 - accuracy: 0.0000e+00 - val_loss: 0.2164 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "42/42 - 0s - loss: 1.1914 - accuracy: 0.0000e+00 - val_loss: 0.8819 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "42/42 - 0s - loss: 1.2396 - accuracy: 0.0000e+00 - val_loss: 0.5483 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "42/42 - 0s - loss: 1.5406 - accuracy: 0.0000e+00 - val_loss: 0.9248 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "42/42 - 0s - loss: 1.2390 - accuracy: 0.0000e+00 - val_loss: 1.1048 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "42/42 - 0s - loss: 1.1406 - accuracy: 0.0000e+00 - val_loss: 0.1585 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "42/42 - 0s - loss: 1.3780 - accuracy: 0.0000e+00 - val_loss: 1.2645 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "42/42 - 0s - loss: 1.7154 - accuracy: 0.0000e+00 - val_loss: 0.6049 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "42/42 - 0s - loss: 1.2585 - accuracy: 0.0000e+00 - val_loss: 0.6931 - val_accuracy: 0.0000e+00\n",
      "47/47 - 0s\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='lstm_99_input'), name='lstm_99_input', description=\"created by layer 'lstm_99_input'\"), but it was called on an input with incompatible shape (1, 3, 1).\n",
      "7/7 - 0s\n",
      "count 0\n"
     ]
    }
   ],
   "source": [
    "# loop through a count to compile and train the model\n",
    "cnt = 10\n",
    "for p in range(cnt):\n",
    "    #compile the model\n",
    "    n_model.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['accuracy'])\n",
    "\n",
    "    #train the model\n",
    "    n_model.fit(x, y, batch_size=1, validation_split=0.1, epochs=n_epoch, verbose=2)\n",
    "\n",
    "    #Predict\n",
    "    training_forecast = model.predict(x, batch_size = 1, verbose = 2)\n",
    "    test_forecast = n_model.predict(x_test, batch_size = 1, verbose = 2)\n",
    "    \n",
    "    cnt = cnt-1\n",
    "    \n",
    "    print ('count', cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48.686962],\n",
       "       [48.604355],\n",
       "       [48.521538],\n",
       "       [48.445263],\n",
       "       [48.383617],\n",
       "       [48.34653 ],\n",
       "       [48.34004 ],\n",
       "       [48.361416],\n",
       "       [48.40428 ],\n",
       "       [48.45777 ],\n",
       "       [48.50716 ],\n",
       "       [48.53693 ],\n",
       "       [48.53206 ],\n",
       "       [48.483627],\n",
       "       [48.387672],\n",
       "       [48.248444],\n",
       "       [48.07342 ],\n",
       "       [47.870342],\n",
       "       [47.639957],\n",
       "       [47.37739 ],\n",
       "       [47.07563 ],\n",
       "       [46.72571 ],\n",
       "       [46.318424],\n",
       "       [45.844387],\n",
       "       [45.289814],\n",
       "       [44.634834],\n",
       "       [43.86929 ],\n",
       "       [43.00969 ],\n",
       "       [42.09202 ],\n",
       "       [41.171234],\n",
       "       [40.32169 ],\n",
       "       [39.611412],\n",
       "       [39.080387],\n",
       "       [38.742325],\n",
       "       [38.58142 ],\n",
       "       [38.5517  ],\n",
       "       [38.584908],\n",
       "       [38.608192],\n",
       "       [38.569714],\n",
       "       [38.44816 ],\n",
       "       [38.243885],\n",
       "       [37.977085],\n",
       "       [37.673664],\n",
       "       [37.34366 ],\n",
       "       [36.97694 ],\n",
       "       [36.55612 ],\n",
       "       [36.06286 ]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_forecast "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.686962</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.604355</td>\n",
       "      <td>1961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.521538</td>\n",
       "      <td>1962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.445263</td>\n",
       "      <td>1963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.383617</td>\n",
       "      <td>1964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48.346531</td>\n",
       "      <td>1965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48.340038</td>\n",
       "      <td>1966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>48.361416</td>\n",
       "      <td>1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>48.404282</td>\n",
       "      <td>1968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>48.457771</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>48.507160</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>48.536930</td>\n",
       "      <td>1971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>48.532059</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>48.483627</td>\n",
       "      <td>1973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>48.387672</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>48.248444</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>48.073421</td>\n",
       "      <td>1976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>47.870342</td>\n",
       "      <td>1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>47.639957</td>\n",
       "      <td>1978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>47.377392</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>47.075630</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>46.725712</td>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>46.318424</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>45.844387</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>45.289814</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>44.634834</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>43.869289</td>\n",
       "      <td>1986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>43.009689</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>42.092018</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>41.171234</td>\n",
       "      <td>1989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>40.321690</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>39.611412</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>39.080387</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>38.742325</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>38.581421</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>38.551701</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>38.584908</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38.608192</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38.569714</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38.448158</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>38.243885</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>37.977085</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>37.673664</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>37.343658</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>36.976940</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>36.556122</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>36.062859</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        value  year\n",
       "0   48.686962  1960\n",
       "1   48.604355  1961\n",
       "2   48.521538  1962\n",
       "3   48.445263  1963\n",
       "4   48.383617  1964\n",
       "5   48.346531  1965\n",
       "6   48.340038  1966\n",
       "7   48.361416  1967\n",
       "8   48.404282  1968\n",
       "9   48.457771  1969\n",
       "10  48.507160  1970\n",
       "11  48.536930  1971\n",
       "12  48.532059  1972\n",
       "13  48.483627  1973\n",
       "14  48.387672  1974\n",
       "15  48.248444  1975\n",
       "16  48.073421  1976\n",
       "17  47.870342  1977\n",
       "18  47.639957  1978\n",
       "19  47.377392  1979\n",
       "20  47.075630  1980\n",
       "21  46.725712  1981\n",
       "22  46.318424  1982\n",
       "23  45.844387  1983\n",
       "24  45.289814  1984\n",
       "25  44.634834  1985\n",
       "26  43.869289  1986\n",
       "27  43.009689  1987\n",
       "28  42.092018  1988\n",
       "29  41.171234  1989\n",
       "30  40.321690  1990\n",
       "31  39.611412  1991\n",
       "32  39.080387  1992\n",
       "33  38.742325  1993\n",
       "34  38.581421  1994\n",
       "35  38.551701  1995\n",
       "36  38.584908  1996\n",
       "37  38.608192  1997\n",
       "38  38.569714  1998\n",
       "39  38.448158  1999\n",
       "40  38.243885  2000\n",
       "41  37.977085  2001\n",
       "42  37.673664  2002\n",
       "43  37.343658  2003\n",
       "44  36.976940  2004\n",
       "45  36.556122  2005\n",
       "46  36.062859  2006"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_df = pd.DataFrame(training_forecast, columns = ['value'])\n",
    "trained_df['year'] = years\n",
    "trained_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.413231</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.557407</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.681889</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.825817</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31.018864</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.293865</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29.674812</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       value    year\n",
       "0  34.413231     NaN\n",
       "1  33.557407     NaN\n",
       "2  32.681889     NaN\n",
       "3  31.825817  2013.0\n",
       "4  31.018864  2014.0\n",
       "5  30.293865  2015.0\n",
       "6  29.674812  2016.0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tested_df = pd.DataFrame(test_forecast, columns = ['value'])\n",
    "tested_df['year'] = test_years['year']\n",
    "tested_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"406.035937pt\" version=\"1.1\" viewBox=\"0 0 510.755625 406.035937\" width=\"510.755625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2021-08-18T16:56:40.048709</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 406.035937 \n",
       "L 510.755625 406.035937 \n",
       "L 510.755625 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 57.155625 352.463437 \n",
       "L 503.555625 352.463437 \n",
       "L 503.555625 26.303437 \n",
       "L 57.155625 26.303437 \n",
       "z\n",
       "\" style=\"fill:#eaeaf2;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path clip-path=\"url(#pc35ddb01dd)\" d=\"M 125.39274 352.463437 \n",
       "L 125.39274 26.303437 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 1970 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(105.373365 374.8475)scale(0.18 -0.18)\">\n",
       "       <defs>\n",
       "        <path d=\"M 39.359375 0 \n",
       "L 25.640625 0 \n",
       "L 25.640625 51.703125 \n",
       "Q 18.109375 44.671875 7.90625 41.3125 \n",
       "L 7.90625 53.765625 \n",
       "Q 13.28125 55.515625 19.578125 60.421875 \n",
       "Q 25.875 65.328125 28.21875 71.875 \n",
       "L 39.359375 71.875 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-49\"/>\n",
       "        <path d=\"M 4.546875 16.546875 \n",
       "L 17.828125 18.015625 \n",
       "Q 18.3125 13.96875 20.359375 12.015625 \n",
       "Q 22.40625 10.0625 25.78125 10.0625 \n",
       "Q 30.03125 10.0625 33 13.96875 \n",
       "Q 35.984375 17.875 36.8125 30.171875 \n",
       "Q 31.640625 24.171875 23.875 24.171875 \n",
       "Q 15.4375 24.171875 9.296875 30.6875 \n",
       "Q 3.171875 37.203125 3.171875 47.65625 \n",
       "Q 3.171875 58.546875 9.640625 65.203125 \n",
       "Q 16.109375 71.875 26.125 71.875 \n",
       "Q 37.015625 71.875 44 63.453125 \n",
       "Q 50.984375 55.03125 50.984375 35.75 \n",
       "Q 50.984375 16.109375 43.703125 7.421875 \n",
       "Q 36.421875 -1.265625 24.75 -1.265625 \n",
       "Q 16.359375 -1.265625 11.171875 3.203125 \n",
       "Q 6 7.671875 4.546875 16.546875 \n",
       "z\n",
       "M 35.59375 46.53125 \n",
       "Q 35.59375 53.171875 32.546875 56.828125 \n",
       "Q 29.5 60.5 25.484375 60.5 \n",
       "Q 21.6875 60.5 19.171875 57.5 \n",
       "Q 16.65625 54.5 16.65625 47.65625 \n",
       "Q 16.65625 40.71875 19.390625 37.46875 \n",
       "Q 22.125 34.234375 26.21875 34.234375 \n",
       "Q 30.171875 34.234375 32.875 37.359375 \n",
       "Q 35.59375 40.484375 35.59375 46.53125 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-57\"/>\n",
       "        <path d=\"M 4.25 57.859375 \n",
       "L 4.25 70.609375 \n",
       "L 51.171875 70.609375 \n",
       "L 51.171875 60.640625 \n",
       "Q 45.359375 54.9375 39.34375 44.234375 \n",
       "Q 33.34375 33.546875 30.1875 21.5 \n",
       "Q 27.046875 9.46875 27.09375 0 \n",
       "L 13.875 0 \n",
       "Q 14.203125 14.84375 19.984375 30.265625 \n",
       "Q 25.78125 45.703125 35.453125 57.859375 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-55\"/>\n",
       "        <path d=\"M 27.4375 71.875 \n",
       "Q 37.84375 71.875 43.703125 64.453125 \n",
       "Q 50.6875 55.671875 50.6875 35.296875 \n",
       "Q 50.6875 14.984375 43.65625 6.109375 \n",
       "Q 37.84375 -1.21875 27.4375 -1.21875 \n",
       "Q 17 -1.21875 10.59375 6.8125 \n",
       "Q 4.203125 14.84375 4.203125 35.453125 \n",
       "Q 4.203125 55.671875 11.234375 64.546875 \n",
       "Q 17.046875 71.875 27.4375 71.875 \n",
       "z\n",
       "M 27.4375 60.5 \n",
       "Q 24.953125 60.5 23 58.90625 \n",
       "Q 21.046875 57.328125 19.96875 53.21875 \n",
       "Q 18.5625 47.90625 18.5625 35.296875 \n",
       "Q 18.5625 22.703125 19.828125 17.984375 \n",
       "Q 21.09375 13.28125 23.015625 11.71875 \n",
       "Q 24.953125 10.15625 27.4375 10.15625 \n",
       "Q 29.9375 10.15625 31.890625 11.734375 \n",
       "Q 33.84375 13.328125 34.90625 17.4375 \n",
       "Q 36.328125 22.703125 36.328125 35.296875 \n",
       "Q 36.328125 47.90625 35.0625 52.609375 \n",
       "Q 33.796875 57.328125 31.859375 58.90625 \n",
       "Q 29.9375 60.5 27.4375 60.5 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-48\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#Arial-BoldMT-49\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#Arial-BoldMT-57\"/>\n",
       "       <use x=\"111.230469\" xlink:href=\"#Arial-BoldMT-55\"/>\n",
       "       <use x=\"166.845703\" xlink:href=\"#Arial-BoldMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <path clip-path=\"url(#pc35ddb01dd)\" d=\"M 201.046033 352.463437 \n",
       "L 201.046033 26.303437 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 1980 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(181.026658 374.8475)scale(0.18 -0.18)\">\n",
       "       <defs>\n",
       "        <path d=\"M 16.015625 38.625 \n",
       "Q 10.6875 40.875 8.265625 44.796875 \n",
       "Q 5.859375 48.734375 5.859375 53.421875 \n",
       "Q 5.859375 61.421875 11.453125 66.640625 \n",
       "Q 17.046875 71.875 27.34375 71.875 \n",
       "Q 37.546875 71.875 43.1875 66.640625 \n",
       "Q 48.828125 61.421875 48.828125 53.421875 \n",
       "Q 48.828125 48.4375 46.234375 44.546875 \n",
       "Q 43.65625 40.671875 38.96875 38.625 \n",
       "Q 44.921875 36.234375 48.015625 31.640625 \n",
       "Q 51.125 27.046875 51.125 21.046875 \n",
       "Q 51.125 11.140625 44.796875 4.9375 \n",
       "Q 38.484375 -1.265625 27.984375 -1.265625 \n",
       "Q 18.21875 -1.265625 11.71875 3.859375 \n",
       "Q 4.046875 9.90625 4.046875 20.453125 \n",
       "Q 4.046875 26.265625 6.921875 31.125 \n",
       "Q 9.8125 35.984375 16.015625 38.625 \n",
       "z\n",
       "M 18.84375 52.4375 \n",
       "Q 18.84375 48.34375 21.15625 46.046875 \n",
       "Q 23.484375 43.75 27.34375 43.75 \n",
       "Q 31.25 43.75 33.59375 46.0625 \n",
       "Q 35.9375 48.390625 35.9375 52.484375 \n",
       "Q 35.9375 56.34375 33.609375 58.65625 \n",
       "Q 31.296875 60.984375 27.484375 60.984375 \n",
       "Q 23.53125 60.984375 21.1875 58.640625 \n",
       "Q 18.84375 56.296875 18.84375 52.4375 \n",
       "z\n",
       "M 17.578125 21.78125 \n",
       "Q 17.578125 16.109375 20.484375 12.9375 \n",
       "Q 23.390625 9.765625 27.734375 9.765625 \n",
       "Q 31.984375 9.765625 34.765625 12.8125 \n",
       "Q 37.546875 15.875 37.546875 21.625 \n",
       "Q 37.546875 26.65625 34.71875 29.703125 \n",
       "Q 31.890625 32.765625 27.546875 32.765625 \n",
       "Q 22.515625 32.765625 20.046875 29.296875 \n",
       "Q 17.578125 25.828125 17.578125 21.78125 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-56\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#Arial-BoldMT-49\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#Arial-BoldMT-57\"/>\n",
       "       <use x=\"111.230469\" xlink:href=\"#Arial-BoldMT-56\"/>\n",
       "       <use x=\"166.845703\" xlink:href=\"#Arial-BoldMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path clip-path=\"url(#pc35ddb01dd)\" d=\"M 276.720041 352.463437 \n",
       "L 276.720041 26.303437 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 1990 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(256.700666 374.8475)scale(0.18 -0.18)\">\n",
       "       <use xlink:href=\"#Arial-BoldMT-49\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#Arial-BoldMT-57\"/>\n",
       "       <use x=\"111.230469\" xlink:href=\"#Arial-BoldMT-57\"/>\n",
       "       <use x=\"166.845703\" xlink:href=\"#Arial-BoldMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <path clip-path=\"url(#pc35ddb01dd)\" d=\"M 352.373333 352.463437 \n",
       "L 352.373333 26.303437 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 2000 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(332.353958 374.8475)scale(0.18 -0.18)\">\n",
       "       <defs>\n",
       "        <path d=\"M 50.59375 12.75 \n",
       "L 50.59375 0 \n",
       "L 2.484375 0 \n",
       "Q 3.265625 7.234375 7.171875 13.703125 \n",
       "Q 11.078125 20.171875 22.609375 30.859375 \n",
       "Q 31.890625 39.5 33.984375 42.578125 \n",
       "Q 36.8125 46.828125 36.8125 50.984375 \n",
       "Q 36.8125 55.5625 34.34375 58.03125 \n",
       "Q 31.890625 60.5 27.546875 60.5 \n",
       "Q 23.25 60.5 20.703125 57.90625 \n",
       "Q 18.171875 55.328125 17.78125 49.3125 \n",
       "L 4.109375 50.6875 \n",
       "Q 5.328125 62.015625 11.765625 66.9375 \n",
       "Q 18.21875 71.875 27.875 71.875 \n",
       "Q 38.484375 71.875 44.53125 66.15625 \n",
       "Q 50.59375 60.453125 50.59375 51.953125 \n",
       "Q 50.59375 47.125 48.859375 42.75 \n",
       "Q 47.125 38.375 43.359375 33.59375 \n",
       "Q 40.875 30.421875 34.375 24.453125 \n",
       "Q 27.875 18.5 26.140625 16.546875 \n",
       "Q 24.421875 14.59375 23.34375 12.75 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-50\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#Arial-BoldMT-50\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#Arial-BoldMT-48\"/>\n",
       "       <use x=\"111.230469\" xlink:href=\"#Arial-BoldMT-48\"/>\n",
       "       <use x=\"166.845703\" xlink:href=\"#Arial-BoldMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path clip-path=\"url(#pc35ddb01dd)\" d=\"M 428.047342 352.463437 \n",
       "L 428.047342 26.303437 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 2010 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(408.027967 374.8475)scale(0.18 -0.18)\">\n",
       "       <use xlink:href=\"#Arial-BoldMT-50\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#Arial-BoldMT-48\"/>\n",
       "       <use x=\"111.230469\" xlink:href=\"#Arial-BoldMT-49\"/>\n",
       "       <use x=\"166.845703\" xlink:href=\"#Arial-BoldMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_6\">\n",
       "     <!-- Year -->\n",
       "     <g transform=\"translate(261.334687 395.28375)scale(0.18 -0.18)\">\n",
       "      <defs>\n",
       "       <path d=\"M 26.078125 0 \n",
       "L 26.078125 30.125 \n",
       "L -0.140625 71.578125 \n",
       "L 16.796875 71.578125 \n",
       "L 33.640625 43.265625 \n",
       "L 50.140625 71.578125 \n",
       "L 66.796875 71.578125 \n",
       "L 40.484375 30.03125 \n",
       "L 40.484375 0 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-89\"/>\n",
       "       <path d=\"M 37.203125 16.5 \n",
       "L 50.875 14.203125 \n",
       "Q 48.25 6.6875 42.546875 2.75 \n",
       "Q 36.859375 -1.171875 28.328125 -1.171875 \n",
       "Q 14.796875 -1.171875 8.296875 7.671875 \n",
       "Q 3.171875 14.75 3.171875 25.53125 \n",
       "Q 3.171875 38.421875 9.90625 45.71875 \n",
       "Q 16.65625 53.03125 26.953125 53.03125 \n",
       "Q 38.53125 53.03125 45.21875 45.390625 \n",
       "Q 51.90625 37.75 51.609375 21.96875 \n",
       "L 17.234375 21.96875 \n",
       "Q 17.390625 15.875 20.5625 12.46875 \n",
       "Q 23.734375 9.078125 28.46875 9.078125 \n",
       "Q 31.6875 9.078125 33.875 10.828125 \n",
       "Q 36.078125 12.59375 37.203125 16.5 \n",
       "z\n",
       "M 37.984375 30.375 \n",
       "Q 37.84375 36.328125 34.90625 39.421875 \n",
       "Q 31.984375 42.53125 27.78125 42.53125 \n",
       "Q 23.296875 42.53125 20.359375 39.265625 \n",
       "Q 17.4375 35.984375 17.484375 30.375 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-101\"/>\n",
       "       <path d=\"M 17.4375 36.03125 \n",
       "L 4.984375 38.28125 \n",
       "Q 7.078125 45.796875 12.203125 49.40625 \n",
       "Q 17.328125 53.03125 27.4375 53.03125 \n",
       "Q 36.625 53.03125 41.109375 50.859375 \n",
       "Q 45.609375 48.6875 47.4375 45.34375 \n",
       "Q 49.265625 42 49.265625 33.0625 \n",
       "L 49.125 17.046875 \n",
       "Q 49.125 10.203125 49.78125 6.953125 \n",
       "Q 50.4375 3.71875 52.25 0 \n",
       "L 38.671875 0 \n",
       "Q 38.140625 1.375 37.359375 4.046875 \n",
       "Q 37.015625 5.28125 36.859375 5.671875 \n",
       "Q 33.34375 2.25 29.34375 0.53125 \n",
       "Q 25.34375 -1.171875 20.796875 -1.171875 \n",
       "Q 12.796875 -1.171875 8.171875 3.171875 \n",
       "Q 3.5625 7.515625 3.5625 14.15625 \n",
       "Q 3.5625 18.5625 5.65625 22 \n",
       "Q 7.765625 25.4375 11.546875 27.265625 \n",
       "Q 15.328125 29.109375 22.46875 30.46875 \n",
       "Q 32.078125 32.28125 35.796875 33.84375 \n",
       "L 35.796875 35.203125 \n",
       "Q 35.796875 39.15625 33.84375 40.84375 \n",
       "Q 31.890625 42.53125 26.46875 42.53125 \n",
       "Q 22.796875 42.53125 20.75 41.09375 \n",
       "Q 18.703125 39.65625 17.4375 36.03125 \n",
       "z\n",
       "M 35.796875 24.90625 \n",
       "Q 33.15625 24.03125 27.4375 22.796875 \n",
       "Q 21.734375 21.578125 19.96875 20.40625 \n",
       "Q 17.28125 18.5 17.28125 15.578125 \n",
       "Q 17.28125 12.703125 19.421875 10.59375 \n",
       "Q 21.578125 8.5 24.90625 8.5 \n",
       "Q 28.609375 8.5 31.984375 10.9375 \n",
       "Q 34.46875 12.796875 35.25 15.484375 \n",
       "Q 35.796875 17.234375 35.796875 22.171875 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-97\"/>\n",
       "       <path d=\"M 20.3125 0 \n",
       "L 6.59375 0 \n",
       "L 6.59375 51.859375 \n",
       "L 19.34375 51.859375 \n",
       "L 19.34375 44.484375 \n",
       "Q 22.609375 49.703125 25.21875 51.359375 \n",
       "Q 27.828125 53.03125 31.15625 53.03125 \n",
       "Q 35.84375 53.03125 40.1875 50.4375 \n",
       "L 35.9375 38.484375 \n",
       "Q 32.46875 40.71875 29.5 40.71875 \n",
       "Q 26.609375 40.71875 24.609375 39.125 \n",
       "Q 22.609375 37.546875 21.453125 33.390625 \n",
       "Q 20.3125 29.25 20.3125 16.015625 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-114\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#Arial-BoldMT-89\"/>\n",
       "      <use x=\"61.199219\" xlink:href=\"#Arial-BoldMT-101\"/>\n",
       "      <use x=\"116.814453\" xlink:href=\"#Arial-BoldMT-97\"/>\n",
       "      <use x=\"172.429688\" xlink:href=\"#Arial-BoldMT-114\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <path clip-path=\"url(#pc35ddb01dd)\" d=\"M 57.155625 352.463437 \n",
       "L 503.555625 352.463437 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 10 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(27.63625 358.905469)scale(0.18 -0.18)\">\n",
       "       <use xlink:href=\"#Arial-BoldMT-49\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#Arial-BoldMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path clip-path=\"url(#pc35ddb01dd)\" d=\"M 57.155625 298.103437 \n",
       "L 503.555625 298.103437 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 20 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(27.63625 304.545469)scale(0.18 -0.18)\">\n",
       "       <use xlink:href=\"#Arial-BoldMT-50\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#Arial-BoldMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <path clip-path=\"url(#pc35ddb01dd)\" d=\"M 57.155625 243.743437 \n",
       "L 503.555625 243.743437 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 30 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(27.63625 250.185469)scale(0.18 -0.18)\">\n",
       "       <defs>\n",
       "        <path d=\"M 3.765625 19 \n",
       "L 17.046875 20.609375 \n",
       "Q 17.671875 15.53125 20.453125 12.84375 \n",
       "Q 23.25 10.15625 27.203125 10.15625 \n",
       "Q 31.453125 10.15625 34.34375 13.375 \n",
       "Q 37.25 16.609375 37.25 22.078125 \n",
       "Q 37.25 27.25 34.46875 30.265625 \n",
       "Q 31.6875 33.296875 27.6875 33.296875 \n",
       "Q 25.046875 33.296875 21.390625 32.28125 \n",
       "L 22.90625 43.453125 \n",
       "Q 28.46875 43.3125 31.390625 45.875 \n",
       "Q 34.328125 48.4375 34.328125 52.6875 \n",
       "Q 34.328125 56.296875 32.171875 58.4375 \n",
       "Q 30.03125 60.59375 26.46875 60.59375 \n",
       "Q 22.953125 60.59375 20.453125 58.15625 \n",
       "Q 17.96875 55.71875 17.4375 51.03125 \n",
       "L 4.78125 53.171875 \n",
       "Q 6.109375 59.671875 8.765625 63.546875 \n",
       "Q 11.421875 67.4375 16.1875 69.65625 \n",
       "Q 20.953125 71.875 26.859375 71.875 \n",
       "Q 36.96875 71.875 43.0625 65.4375 \n",
       "Q 48.09375 60.15625 48.09375 53.515625 \n",
       "Q 48.09375 44.09375 37.796875 38.484375 \n",
       "Q 43.953125 37.15625 47.625 32.5625 \n",
       "Q 51.3125 27.984375 51.3125 21.484375 \n",
       "Q 51.3125 12.0625 44.421875 5.421875 \n",
       "Q 37.546875 -1.21875 27.296875 -1.21875 \n",
       "Q 17.578125 -1.21875 11.171875 4.375 \n",
       "Q 4.78125 9.96875 3.765625 19 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-51\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#Arial-BoldMT-51\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#Arial-BoldMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path clip-path=\"url(#pc35ddb01dd)\" d=\"M 57.155625 189.383437 \n",
       "L 503.555625 189.383437 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 40 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(27.63625 195.825469)scale(0.18 -0.18)\">\n",
       "       <defs>\n",
       "        <path d=\"M 31.15625 0 \n",
       "L 31.15625 14.40625 \n",
       "L 1.859375 14.40625 \n",
       "L 1.859375 26.421875 \n",
       "L 32.90625 71.875 \n",
       "L 44.4375 71.875 \n",
       "L 44.4375 26.46875 \n",
       "L 53.328125 26.46875 \n",
       "L 53.328125 14.40625 \n",
       "L 44.4375 14.40625 \n",
       "L 44.4375 0 \n",
       "z\n",
       "M 31.15625 26.46875 \n",
       "L 31.15625 50.921875 \n",
       "L 14.703125 26.46875 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-52\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#Arial-BoldMT-52\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#Arial-BoldMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <path clip-path=\"url(#pc35ddb01dd)\" d=\"M 57.155625 135.023437 \n",
       "L 503.555625 135.023437 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 50 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(27.63625 141.465469)scale(0.18 -0.18)\">\n",
       "       <defs>\n",
       "        <path d=\"M 4.4375 18.40625 \n",
       "L 18.109375 19.828125 \n",
       "Q 18.703125 15.1875 21.578125 12.46875 \n",
       "Q 24.46875 9.765625 28.21875 9.765625 \n",
       "Q 32.515625 9.765625 35.5 13.25 \n",
       "Q 38.484375 16.75 38.484375 23.78125 \n",
       "Q 38.484375 30.375 35.515625 33.671875 \n",
       "Q 32.5625 36.96875 27.828125 36.96875 \n",
       "Q 21.921875 36.96875 17.234375 31.734375 \n",
       "L 6.109375 33.34375 \n",
       "L 13.140625 70.609375 \n",
       "L 49.421875 70.609375 \n",
       "L 49.421875 57.765625 \n",
       "L 23.53125 57.765625 \n",
       "L 21.390625 45.609375 \n",
       "Q 25.984375 47.90625 30.765625 47.90625 \n",
       "Q 39.890625 47.90625 46.234375 41.265625 \n",
       "Q 52.59375 34.625 52.59375 24.03125 \n",
       "Q 52.59375 15.1875 47.46875 8.25 \n",
       "Q 40.484375 -1.21875 28.078125 -1.21875 \n",
       "Q 18.171875 -1.21875 11.921875 4.09375 \n",
       "Q 5.671875 9.421875 4.4375 18.40625 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-53\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#Arial-BoldMT-53\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#Arial-BoldMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path clip-path=\"url(#pc35ddb01dd)\" d=\"M 57.155625 80.663437 \n",
       "L 503.555625 80.663437 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 60 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(27.63625 87.105469)scale(0.18 -0.18)\">\n",
       "       <defs>\n",
       "        <path d=\"M 50.734375 54.046875 \n",
       "L 37.453125 52.59375 \n",
       "Q 36.96875 56.6875 34.90625 58.640625 \n",
       "Q 32.859375 60.59375 29.59375 60.59375 \n",
       "Q 25.25 60.59375 22.234375 56.6875 \n",
       "Q 19.234375 52.78125 18.453125 40.4375 \n",
       "Q 23.578125 46.484375 31.203125 46.484375 \n",
       "Q 39.796875 46.484375 45.921875 39.9375 \n",
       "Q 52.046875 33.40625 52.046875 23.046875 \n",
       "Q 52.046875 12.0625 45.59375 5.421875 \n",
       "Q 39.15625 -1.21875 29.046875 -1.21875 \n",
       "Q 18.21875 -1.21875 11.234375 7.203125 \n",
       "Q 4.25 15.625 4.25 34.8125 \n",
       "Q 4.25 54.5 11.515625 63.1875 \n",
       "Q 18.796875 71.875 30.421875 71.875 \n",
       "Q 38.578125 71.875 43.921875 67.3125 \n",
       "Q 49.265625 62.75 50.734375 54.046875 \n",
       "z\n",
       "M 19.625 24.125 \n",
       "Q 19.625 17.4375 22.703125 13.796875 \n",
       "Q 25.78125 10.15625 29.734375 10.15625 \n",
       "Q 33.546875 10.15625 36.078125 13.125 \n",
       "Q 38.625 16.109375 38.625 22.90625 \n",
       "Q 38.625 29.890625 35.890625 33.125 \n",
       "Q 33.15625 36.375 29.046875 36.375 \n",
       "Q 25.09375 36.375 22.359375 33.265625 \n",
       "Q 19.625 30.171875 19.625 24.125 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-54\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#Arial-BoldMT-54\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#Arial-BoldMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <path clip-path=\"url(#pc35ddb01dd)\" d=\"M 57.155625 26.303437 \n",
       "L 503.555625 26.303437 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 70 -->\n",
       "      <g style=\"fill:#262626;\" transform=\"translate(27.63625 32.745469)scale(0.18 -0.18)\">\n",
       "       <use xlink:href=\"#Arial-BoldMT-55\"/>\n",
       "       <use x=\"55.615234\" xlink:href=\"#Arial-BoldMT-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_14\">\n",
       "     <!-- Birth Rate -->\n",
       "     <g transform=\"translate(20.084062 232.386562)rotate(-90)scale(0.18 -0.18)\">\n",
       "      <defs>\n",
       "       <path d=\"M 7.328125 71.578125 \n",
       "L 35.9375 71.578125 \n",
       "Q 44.4375 71.578125 48.609375 70.875 \n",
       "Q 52.78125 70.171875 56.078125 67.921875 \n",
       "Q 59.375 65.671875 61.5625 61.9375 \n",
       "Q 63.765625 58.203125 63.765625 53.5625 \n",
       "Q 63.765625 48.53125 61.046875 44.328125 \n",
       "Q 58.34375 40.140625 53.71875 38.03125 \n",
       "Q 60.25 36.140625 63.765625 31.546875 \n",
       "Q 67.28125 26.953125 67.28125 20.75 \n",
       "Q 67.28125 15.875 65.015625 11.25 \n",
       "Q 62.75 6.640625 58.8125 3.875 \n",
       "Q 54.890625 1.125 49.125 0.484375 \n",
       "Q 45.515625 0.09375 31.6875 0 \n",
       "L 7.328125 0 \n",
       "z\n",
       "M 21.78125 59.671875 \n",
       "L 21.78125 43.109375 \n",
       "L 31.25 43.109375 \n",
       "Q 39.703125 43.109375 41.75 43.359375 \n",
       "Q 45.453125 43.796875 47.578125 45.921875 \n",
       "Q 49.703125 48.046875 49.703125 51.515625 \n",
       "Q 49.703125 54.828125 47.875 56.90625 \n",
       "Q 46.046875 58.984375 42.4375 59.421875 \n",
       "Q 40.28125 59.671875 30.078125 59.671875 \n",
       "z\n",
       "M 21.78125 31.203125 \n",
       "L 21.78125 12.0625 \n",
       "L 35.15625 12.0625 \n",
       "Q 42.96875 12.0625 45.0625 12.5 \n",
       "Q 48.296875 13.09375 50.3125 15.359375 \n",
       "Q 52.34375 17.625 52.34375 21.4375 \n",
       "Q 52.34375 24.65625 50.78125 26.90625 \n",
       "Q 49.21875 29.15625 46.265625 30.171875 \n",
       "Q 43.3125 31.203125 33.453125 31.203125 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-66\"/>\n",
       "       <path d=\"M 7.171875 58.890625 \n",
       "L 7.171875 71.578125 \n",
       "L 20.90625 71.578125 \n",
       "L 20.90625 58.890625 \n",
       "z\n",
       "M 7.171875 0 \n",
       "L 7.171875 51.859375 \n",
       "L 20.90625 51.859375 \n",
       "L 20.90625 0 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-105\"/>\n",
       "       <path d=\"M 30.953125 51.859375 \n",
       "L 30.953125 40.921875 \n",
       "L 21.578125 40.921875 \n",
       "L 21.578125 20.015625 \n",
       "Q 21.578125 13.671875 21.84375 12.625 \n",
       "Q 22.125 11.578125 23.078125 10.890625 \n",
       "Q 24.03125 10.203125 25.390625 10.203125 \n",
       "Q 27.296875 10.203125 30.90625 11.53125 \n",
       "L 32.078125 0.875 \n",
       "Q 27.296875 -1.171875 21.234375 -1.171875 \n",
       "Q 17.53125 -1.171875 14.546875 0.0625 \n",
       "Q 11.578125 1.3125 10.1875 3.296875 \n",
       "Q 8.796875 5.28125 8.25 8.640625 \n",
       "Q 7.8125 11.03125 7.8125 18.3125 \n",
       "L 7.8125 40.921875 \n",
       "L 1.515625 40.921875 \n",
       "L 1.515625 51.859375 \n",
       "L 7.8125 51.859375 \n",
       "L 7.8125 62.15625 \n",
       "L 21.578125 70.171875 \n",
       "L 21.578125 51.859375 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-116\"/>\n",
       "       <path d=\"M 20.84375 71.578125 \n",
       "L 20.84375 45.265625 \n",
       "Q 27.484375 53.03125 36.71875 53.03125 \n",
       "Q 41.453125 53.03125 45.265625 51.265625 \n",
       "Q 49.078125 49.515625 51 46.78125 \n",
       "Q 52.9375 44.046875 53.640625 40.71875 \n",
       "Q 54.34375 37.40625 54.34375 30.421875 \n",
       "L 54.34375 0 \n",
       "L 40.625 0 \n",
       "L 40.625 27.390625 \n",
       "Q 40.625 35.546875 39.84375 37.734375 \n",
       "Q 39.0625 39.9375 37.078125 41.234375 \n",
       "Q 35.109375 42.53125 32.125 42.53125 \n",
       "Q 28.71875 42.53125 26.03125 40.859375 \n",
       "Q 23.34375 39.203125 22.09375 35.859375 \n",
       "Q 20.84375 32.515625 20.84375 25.984375 \n",
       "L 20.84375 0 \n",
       "L 7.125 0 \n",
       "L 7.125 71.578125 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-104\"/>\n",
       "       <path id=\"Arial-BoldMT-32\"/>\n",
       "       <path d=\"M 7.328125 0 \n",
       "L 7.328125 71.578125 \n",
       "L 37.75 71.578125 \n",
       "Q 49.21875 71.578125 54.421875 69.640625 \n",
       "Q 59.625 67.71875 62.75 62.78125 \n",
       "Q 65.875 57.859375 65.875 51.515625 \n",
       "Q 65.875 43.453125 61.125 38.203125 \n",
       "Q 56.390625 32.953125 46.96875 31.59375 \n",
       "Q 51.65625 28.859375 54.703125 25.578125 \n",
       "Q 57.765625 22.3125 62.9375 13.96875 \n",
       "L 71.6875 0 \n",
       "L 54.390625 0 \n",
       "L 43.953125 15.578125 \n",
       "Q 38.375 23.921875 36.328125 26.09375 \n",
       "Q 34.28125 28.265625 31.984375 29.078125 \n",
       "Q 29.6875 29.890625 24.703125 29.890625 \n",
       "L 21.78125 29.890625 \n",
       "L 21.78125 0 \n",
       "z\n",
       "M 21.78125 41.3125 \n",
       "L 32.46875 41.3125 \n",
       "Q 42.875 41.3125 45.453125 42.1875 \n",
       "Q 48.046875 43.0625 49.515625 45.203125 \n",
       "Q 50.984375 47.359375 50.984375 50.59375 \n",
       "Q 50.984375 54.203125 49.046875 56.421875 \n",
       "Q 47.125 58.640625 43.609375 59.234375 \n",
       "Q 41.84375 59.46875 33.0625 59.46875 \n",
       "L 21.78125 59.46875 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-82\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#Arial-BoldMT-66\"/>\n",
       "      <use x=\"72.216797\" xlink:href=\"#Arial-BoldMT-105\"/>\n",
       "      <use x=\"100\" xlink:href=\"#Arial-BoldMT-114\"/>\n",
       "      <use x=\"138.916016\" xlink:href=\"#Arial-BoldMT-116\"/>\n",
       "      <use x=\"172.216797\" xlink:href=\"#Arial-BoldMT-104\"/>\n",
       "      <use x=\"233.300781\" xlink:href=\"#Arial-BoldMT-32\"/>\n",
       "      <use x=\"261.083984\" xlink:href=\"#Arial-BoldMT-82\"/>\n",
       "      <use x=\"333.300781\" xlink:href=\"#Arial-BoldMT-97\"/>\n",
       "      <use x=\"388.916016\" xlink:href=\"#Arial-BoldMT-116\"/>\n",
       "      <use x=\"422.216797\" xlink:href=\"#Arial-BoldMT-101\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_1\">\n",
       "    <defs>\n",
       "     <path d=\"M 0 3 \n",
       "C 0.795609 3 1.55874 2.683901 2.12132 2.12132 \n",
       "C 2.683901 1.55874 3 0.795609 3 -0 \n",
       "C 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \n",
       "C 1.55874 -2.683901 0.795609 -3 0 -3 \n",
       "C -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \n",
       "C -2.683901 -1.55874 -3 -0.795609 -3 0 \n",
       "C -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \n",
       "C -1.55874 2.683901 -0.795609 3 0 3 \n",
       "z\n",
       "\" id=\"C0_0_5758fd4d31\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"165.995274\" xlink:href=\"#C0_0_5758fd4d31\" y=\"128.739421\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.01599\" xlink:href=\"#C0_0_5758fd4d31\" y=\"129.217789\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.036705\" xlink:href=\"#C0_0_5758fd4d31\" y=\"129.717901\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.057421\" xlink:href=\"#C0_0_5758fd4d31\" y=\"130.201705\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.078136\" xlink:href=\"#C0_0_5758fd4d31\" y=\"130.636585\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.098852\" xlink:href=\"#C0_0_5758fd4d31\" y=\"130.957309\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.119568\" xlink:href=\"#C0_0_5758fd4d31\" y=\"131.093209\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.140283\" xlink:href=\"#C0_0_5758fd4d31\" y=\"131.049721\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.160999\" xlink:href=\"#C0_0_5758fd4d31\" y=\"130.848589\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.181714\" xlink:href=\"#C0_0_5758fd4d31\" y=\"130.538737\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.20243\" xlink:href=\"#C0_0_5758fd4d31\" y=\"130.201705\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.223146\" xlink:href=\"#C0_0_5758fd4d31\" y=\"129.924469\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.243861\" xlink:href=\"#C0_0_5758fd4d31\" y=\"129.815749\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.264577\" xlink:href=\"#C0_0_5758fd4d31\" y=\"129.940777\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.285292\" xlink:href=\"#C0_0_5758fd4d31\" y=\"130.353913\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.306008\" xlink:href=\"#C0_0_5758fd4d31\" y=\"131.044285\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.326723\" xlink:href=\"#C0_0_5758fd4d31\" y=\"131.979277\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.347439\" xlink:href=\"#C0_0_5758fd4d31\" y=\"133.088221\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.368155\" xlink:href=\"#C0_0_5758fd4d31\" y=\"134.343937\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.38887\" xlink:href=\"#C0_0_5758fd4d31\" y=\"135.768169\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.409586\" xlink:href=\"#C0_0_5758fd4d31\" y=\"137.393533\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.430301\" xlink:href=\"#C0_0_5758fd4d31\" y=\"139.268953\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.451017\" xlink:href=\"#C0_0_5758fd4d31\" y=\"141.454225\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.471732\" xlink:href=\"#C0_0_5758fd4d31\" y=\"143.998273\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.492448\" xlink:href=\"#C0_0_5758fd4d31\" y=\"146.939149\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.513164\" xlink:href=\"#C0_0_5758fd4d31\" y=\"150.401881\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.533879\" xlink:href=\"#C0_0_5758fd4d31\" y=\"154.544113\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.554595\" xlink:href=\"#C0_0_5758fd4d31\" y=\"159.327793\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.57531\" xlink:href=\"#C0_0_5758fd4d31\" y=\"164.595277\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.596026\" xlink:href=\"#C0_0_5758fd4d31\" y=\"170.118253\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.616742\" xlink:href=\"#C0_0_5758fd4d31\" y=\"175.467277\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.637457\" xlink:href=\"#C0_0_5758fd4d31\" y=\"180.153109\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.658173\" xlink:href=\"#C0_0_5758fd4d31\" y=\"183.865897\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.678888\" xlink:href=\"#C0_0_5758fd4d31\" y=\"186.437125\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.699604\" xlink:href=\"#C0_0_5758fd4d31\" y=\"187.861357\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.720319\" xlink:href=\"#C0_0_5758fd4d31\" y=\"188.317981\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.741035\" xlink:href=\"#C0_0_5758fd4d31\" y=\"188.154901\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.761751\" xlink:href=\"#C0_0_5758fd4d31\" y=\"187.850485\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.782466\" xlink:href=\"#C0_0_5758fd4d31\" y=\"187.812433\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.803182\" xlink:href=\"#C0_0_5758fd4d31\" y=\"188.231005\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.823897\" xlink:href=\"#C0_0_5758fd4d31\" y=\"189.182305\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.844613\" xlink:href=\"#C0_0_5758fd4d31\" y=\"190.595665\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.865328\" xlink:href=\"#C0_0_5758fd4d31\" y=\"192.275389\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.886044\" xlink:href=\"#C0_0_5758fd4d31\" y=\"194.085577\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.90676\" xlink:href=\"#C0_0_5758fd4d31\" y=\"196.053409\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.927475\" xlink:href=\"#C0_0_5758fd4d31\" y=\"198.265861\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.948191\" xlink:href=\"#C0_0_5758fd4d31\" y=\"200.853397\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.968906\" xlink:href=\"#C0_0_5758fd4d31\" y=\"203.897557\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"166.989622\" xlink:href=\"#C0_0_5758fd4d31\" y=\"207.441829\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"167.010338\" xlink:href=\"#C0_0_5758fd4d31\" y=\"211.442725\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"167.031053\" xlink:href=\"#C0_0_5758fd4d31\" y=\"215.867629\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"167.051769\" xlink:href=\"#C0_0_5758fd4d31\" y=\"220.645873\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"167.072484\" xlink:href=\"#C0_0_5758fd4d31\" y=\"225.625249\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"167.0932\" xlink:href=\"#C0_0_5758fd4d31\" y=\"230.615497\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"167.113915\" xlink:href=\"#C0_0_5758fd4d31\" y=\"235.469845\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"167.134631\" xlink:href=\"#C0_0_5758fd4d31\" y=\"240.003469\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"167.155347\" xlink:href=\"#C0_0_5758fd4d31\" y=\"244.053289\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"167.176062\" xlink:href=\"#C0_0_5758fd4d31\" y=\"247.570381\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"167.196778\" xlink:href=\"#C0_0_5758fd4d31\" y=\"250.549309\"/>\n",
       "    </g>\n",
       "    <g clip-path=\"url(#pc35ddb01dd)\">\n",
       "     <use style=\"fill:none;stroke:#808080;\" x=\"167.217493\" xlink:href=\"#C0_0_5758fd4d31\" y=\"252.995509\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path clip-path=\"url(#pc35ddb01dd)\" d=\"M 435.463519 352.463437 \n",
       "L 435.463519 26.303437 \n",
       "L 503.555625 26.303437 \n",
       "L 503.555625 352.463437 \n",
       "z\n",
       "\" style=\"fill:#808080;opacity:0.25;stroke:#808080;stroke-linejoin:miter;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 57.155625 352.463437 \n",
       "L 57.155625 26.303437 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 503.555625 352.463437 \n",
       "L 503.555625 26.303437 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 57.155625 352.463437 \n",
       "L 503.555625 352.463437 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_7\">\n",
       "    <path d=\"M 57.155625 26.303437 \n",
       "L 503.555625 26.303437 \n",
       "\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n",
       "   </g>\n",
       "   <g id=\"text_15\">\n",
       "    <!-- Birth Rate crude(per 1000 people) -->\n",
       "    <g style=\"fill:#262626;\" transform=\"translate(136.326094 20.303437)scale(0.18 -0.18)\">\n",
       "     <defs>\n",
       "      <path d=\"M 52.390625 36.53125 \n",
       "L 38.875 34.078125 \n",
       "Q 38.1875 38.140625 35.765625 40.1875 \n",
       "Q 33.34375 42.234375 29.5 42.234375 \n",
       "Q 24.359375 42.234375 21.3125 38.6875 \n",
       "Q 18.265625 35.15625 18.265625 26.859375 \n",
       "Q 18.265625 17.625 21.359375 13.8125 \n",
       "Q 24.46875 10.015625 29.6875 10.015625 \n",
       "Q 33.59375 10.015625 36.078125 12.234375 \n",
       "Q 38.578125 14.453125 39.59375 19.875 \n",
       "L 53.078125 17.578125 \n",
       "Q 50.984375 8.296875 45.015625 3.5625 \n",
       "Q 39.0625 -1.171875 29.046875 -1.171875 \n",
       "Q 17.671875 -1.171875 10.90625 6 \n",
       "Q 4.15625 13.1875 4.15625 25.875 \n",
       "Q 4.15625 38.71875 10.9375 45.875 \n",
       "Q 17.71875 53.03125 29.296875 53.03125 \n",
       "Q 38.765625 53.03125 44.359375 48.953125 \n",
       "Q 49.953125 44.875 52.390625 36.53125 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-99\"/>\n",
       "      <path d=\"M 41.3125 0 \n",
       "L 41.3125 7.765625 \n",
       "Q 38.484375 3.609375 33.859375 1.21875 \n",
       "Q 29.25 -1.171875 24.125 -1.171875 \n",
       "Q 18.890625 -1.171875 14.734375 1.125 \n",
       "Q 10.59375 3.421875 8.734375 7.5625 \n",
       "Q 6.890625 11.71875 6.890625 19.046875 \n",
       "L 6.890625 51.859375 \n",
       "L 20.609375 51.859375 \n",
       "L 20.609375 28.03125 \n",
       "Q 20.609375 17.09375 21.359375 14.625 \n",
       "Q 22.125 12.15625 24.125 10.71875 \n",
       "Q 26.125 9.28125 29.203125 9.28125 \n",
       "Q 32.71875 9.28125 35.5 11.203125 \n",
       "Q 38.28125 13.140625 39.296875 15.984375 \n",
       "Q 40.328125 18.84375 40.328125 29.984375 \n",
       "L 40.328125 51.859375 \n",
       "L 54.046875 51.859375 \n",
       "L 54.046875 0 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-117\"/>\n",
       "      <path d=\"M 54.734375 0 \n",
       "L 42 0 \n",
       "L 42 7.625 \n",
       "Q 38.8125 3.171875 34.484375 1 \n",
       "Q 30.171875 -1.171875 25.78125 -1.171875 \n",
       "Q 16.84375 -1.171875 10.46875 6.03125 \n",
       "Q 4.109375 13.234375 4.109375 26.125 \n",
       "Q 4.109375 39.3125 10.296875 46.171875 \n",
       "Q 16.5 53.03125 25.984375 53.03125 \n",
       "Q 34.671875 53.03125 41.015625 45.796875 \n",
       "L 41.015625 71.578125 \n",
       "L 54.734375 71.578125 \n",
       "z\n",
       "M 18.109375 27.046875 \n",
       "Q 18.109375 18.75 20.40625 15.046875 \n",
       "Q 23.734375 9.671875 29.6875 9.671875 \n",
       "Q 34.421875 9.671875 37.734375 13.6875 \n",
       "Q 41.0625 17.71875 41.0625 25.734375 \n",
       "Q 41.0625 34.671875 37.84375 38.59375 \n",
       "Q 34.625 42.53125 29.59375 42.53125 \n",
       "Q 24.703125 42.53125 21.40625 38.640625 \n",
       "Q 18.109375 34.765625 18.109375 27.046875 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-100\"/>\n",
       "      <path d=\"M 29.9375 -21.046875 \n",
       "L 20.515625 -21.046875 \n",
       "Q 13.03125 -9.765625 9.125 2.390625 \n",
       "Q 5.21875 14.546875 5.21875 25.921875 \n",
       "Q 5.21875 40.046875 10.0625 52.640625 \n",
       "Q 14.265625 63.578125 20.703125 72.796875 \n",
       "L 30.078125 72.796875 \n",
       "Q 23.390625 58.015625 20.875 47.625 \n",
       "Q 18.359375 37.25 18.359375 25.640625 \n",
       "Q 18.359375 17.625 19.84375 9.21875 \n",
       "Q 21.34375 0.828125 23.921875 -6.734375 \n",
       "Q 25.640625 -11.71875 29.9375 -21.046875 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-40\"/>\n",
       "      <path d=\"M 6.78125 51.859375 \n",
       "L 19.578125 51.859375 \n",
       "L 19.578125 44.234375 \n",
       "Q 22.078125 48.140625 26.3125 50.578125 \n",
       "Q 30.5625 53.03125 35.75 53.03125 \n",
       "Q 44.78125 53.03125 51.078125 45.953125 \n",
       "Q 57.375 38.875 57.375 26.21875 \n",
       "Q 57.375 13.234375 51.015625 6.03125 \n",
       "Q 44.671875 -1.171875 35.640625 -1.171875 \n",
       "Q 31.34375 -1.171875 27.84375 0.53125 \n",
       "Q 24.359375 2.25 20.515625 6.390625 \n",
       "L 20.515625 -19.734375 \n",
       "L 6.78125 -19.734375 \n",
       "z\n",
       "M 20.359375 26.8125 \n",
       "Q 20.359375 18.0625 23.828125 13.890625 \n",
       "Q 27.296875 9.71875 32.28125 9.71875 \n",
       "Q 37.0625 9.71875 40.234375 13.546875 \n",
       "Q 43.40625 17.390625 43.40625 26.125 \n",
       "Q 43.40625 34.28125 40.125 38.234375 \n",
       "Q 36.859375 42.1875 32.03125 42.1875 \n",
       "Q 27 42.1875 23.671875 38.296875 \n",
       "Q 20.359375 34.421875 20.359375 26.8125 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-112\"/>\n",
       "      <path d=\"M 4 26.65625 \n",
       "Q 4 33.5 7.375 39.890625 \n",
       "Q 10.75 46.296875 16.921875 49.65625 \n",
       "Q 23.09375 53.03125 30.71875 53.03125 \n",
       "Q 42.484375 53.03125 50 45.390625 \n",
       "Q 57.515625 37.75 57.515625 26.078125 \n",
       "Q 57.515625 14.3125 49.921875 6.5625 \n",
       "Q 42.328125 -1.171875 30.8125 -1.171875 \n",
       "Q 23.6875 -1.171875 17.21875 2.046875 \n",
       "Q 10.75 5.28125 7.375 11.5 \n",
       "Q 4 17.71875 4 26.65625 \n",
       "z\n",
       "M 18.0625 25.921875 \n",
       "Q 18.0625 18.21875 21.71875 14.109375 \n",
       "Q 25.390625 10.015625 30.765625 10.015625 \n",
       "Q 36.140625 10.015625 39.765625 14.109375 \n",
       "Q 43.40625 18.21875 43.40625 26.03125 \n",
       "Q 43.40625 33.640625 39.765625 37.734375 \n",
       "Q 36.140625 41.84375 30.765625 41.84375 \n",
       "Q 25.390625 41.84375 21.71875 37.734375 \n",
       "Q 18.0625 33.640625 18.0625 25.921875 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-111\"/>\n",
       "      <path d=\"M 7.171875 0 \n",
       "L 7.171875 71.578125 \n",
       "L 20.90625 71.578125 \n",
       "L 20.90625 0 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-108\"/>\n",
       "      <path d=\"M 3.375 -21.046875 \n",
       "Q 7.421875 -12.359375 9.078125 -7.71875 \n",
       "Q 10.75 -3.078125 12.15625 2.96875 \n",
       "Q 13.578125 9.03125 14.25 14.46875 \n",
       "Q 14.9375 19.921875 14.9375 25.640625 \n",
       "Q 14.9375 37.25 12.453125 47.625 \n",
       "Q 9.96875 58.015625 3.265625 72.796875 \n",
       "L 12.59375 72.796875 \n",
       "Q 19.96875 62.3125 24.046875 50.53125 \n",
       "Q 28.125 38.765625 28.125 26.65625 \n",
       "Q 28.125 16.453125 24.90625 4.78125 \n",
       "Q 21.234375 -8.296875 12.84375 -21.046875 \n",
       "z\n",
       "\" id=\"Arial-BoldMT-41\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#Arial-BoldMT-66\"/>\n",
       "     <use x=\"72.216797\" xlink:href=\"#Arial-BoldMT-105\"/>\n",
       "     <use x=\"100\" xlink:href=\"#Arial-BoldMT-114\"/>\n",
       "     <use x=\"138.916016\" xlink:href=\"#Arial-BoldMT-116\"/>\n",
       "     <use x=\"172.216797\" xlink:href=\"#Arial-BoldMT-104\"/>\n",
       "     <use x=\"233.300781\" xlink:href=\"#Arial-BoldMT-32\"/>\n",
       "     <use x=\"261.083984\" xlink:href=\"#Arial-BoldMT-82\"/>\n",
       "     <use x=\"333.300781\" xlink:href=\"#Arial-BoldMT-97\"/>\n",
       "     <use x=\"388.916016\" xlink:href=\"#Arial-BoldMT-116\"/>\n",
       "     <use x=\"422.216797\" xlink:href=\"#Arial-BoldMT-101\"/>\n",
       "     <use x=\"477.832031\" xlink:href=\"#Arial-BoldMT-32\"/>\n",
       "     <use x=\"505.615234\" xlink:href=\"#Arial-BoldMT-99\"/>\n",
       "     <use x=\"561.230469\" xlink:href=\"#Arial-BoldMT-114\"/>\n",
       "     <use x=\"600.146484\" xlink:href=\"#Arial-BoldMT-117\"/>\n",
       "     <use x=\"661.230469\" xlink:href=\"#Arial-BoldMT-100\"/>\n",
       "     <use x=\"722.314453\" xlink:href=\"#Arial-BoldMT-101\"/>\n",
       "     <use x=\"777.929688\" xlink:href=\"#Arial-BoldMT-40\"/>\n",
       "     <use x=\"811.230469\" xlink:href=\"#Arial-BoldMT-112\"/>\n",
       "     <use x=\"872.314453\" xlink:href=\"#Arial-BoldMT-101\"/>\n",
       "     <use x=\"927.929688\" xlink:href=\"#Arial-BoldMT-114\"/>\n",
       "     <use x=\"966.845703\" xlink:href=\"#Arial-BoldMT-32\"/>\n",
       "     <use x=\"994.628906\" xlink:href=\"#Arial-BoldMT-49\"/>\n",
       "     <use x=\"1050.244141\" xlink:href=\"#Arial-BoldMT-48\"/>\n",
       "     <use x=\"1105.859375\" xlink:href=\"#Arial-BoldMT-48\"/>\n",
       "     <use x=\"1161.474609\" xlink:href=\"#Arial-BoldMT-48\"/>\n",
       "     <use x=\"1217.089844\" xlink:href=\"#Arial-BoldMT-32\"/>\n",
       "     <use x=\"1244.873047\" xlink:href=\"#Arial-BoldMT-112\"/>\n",
       "     <use x=\"1305.957031\" xlink:href=\"#Arial-BoldMT-101\"/>\n",
       "     <use x=\"1361.572266\" xlink:href=\"#Arial-BoldMT-111\"/>\n",
       "     <use x=\"1422.65625\" xlink:href=\"#Arial-BoldMT-112\"/>\n",
       "     <use x=\"1483.740234\" xlink:href=\"#Arial-BoldMT-108\"/>\n",
       "     <use x=\"1511.523438\" xlink:href=\"#Arial-BoldMT-101\"/>\n",
       "     <use x=\"1567.138672\" xlink:href=\"#Arial-BoldMT-41\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_8\">\n",
       "     <path d=\"M 65.555625 346.463437 \n",
       "L 70.355625 346.463437 \n",
       "Q 72.755625 346.463437 72.755625 344.063437 \n",
       "L 72.755625 339.263437 \n",
       "Q 72.755625 336.863437 70.355625 336.863437 \n",
       "L 65.555625 336.863437 \n",
       "Q 63.155625 336.863437 63.155625 339.263437 \n",
       "L 63.155625 344.063437 \n",
       "Q 63.155625 346.463437 65.555625 346.463437 \n",
       "z\n",
       "\" style=\"fill:#eaeaf2;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pc35ddb01dd\">\n",
       "   <rect height=\"326.16\" width=\"446.4\" x=\"57.155625\" y=\"26.303437\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Visualising the results\n",
    "# plt.plot(test_years,y_test, color = 'blue', label = 'Real Birth Rate')\n",
    "# plt.plot(test_years,n_predictions, color = 'green', label = 'Predicted Birth Rate')\n",
    "# plt.legend()\n",
    "# plt.xlabel('Year')\n",
    "# # plt.ylabel(label)\n",
    "# plt.title('Birth Rate Crude(per 1000 people) (2000-2019)')\n",
    "# plt.show()\n",
    "# sns.set(rc={'figure.figsize':(8,6)})\n",
    "\n",
    "sns.set(rc={'figure.figsize':(8,6)})\n",
    "plt.axvspan(xmin =datetime.strptime('2010-12-25', '%Y-%m-%d'),\n",
    "            xmax =datetime.strptime('2019-12-25', '%Y-%m-%d'),\n",
    "            color = 'grey',\n",
    "            alpha = 0.25)\n",
    "plt.scatter(df['year'], df['value'], facecolors = 'none', edgecolors = 'grey')\n",
    "# plt.plot(trained_df['year'], trained_df['value'], color = 'green', label = 'train_predictions')\n",
    "# plt.fill_between(training_forecast['ds'],training_forecast['yhat_lower'], training_forecast['yhat_upper'], color = 'green', alpha =0.25)\n",
    "\n",
    "# plt.plot(tested_df['year'], tested_df['value'], color = 'red', label = 'test_predictions')\n",
    "# plt.fill_between(test_forecast['ds'],test_forecast['yhat_lower'], test_forecast['yhat_upper'], color = 'red', alpha =0.25)\n",
    "\n",
    "plt.xlim([datetime.strptime('1960-12-25', '%Y-%m-%d'), datetime.strptime('2019-12-25', '%Y-%m-%d')])\n",
    "plt.ylim([10,70])\n",
    "plt.xlabel('Year', fontsize = 18, fontweight = 'bold', color ='black')\n",
    "plt.ylabel('Birth Rate', fontsize = 18, fontweight = 'bold', color ='black')\n",
    "plt.xticks(fontsize = 18, fontweight = 'bold')\n",
    "plt.yticks(fontsize = 18, fontweight = 'bold')\n",
    "plt.title('Birth Rate crude(per 1000 people)', fontsize = 18, fontweight = 'bold')\n",
    "plt.legend(loc='lower left', fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test RMSE: 0.870\n"
     ]
    }
   ],
   "source": [
    "# report performance\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = sqrt(mean_squared_error(y_test, n_predictions))\n",
    "print(' Test RMSE: %.3f' %  rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ----------- To Do: Predict the next 10 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
